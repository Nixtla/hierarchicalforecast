{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconciliation Methods\n",
    "> Classes in this module have the `reconcile` method capable of reconcile base forecasts using `numpy` arrays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from statsmodels.stats.moment_helpers import cov2corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import ExceptionExpected, test_close, test_eq\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _reconcile(S: np.ndarray, P: np.ndarray, W: np.ndarray, \n",
    "               y_hat: np.ndarray, SP: np.ndarray = None):\n",
    "    if SP is None:\n",
    "        SP = S @ P\n",
    "    return np.matmul(SP, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 1. Bottom Up </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def bottom_up(S: np.ndarray,\n",
    "              y_hat: np.ndarray,\n",
    "              idx_bottom: List[int]):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    P = np.zeros_like(S, dtype=np.float32)\n",
    "    P[idx_bottom] = S[idx_bottom]\n",
    "    P = P.T\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BottomUp:\n",
    "    \"\"\"Bottom Up Reconciliation Class.\n",
    "    [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "    The most basic hierarchical reconciliation is performed using an Bottom-Up strategy. It was proposed for \n",
    "    the first time by Orcutt in 1968.\n",
    "    The corresponding hierarchical \"projection\" matrix is defined as:\n",
    "\n",
    "    $$\\mathbf{P}_{\\\\text{BU}} = [\\mathbf{0}_{\\mathrm{[b],[a]}}\\;|\\;\\mathbf{I}_{\\mathrm{[b][b]}}]$$\n",
    "\n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    None\n",
    "    \n",
    "    **References:**<br>\n",
    "    - [Orcutt, G.H., Watts, H.W., & Edwards, J.B.(1968). Data aggregation and information loss. The American \n",
    "    Economic Review, 58 , 773{787)](http://www.jstor.org/stable/1815532).\n",
    "    \"\"\"\n",
    "    \n",
    "    def reconcile(\n",
    "            self,\n",
    "            S: np.ndarray, \n",
    "            y_hat: np.ndarray, \n",
    "            idx_bottom: np.ndarray\n",
    "        ):\n",
    "        \"\"\"Bottom Up Reconciliation Method.\n",
    "        [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `S`: Summing matrix of size (`base`, `bottom`).<br>\n",
    "        `y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
    "        `idx_bottom`: Indices corresponding to the bottom level of `S`, size (`bottom`).<br>\n",
    "\n",
    "        \"\"\"\n",
    "        return bottom_up(S=S, y_hat=y_hat, idx_bottom=idx_bottom)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"BottomUp\" class=\"doc_header\"><code>class</code> <code>BottomUp</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>BottomUp</code>()\n",
       "\n",
       "Bottom Up Reconciliation Class.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "The most basic hierarchical reconciliation is performed using an Bottom-Up strategy. It was proposed for \n",
       "the first time by Orcutt in 1968.\n",
       "The corresponding hierarchical \"projection\" matrix is defined as:\n",
       "\n",
       "$$\\mathbf{P}_{\\text{BU}} = [\\mathbf{0}_{\\mathrm{[b],[a]}}\\;|\\;\\mathbf{I}_{\\mathrm{[b][b]}}]$$\n",
       "\n",
       "\n",
       "**Parameters:**<br>\n",
       "None\n",
       "\n",
       "**References:**<br>\n",
       "- [Orcutt, G.H., Watts, H.W., & Edwards, J.B.(1968). Data aggregation and information loss. The American \n",
       "Economic Review, 58 , 773{787)](http://www.jstor.org/stable/1815532)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BottomUp, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"BottomUp.reconcile\" class=\"doc_header\"><code>BottomUp.reconcile</code><a href=\"__main__.py#L21\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>BottomUp.reconcile</code>(**`S`**:`ndarray`, **`y_hat`**:`ndarray`, **`idx_bottom`**:`ndarray`)\n",
       "\n",
       "Bottom Up Reconciliation Method.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`S`: Summing matrix of size (`base`, `bottom`).<br>\n",
       "`y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
       "`idx_bottom`: Indices corresponding to the bottom level of `S`, size (`bottom`).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BottomUp.reconcile, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "S = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 0., 0.],\n",
    "    [0., 0., 1., 1.],\n",
    "    [0., 1., 0., 0.],\n",
    "    [1., 0., 0., 0.],\n",
    "    [0., 0., 1., 0.],\n",
    "    [0., 0., 0., 1.],\n",
    "])\n",
    "h = 10\n",
    "_y = np.array([10., 5., 4., 2., 1.])\n",
    "y_bottom = np.vstack([i * _y for i in range(1, 5)])\n",
    "y_hat_bottom_insample = np.roll(y_bottom, 1)\n",
    "y_hat_bottom_insample[:, 0] = np.nan\n",
    "y_hat_bottom = np.vstack([i * np.ones(h) for i in range(1, 5)])\n",
    "idx_bottom = [4, 3, 5, 6]\n",
    "levels = {'level1': np.array([0]),\n",
    "          'level2': np.array([1, 2]),\n",
    "          'level3': idx_bottom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "cls_bottom_up = BottomUp()\n",
    "test_eq(\n",
    "    cls_bottom_up(S=S, y_hat=S @ y_hat_bottom, idx_bottom=idx_bottom),\n",
    "    S @ y_hat_bottom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def is_strictly_hierarchical(S: np.ndarray, \n",
    "                             levels: Dict[str, np.ndarray]):\n",
    "    # main idea:\n",
    "    # if S represents a strictly hierarchical structure\n",
    "    # the number of paths before the bottom level\n",
    "    # should be equal to the number of nodes\n",
    "    # of the previuos level\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    # removing bottom level\n",
    "    levels_.popitem()\n",
    "    # making S categorical\n",
    "    hiers = [np.argmax(S[idx], axis=0) + 1 for _, idx in levels_.items()]\n",
    "    hiers = np.vstack(hiers)\n",
    "    paths = np.unique(hiers, axis=1).shape[1] \n",
    "    nodes = levels_.popitem()[1].size\n",
    "    return paths == nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert is_strictly_hierarchical(S, levels)\n",
    "S_non_hier = np.array([\n",
    "    [1., 1., 1., 1.], # total\n",
    "    [1., 1., 0., 0.], # city 1\n",
    "    [0., 0., 1., 1.], # city 2\n",
    "    [1., 0., 1., 0.], # transgender\n",
    "    [0., 1., 0., 1.], # no transgender\n",
    "    [1., 0., 0., 0.], #city 1 - transgender\n",
    "    [0., 1., 0., 0.], #city 1 - no transgender\n",
    "    [0., 0., 1., 0.], #city 2 - transgender\n",
    "    [0., 0., 0., 1.], #city 2 - no transgender\n",
    "])\n",
    "levels_non_hier = {\n",
    "    'Country': np.array([0]),\n",
    "    'Country/City': np.array([2, 1]),\n",
    "    'Country/Transgender': np.array([3, 4]),\n",
    "    'Country-City-Transgender': np.array([5, 6, 7, 8]),\n",
    "}\n",
    "assert not is_strictly_hierarchical(S_non_hier, levels_non_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _get_child_nodes(S: np.ndarray, levels: Dict[str, np.ndarray]):\n",
    "    level_names = list(levels.keys())\n",
    "    nodes = OrderedDict()\n",
    "    for i_level, level in enumerate(level_names[:-1]):\n",
    "        parent = levels[level]\n",
    "        child = np.zeros_like(S)\n",
    "        idx_child = levels[level_names[i_level+1]] \n",
    "        child[idx_child] = S[idx_child]\n",
    "        nodes_level = {}\n",
    "        for idx_parent_node in parent:\n",
    "            parent_node = S[idx_parent_node]\n",
    "            idx_node = child * parent_node.astype(bool)\n",
    "            idx_node, = np.where(idx_node.sum(axis=1) > 0)\n",
    "            nodes_level[idx_parent_node] = [idx for idx in idx_child if idx in idx_node]\n",
    "        nodes[level] = nodes_level\n",
    "    return nodes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _reconcile_fcst_proportions(S: np.ndarray, y_hat: np.ndarray,\n",
    "                                levels: Dict[str, np.ndarray],\n",
    "                                nodes: Dict[str, Dict[int, np.ndarray]],\n",
    "                                idx_top: int):\n",
    "    reconciled = np.zeros_like(y_hat)\n",
    "    reconciled[idx_top] = y_hat[idx_top]\n",
    "    level_names = list(levels.keys())\n",
    "    for i_level, level in enumerate(level_names[:-1]):\n",
    "        nodes_level = nodes[level]\n",
    "        for idx_parent, idx_childs in nodes_level.items():\n",
    "            fcst_parent = reconciled[idx_parent]\n",
    "            childs_sum = y_hat[idx_childs].sum()\n",
    "            for idx_child in idx_childs:\n",
    "                reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
    "    return reconciled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 2. Top Down </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def top_down(S: np.ndarray, \n",
    "             y_hat: np.ndarray,\n",
    "             y_insample: np.ndarray,\n",
    "             levels: Dict[str, np.ndarray],\n",
    "             method: str):\n",
    "    if not is_strictly_hierarchical(S, levels):\n",
    "        raise ValueError('Top down reconciliation requires strictly hierarchical structures.')\n",
    "    \n",
    "    n_hiers, n_bottom = S.shape\n",
    "    idx_top = int(S.sum(axis=1).argmax())\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    idx_bottom = levels_[list(levels_)[-1]]\n",
    "    \n",
    "    if method == 'forecast_proportions':\n",
    "        nodes = _get_child_nodes(S=S, levels=levels_)\n",
    "        reconciled = [_reconcile_fcst_proportions(S=S, y_hat=y_hat_[:, None], \n",
    "                                                  levels=levels_, \n",
    "                                                  nodes=nodes,\n",
    "                                                  idx_top=idx_top) \\\n",
    "                      for y_hat_ in y_hat.T]\n",
    "        reconciled = np.hstack(reconciled)\n",
    "        return reconciled\n",
    "    else:\n",
    "        y_top = y_insample[idx_top]\n",
    "        y_btm = y_insample[idx_bottom]\n",
    "        if method == 'average_proportions':\n",
    "            prop = np.mean(y_btm / y_top, axis=1)\n",
    "        elif method == 'proportion_averages':\n",
    "            prop = np.mean(y_btm, axis=1) / np.mean(y_top)\n",
    "        else:\n",
    "            raise Exception(f'Unknown method {method}')\n",
    "    P = np.zeros_like(S, np.float64).T #float 64 if prop is too small, happens with wiki2\n",
    "    P[:, idx_top] = prop\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TopDown:\n",
    "    \"\"\"Top Down Reconciliation Class.\n",
    "    [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "    The Top Down hierarchical reconciliation method, distributes the total aggregate predictions and decomposes \n",
    "    it down the hierarchy using proportions $\\mathbf{p}_{\\mathrm{[b]}}$ that can be actual historical values \n",
    "    or estimated.\n",
    "    \n",
    "    $$\\mathbf{P}=[\\mathbf{p}_{\\mathrm{[b]}}\\;|\\;\\mathbf{0}_{\\mathrm{[b][a,b\\;-1]}}]$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `method`: One of `forecast_proportions`, `average_proportions` and `proportion_averages`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    - [Disaggregation methods to expedite product line forecasting. Journal of Forecasting, 9 , 233–254. \n",
    "    doi:10.1002/for.3980090304](https://onlinelibrary.wiley.com/doi/abs/10.1002/for.3980090304).<br>\n",
    "    - [An investigation of aggregate variable time series forecast strategies with specific subaggregate \n",
    "    time series statistical correlation. Computers and Operations Research, 26 , 1133–1149. \n",
    "    doi:10.1016/S0305-0548(99)00017-9](https://doi.org/10.1016/S0305-0548(99)00017-9).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            method: str \n",
    "        ):\n",
    "        self.method = method\n",
    "    \n",
    "    def reconcile(\n",
    "            self, \n",
    "            S: np.ndarray, \n",
    "            y_hat: np.ndarray, \n",
    "            y_insample: np.ndarray, \n",
    "            levels: Dict[str, np.ndarray] \n",
    "        ):\n",
    "        \"\"\"Top Down Reconciliation Method.\n",
    "        [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `S`: Summing matrix of size (`base`, `bottom`).<br>\n",
    "        `y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
    "        `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "        `levels`: Each key is a level and each value its `S` indices.<br>\n",
    "\n",
    "        \"\"\"\n",
    "        return top_down(S=S, y_hat=y_hat, \n",
    "                        y_insample=y_insample, \n",
    "                        levels=levels,\n",
    "                        method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TopDown\" class=\"doc_header\"><code>class</code> <code>TopDown</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>TopDown</code>(**`method`**:`str`)\n",
       "\n",
       "Top Down Reconciliation Class.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "The Top Down hierarchical reconciliation method, distributes the total aggregate predictions and decomposes \n",
       "it down the hierarchy using proportions $\\mathbf{p}_{\\mathrm{[b]}}$ that can be actual historical values \n",
       "or estimated.\n",
       "\n",
       "$$\\mathbf{P}=[\\mathbf{p}_{\\mathrm{[b]}}\\;|\\;\\mathbf{0}_{\\mathrm{[b][a,b\\;-1]}}]$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`method`: One of `forecast_proportions`, `average_proportions` and `proportion_averages`.<br>\n",
       "\n",
       "**References:**<br>\n",
       "- [Disaggregation methods to expedite product line forecasting. Journal of Forecasting, 9 , 233–254. \n",
       "doi:10.1002/for.3980090304](https://onlinelibrary.wiley.com/doi/abs/10.1002/for.3980090304).<br>\n",
       "- [An investigation of aggregate variable time series forecast strategies with specific subaggregate \n",
       "time series statistical correlation. Computers and Operations Research, 26 , 1133–1149. \n",
       "doi:10.1016/S0305-0548(99)00017-9](https://doi.org/10.1016/S0305-0548(99)00017-9)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TopDown, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"TopDown.reconcile\" class=\"doc_header\"><code>TopDown.reconcile</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>TopDown.reconcile</code>(**`S`**:`ndarray`, **`y_hat`**:`ndarray`, **`y_insample`**:`ndarray`, **`levels`**:`Dict`\\[`str`, `ndarray`\\])\n",
       "\n",
       "Top Down Reconciliation Method.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`S`: Summing matrix of size (`base`, `bottom`).<br>\n",
       "`y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
       "`y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
       "`levels`: Each key is a level and each value its `S` indices.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TopDown.reconcile, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# we are able to recover forecasts \n",
    "# from top_down in this example\n",
    "# because the time series\n",
    "# share the same proportion\n",
    "# across time\n",
    "# but it is not a general case\n",
    "for method in ['forecast_proportions', 'average_proportions', 'proportion_averages']:\n",
    "    cls_top_down = TopDown(method=method)\n",
    "    test_close(\n",
    "        cls_top_down(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y_insample=S @ y_bottom, \n",
    "            levels=levels\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 3. Middle Out </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def middle_out(S: np.ndarray, \n",
    "               y_hat: np.ndarray,\n",
    "               y_insample: np.ndarray,\n",
    "               levels: Dict[str, np.ndarray],\n",
    "               level: str,\n",
    "               top_down_method: str):\n",
    "    if not is_strictly_hierarchical(S, levels):\n",
    "        raise ValueError('Middle out reconciliation requires strictly hierarchical structures.')\n",
    "    if level not in levels.keys():\n",
    "        raise ValueError('You have to provide a `level` in `levels`.')\n",
    "    levels_ = dict(sorted(levels.items(), key=lambda x: len(x[1])))\n",
    "    reconciled = np.full_like(y_hat, fill_value=np.nan)\n",
    "    cut_nodes = levels_[level]\n",
    "    # bottom up reconciliation\n",
    "    idxs_bu = []\n",
    "    for node, idx_node in levels_.items():\n",
    "        idxs_bu.append(idx_node)\n",
    "        if node == level:\n",
    "            break\n",
    "    idxs_bu = np.hstack(idxs_bu)\n",
    "    #bottom up forecasts\n",
    "    bu = bottom_up(S=np.unique(S[idxs_bu], axis=1), \n",
    "                   y_hat=y_hat[idxs_bu], \n",
    "                   idx_bottom=np.arange(len(idxs_bu))[-len(cut_nodes):])\n",
    "    reconciled[idxs_bu] = bu\n",
    "    \n",
    "    #top down\n",
    "    child_nodes = _get_child_nodes(S, levels_)\n",
    "    # parents contains each node in the middle out level\n",
    "    # as key. The values of each node are the levels that\n",
    "    # are conected to that node.\n",
    "    parents = {node: {level: np.array([node])} for node in cut_nodes}\n",
    "    level_names = list(levels_.keys())\n",
    "    for lv, lv_child in zip(level_names[:-1], level_names[1:]):\n",
    "        # if lv is not part of the middle out to bottom\n",
    "        # structure we continue\n",
    "        if lv not in list(parents.values())[0].keys():\n",
    "            continue\n",
    "        for idx_middle_out in parents.keys():\n",
    "            idxs_parents = parents[idx_middle_out].values()\n",
    "            complete_idxs_child = []\n",
    "            for idx_parent, idxs_child in child_nodes[lv].items():\n",
    "                if any(idx_parent in val for val in idxs_parents):\n",
    "                    complete_idxs_child.append(idxs_child)\n",
    "            parents[idx_middle_out][lv_child] = np.hstack(complete_idxs_child)\n",
    " \n",
    "    for node, levels_node in parents.items():\n",
    "        idxs_node = np.hstack(list(levels_node.values()))\n",
    "        S_node = S[idxs_node]\n",
    "        S_node = S_node[:,~np.all(S_node == 0, axis=0)]\n",
    "        counter = 0\n",
    "        levels_node_ = deepcopy(levels_node)\n",
    "        for lv_name, idxs_level in levels_node_.items():\n",
    "            idxs_len = len(idxs_level)\n",
    "            levels_node_[lv_name] = np.arange(counter, idxs_len + counter)\n",
    "            counter += idxs_len\n",
    "        td = top_down(S_node, \n",
    "                      y_hat[idxs_node], \n",
    "                      y_insample[idxs_node], \n",
    "                      levels_node_, \n",
    "                      method=top_down_method)\n",
    "        reconciled[idxs_node] = td\n",
    "    return reconciled\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MiddleOut:\n",
    "    \"\"\"Middle Out Reconciliation Class.\n",
    "    [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "    This method is only available for strictly hierarchical structures. It anchors the base predictions in \n",
    "    a middle level. The levels above the base predictions use the bottom-up approach, while the levels below \n",
    "    use a top-down.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `level`: Middle level.<br>\n",
    "    `top_down_method`: One of `forecast_proportions`, `average_proportions` and `proportion_averages`.<br>\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            level: str, \n",
    "            top_down_method: str \n",
    "        ):\n",
    "        self.level = level\n",
    "        self.top_down_method = top_down_method \n",
    "    \n",
    "    def reconcile(\n",
    "            self, \n",
    "            S: np.ndarray, \n",
    "            y_hat: np.ndarray,\n",
    "            y_insample: np.ndarray, \n",
    "            levels: Dict[str, np.ndarray] \n",
    "        ):\n",
    "        \"\"\"Middle Out Reconciliation Method.\n",
    "        [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `S`: Summing matrix of size (`base`, `bottom`).<br>\n",
    "        `y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
    "        `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "        `levels`: Each key is a level and each value its `S` indices.<br>\n",
    "\n",
    "        \"\"\"\n",
    "        return middle_out(S=S, y_hat=y_hat, \n",
    "                          y_insample=y_insample, \n",
    "                          levels=levels,\n",
    "                          level=self.level,\n",
    "                          top_down_method=self.top_down_method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"MiddleOut\" class=\"doc_header\"><code>class</code> <code>MiddleOut</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>MiddleOut</code>(**`level`**:`str`, **`top_down_method`**:`str`)\n",
       "\n",
       "Middle Out Reconciliation Class.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "This method is only available for strictly hierarchical structures. It anchors the base predictions in \n",
       "a middle level. The levels above the base predictions use the bottom-up approach, while the levels below \n",
       "use a top-down.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: Middle level.<br>\n",
       "`top_down_method`: One of `forecast_proportions`, `average_proportions` and `proportion_averages`.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MiddleOut, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"MiddleOut.reconcile\" class=\"doc_header\"><code>MiddleOut.reconcile</code><a href=\"__main__.py#L23\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>MiddleOut.reconcile</code>(**`S`**:`ndarray`, **`y_hat`**:`ndarray`, **`y_insample`**:`ndarray`, **`levels`**:`Dict`\\[`str`, `ndarray`\\])\n",
       "\n",
       "Middle Out Reconciliation Method.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`S`: Summing matrix of size (`base`, `bottom`).<br>\n",
       "`y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
       "`y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
       "`levels`: Each key is a level and each value its `S` indices.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MiddleOut.reconcile, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is only available for strictly hierarchical structures. It anchors the base predictions in a middle level. The levels above the base predictions use the bottom-up approach, while the levels below use a top-down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# we are able to recover forecasts \n",
    "# from middle out in this example\n",
    "# because the time series\n",
    "# share the same proportion\n",
    "# across time\n",
    "# but it is not a general case\n",
    "for method in ['forecast_proportions', 'average_proportions', 'proportion_averages']:\n",
    "    cls_middle_out = MiddleOut(level='level2', top_down_method=method)\n",
    "    test_close(\n",
    "        cls_middle_out(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y_insample=S @ y_bottom, \n",
    "            levels=levels\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def crossprod(x):\n",
    "    return x.T @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 4. MinTrace </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def min_trace(S: np.ndarray, \n",
    "              y_hat: np.ndarray,\n",
    "              y_insample: np.ndarray,\n",
    "              y_hat_insample: np.ndarray,\n",
    "              method: str):\n",
    "    # shape residuals_insample (n_hiers, obs)\n",
    "    res_methods = ['wls_var', 'mint_cov', 'mint_shrink']\n",
    "    if method in res_methods and y_insample is None and y_hat_insample is None:\n",
    "        raise ValueError(f\"For methods {', '.join(res_methods)} you need to pass residuals\")\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    if method == 'ols':\n",
    "        W = np.eye(n_hiers)\n",
    "    elif method == 'wls_struct':\n",
    "        W = np.diag(S @ np.ones((n_bottom,)))\n",
    "    elif method in res_methods:\n",
    "        #we need residuals with shape (obs, n_hiers)\n",
    "        residuals = (y_insample - y_hat_insample).T\n",
    "        n, _ = residuals.shape\n",
    "        masked_res = np.ma.array(residuals, mask=np.isnan(residuals))\n",
    "        covm = np.ma.cov(masked_res, rowvar=False, allow_masked=True).data\n",
    "        if method == 'wls_var':\n",
    "            W = np.diag(np.diag(covm))\n",
    "        elif method == 'mint_cov':\n",
    "            W = covm\n",
    "        elif method == 'mint_shrink':\n",
    "            tar = np.diag(np.diag(covm))\n",
    "            corm = cov2corr(covm)\n",
    "            xs = np.divide(residuals, np.sqrt(np.diag(covm)))\n",
    "            xs = xs[~np.isnan(xs).any(axis=1), :]\n",
    "            v = (1 / (n * (n - 1))) * (crossprod(xs ** 2) - (1 / n) * (crossprod(xs) ** 2))\n",
    "            np.fill_diagonal(v, 0)\n",
    "            corapn = cov2corr(tar)\n",
    "            d = (corm - corapn) ** 2\n",
    "            lmd = v.sum() / d.sum()\n",
    "            lmd = max(min(lmd, 1), 0)\n",
    "            W = lmd * tar + (1 - lmd) * covm\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "    \n",
    "    eigenvalues, _ = np.linalg.eig(W)\n",
    "    if any(eigenvalues < 1e-8):\n",
    "        raise Exception(f'min_trace ({method}) needs covariance matrix to be positive definite.')\n",
    "    \n",
    "    R = S.T @ np.linalg.pinv(W)\n",
    "    P = np.linalg.pinv(R @ S) @ R\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MinTrace:\n",
    "    \"\"\"MinTrace Reconciliation Class.\n",
    "    [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "    This reconciliation algorithm proposed by Wickramasuriya et al. depends on a generalized least squares estimator \n",
    "    and an estimator of the covariance matrix of the coherency errors $\\mathbf{W}_{h}$. The Min Trace algorithm \n",
    "    minimizes the squared errors for the coherent forecasts under an unbiasedness assumption; the solution has a \n",
    "    closed form.<br>\n",
    "    \n",
    "    $$\\mathbf{P}_{\\\\text{MinT}}=\\\\left(\\mathbf{S}^{\\intercal}\\mathbf{W}_{h}\\mathbf{S}\\\\right)^{-1}\n",
    "    \\mathbf{S}^{\\intercal}\\mathbf{W}^{-1}_{h}$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `method`: One of `ols`, `wls_struct`, `wls_var`, `mint_shrink`, `mint_co`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    - [Wickramasuriya, S. L., Athanasopoulos, G., & Hyndman, R. J. (2019). Optimal forecast reconciliation for\n",
    "    hierarchical and grouped time series through trace minimization. Journal of the American Statistical Association, \n",
    "    114 , 804–819. doi:10.1080/01621459.2018.1448825.](https://robjhyndman.com/publications/mint/).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            method: str \n",
    "        ):\n",
    "        self.method = method\n",
    "        \n",
    "    def reconcile(\n",
    "            self, \n",
    "            S: np.ndarray, \n",
    "            y_hat: np.ndarray, \n",
    "            y_insample: np.ndarray, \n",
    "            y_hat_insample: np.ndarray \n",
    "        ):\n",
    "        \"\"\"MinTrace Reconciliation Method.\n",
    "        [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `S`: Summing matrix of size (`base`, `bottom`).<br>\n",
    "        `y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
    "        `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "        `y_hat_insample`: Insample forecasts of size (`base`, `insample_size`).<br>\n",
    "\n",
    "        \"\"\"\n",
    "        return min_trace(S=S, y_hat=y_hat, \n",
    "                         y_insample=y_insample,\n",
    "                         y_hat_insample=y_hat_insample,\n",
    "                         method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"MinTrace\" class=\"doc_header\"><code>class</code> <code>MinTrace</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>MinTrace</code>(**`method`**:`str`)\n",
       "\n",
       "MinTrace Reconciliation Class.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "This reconciliation algorithm proposed by Wickramasuriya et al. depends on a generalized least squares estimator \n",
       "and an estimator of the covariance matrix of the coherency errors $\\mathbf{W}_{h}$. The Min Trace algorithm \n",
       "minimizes the squared errors for the coherent forecasts under an unbiasedness assumption; the solution has a \n",
       "closed form.<br>\n",
       "\n",
       "$$\\mathbf{P}_{\\text{MinT}}=\\left(\\mathbf{S}^{\\intercal}\\mathbf{W}_{h}\\mathbf{S}\\right)^{-1}\n",
       "\\mathbf{S}^{\\intercal}\\mathbf{W}^{-1}_{h}$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`method`: One of `ols`, `wls_struct`, `wls_var`, `mint_shrink`, `mint_co`.<br>\n",
       "\n",
       "**References:**<br>\n",
       "- [Wickramasuriya, S. L., Athanasopoulos, G., & Hyndman, R. J. (2019). Optimal forecast reconciliation for\n",
       "hierarchical and grouped time series through trace minimization. Journal of the American Statistical Association, \n",
       "114 , 804–819. doi:10.1080/01621459.2018.1448825.](https://robjhyndman.com/publications/mint/)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MinTrace, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"MinTrace.reconcile\" class=\"doc_header\"><code>MinTrace.reconcile</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>MinTrace.reconcile</code>(**`S`**:`ndarray`, **`y_hat`**:`ndarray`, **`y_insample`**:`ndarray`, **`y_hat_insample`**:`ndarray`)\n",
       "\n",
       "MinTrace Reconciliation Method.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`S`: Summing matrix of size (`base`, `bottom`).<br>\n",
       "`y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
       "`y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
       "`y_hat_insample`: Insample forecasts of size (`base`, `insample_size`).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(MinTrace.reconcile, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for method in ['ols', 'wls_struct', 'wls_var', 'mint_shrink']:\n",
    "    cls_min_trace = MinTrace(method=method)\n",
    "    test_close(\n",
    "        cls_min_trace(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom, \n",
    "            y_insample=S @ y_bottom,\n",
    "            y_hat_insample=S @ y_hat_bottom_insample\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )\n",
    "with ExceptionExpected(regex='min_trace (mint_cov)*'):\n",
    "    cls_min_trace = MinTrace(method='mint_cov')\n",
    "    cls_min_trace(\n",
    "        S=S, \n",
    "        y_hat=S @ y_hat_bottom, \n",
    "        y_insample=S @ y_bottom,\n",
    "        y_hat_insample=S @ y_hat_bottom_insample\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 5. Optimal Combination </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def optimal_combination(S: np.ndarray, \n",
    "                        y_hat: np.ndarray,\n",
    "                        method: str,\n",
    "                        y_insample: np.ndarray = None,\n",
    "                        y_hat_insample: np.ndarray = None):\n",
    "    \n",
    "    return min_trace(S=S, y_hat=y_hat, \n",
    "                         y_insample=y_insample,\n",
    "                         y_hat_insample=y_hat_insample,\n",
    "                         method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OptimalCombination:\n",
    "    \"\"\"Optimal Combination Reconciliation Class.\n",
    "    [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "    This reconciliation algorithm was proposed by Hyndman et al. 2011, the method uses generalized least squares \n",
    "    estimator using the coherency errors covariance matrix. Consider the covariance of the base forecast \n",
    "    $\\\\textrm{Var}(\\epsilon_{h}) = \\Sigma_{h}$, the $\\mathbf{P}$ matrix of this method is defined by:\n",
    "\n",
    "    $$ \\mathbf{P} = \\\\left(\\mathbf{S}^{\\intercal}\\Sigma_{h}^{\\dagger}\\mathbf{S}\\\\right)^{-1}\\mathbf{S}^{\\intercal}\\Sigma^{\\dagger}_{h}$$\n",
    "\n",
    "    where $\\Sigma_{h}^{\\dagger}$ denotes the variance pseudo-inverse. The method was later proven equivalent to \n",
    "    `MinTrace` variants.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `method`: Allowed Optimal Combination Methods: 'ols', 'wls_struct'.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    - [Rob J. Hyndman, Roman A. Ahmed, George Athanasopoulos, Han Lin Shang. \"Optimal Combination Forecasts for \n",
    "    Hierarchical Time Series\" (2010).](https://robjhyndman.com/papers/Hierarchical6.pdf).<br>\n",
    "    - [Shanika L. Wickramasuriya, George Athanasopoulos and Rob J. Hyndman. \"Optimal Combination Forecasts for \n",
    "    Hierarchical Time Series\" (2010).](https://robjhyndman.com/papers/MinT.pdf).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            method: str\n",
    "        ):\n",
    "        comb_methods = ['ols', 'wls_struct']\n",
    "        if method not in comb_methods:\n",
    "            raise ValueError(f\"Optimal Combination class does not support method: \\\"{method}\\\"\")\n",
    "        \n",
    "        self.method = method\n",
    "    \n",
    "    def reconcile(\n",
    "            self,\n",
    "            S: np.ndarray, \n",
    "            y_hat: np.ndarray, \n",
    "            y_insample: np.ndarray = None, \n",
    "            y_hat_insample: np.ndarray = None \n",
    "        ):\n",
    "        \"\"\"Optimal Combination Reconciliation Method.\n",
    "        [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `S`: Summing matrix of size (`base`, `bottom`).<br>\n",
    "        `y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
    "        `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "        `y_hat_insample`: Insample forecasts of size (`base`, `insample_size`).<br>\n",
    "\n",
    "        \"\"\"\n",
    "        return optimal_combination(S=S, \n",
    "                                   y_hat=y_hat, \n",
    "                                   y_insample=y_insample, \n",
    "                                   y_hat_insample=y_hat_insample, \n",
    "                                   method=self.method)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"OptimalCombination\" class=\"doc_header\"><code>class</code> <code>OptimalCombination</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>OptimalCombination</code>(**`method`**:`str`)\n",
       "\n",
       "Optimal Combination Reconciliation Class.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "This reconciliation algorithm was proposed by Hyndman et al. 2011, the method uses generalized least squares \n",
       "estimator using the coherency errors covariance matrix. Consider the covariance of the base forecast \n",
       "$   extrm{Var}(\\epsilon_{h}) = \\Sigma_{h}$, the $\\mathbf{P}$ matrix of this method is defined by:\n",
       "\n",
       "$$ \\mathbf{P} = \\left(\\mathbf{S}^{\\intercal}\\Sigma_{h}^{\\dagger}\\mathbf{S}\r",
       "ight)^{-1}\\mathbf{S}^{\\intercal}\\Sigma^{\\dagger}_{h}$$\n",
       "\n",
       "where $\\Sigma_{h}^{\\dagger}$ denotes the variance pseudo-inverse. The method was later proven equivalent to \n",
       "[`MinTrace`](/hierarchicalforecast/methods.html#MinTrace) variants.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`method`: Allowed Optimal Combination Methods: 'ols', 'wls_struct'.<br>\n",
       "\n",
       "**References:**<br>\n",
       "- [Rob J. Hyndman, Roman A. Ahmed, George Athanasopoulos, Han Lin Shang. \"Optimal Combination Forecasts for \n",
       "Hierarchical Time Series\" (2010).](https://robjhyndman.com/papers/Hierarchical6.pdf).<br>\n",
       "- [Shanika L. Wickramasuriya, George Athanasopoulos and Rob J. Hyndman. \"Optimal Combination Forecasts for \n",
       "Hierarchical Time Series\" (2010).](https://robjhyndman.com/papers/MinT.pdf)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(OptimalCombination, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"OptimalCombination.reconcile\" class=\"doc_header\"><code>OptimalCombination.reconcile</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>OptimalCombination.reconcile</code>(**`S`**:`ndarray`, **`y_hat`**:`ndarray`, **`y_insample`**:`ndarray`=*`None`*, **`y_hat_insample`**:`ndarray`=*`None`*)\n",
       "\n",
       "Optimal Combination Reconciliation Method.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`S`: Summing matrix of size (`base`, `bottom`).<br>\n",
       "`y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
       "`y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
       "`y_hat_insample`: Insample forecasts of size (`base`, `insample_size`).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(OptimalCombination.reconcile, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for method in ['ols', 'wls_struct']:\n",
    "    cls_optimal_combination = OptimalCombination(method=method)\n",
    "    test_close(\n",
    "        cls_optimal_combination(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom \n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def lasso(X: np.ndarray, y: np.ndarray, \n",
    "          lambda_reg: float, max_iters: int = 1_000,\n",
    "          tol: float = 1e-4):\n",
    "    # lasso cyclic coordinate descent\n",
    "    n, feats = X.shape\n",
    "    norms = (X ** 2).sum(axis=0)\n",
    "    beta = np.zeros(feats, dtype=np.float32)\n",
    "    beta_changes = np.zeros(feats, dtype=np.float32)\n",
    "    residuals = y.copy()\n",
    "    \n",
    "    for it in range(max_iters):\n",
    "        for i, betai in enumerate(beta):\n",
    "            # is feature is close to zero, we \n",
    "            # continue to the next.\n",
    "            # in this case is optimal betai= 0\n",
    "            if abs(norms[i]) < 1e-8:\n",
    "                continue\n",
    "            xi = X[:, i]\n",
    "            #we calculate the normalized derivative\n",
    "            rho = betai + xi.flatten().dot(residuals) / norms[i] #(norms[i] + 1e-3)\n",
    "            #soft threshold\n",
    "            beta[i] = np.sign(rho) * max(np.abs(rho) - lambda_reg * n / norms[i], 0.)#(norms[i] + 1e-3), 0.)\n",
    "            beta_changes[i] = np.abs(betai - beta[i])\n",
    "            if beta[i] != betai:\n",
    "                residuals += (betai - beta[i]) * xi\n",
    "        if max(beta_changes) < tol:\n",
    "            break\n",
    "    #print(it)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 6. ERM </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def erm(S: np.ndarray,\n",
    "        y_hat: np.ndarray,\n",
    "        y_insample: np.ndarray,\n",
    "        y_hat_insample: np.ndarray,\n",
    "        idx_bottom: np.ndarray,\n",
    "        method: str,\n",
    "        lambda_reg: float = 1e-3):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    # y_hat_insample shape (n_hiers, obs)\n",
    "    # remove obs with nan values\n",
    "    nan_idx = np.isnan(y_hat_insample).any(axis=0)\n",
    "    y_insample = y_insample[:, ~nan_idx]\n",
    "    y_hat_insample = y_hat_insample[:, ~nan_idx]\n",
    "    #only using h validation steps to avoid \n",
    "    #computational burden\n",
    "    #print(y_hat.shape)\n",
    "    h = min(y_hat.shape[1], y_hat_insample.shape[1])\n",
    "    y_hat_insample = y_hat_insample[:, -h:] # shape (h, n_hiers)\n",
    "    y_insample = y_insample[:, -h:]\n",
    "    if method == 'closed':\n",
    "        B = np.linalg.inv(S.T @ S) @ S.T @ y_insample\n",
    "        B = B.T\n",
    "        P = np.linalg.pinv(y_hat_insample.T) @ B\n",
    "        P = P.T\n",
    "    elif method in ['reg', 'reg_bu']:\n",
    "        X = np.kron(np.array(S, order='F'), np.array(y_hat_insample.T, order='F'))\n",
    "        Pbu = np.zeros_like(S)\n",
    "        if method == 'reg_bu':\n",
    "            Pbu[idx_bottom] = S[idx_bottom]\n",
    "        Pbu = Pbu.T\n",
    "        Y = y_insample.T.flatten(order='F') - X @ Pbu.T.flatten(order='F')\n",
    "        if lambda_reg is None:\n",
    "            lambda_reg = np.max(np.abs(X.T.dot(Y)))\n",
    "        P = lasso(X, Y, lambda_reg)\n",
    "        P = P + Pbu.T.flatten(order='F')\n",
    "        P = P.reshape(-1, n_bottom, order='F').T\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "        \n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ERM:\n",
    "    \"\"\"Optimal Combination Reconciliation Class.\n",
    "    [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "    The Empirical Risk Minimization reconciliation strategy relaxes the unbiasedness assumptions from\n",
    "    previous reconciliation methods like MinT and optimizes square errors between the reconciled predictions\n",
    "    and the validation data to obtain an optimal reconciliation matrix P.\n",
    "\n",
    "    The exact solution for $\\mathbf{P}$ (`method='closed'`) follows the expression:\n",
    "\n",
    "    $$\\mathbf{P}^{*} = \\\\left(\\mathbf{S}^{\\intercal}\\mathbf{S}\\\\right)^{-1}\\mathbf{Y}^{\\intercal}\\hat{\\mathbf{Y}}\\\\left(\\hat{\\mathbf{Y}}\\hat{\\mathbf{Y}}\\\\right)^{-1}$$\n",
    "\n",
    "    The alternative Lasso regularized $\\mathbf{P}$ solution (`method='reg_bu'`) is useful when the observations \n",
    "    of validation data is limited or the exact solution has low numerical stability.\n",
    "\n",
    "    $$\\mathbf{P}^{*} = \\\\text{argmin}_{\\mathbf{P}} ||\\mathbf{Y}-\\mathbf{S} \\mathbf{P} \\hat{Y} ||^{2}_{2} + \\lambda ||\\mathbf{P}-\\mathbf{P}_{\\\\text{BU}}||_{1}$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `method`: one of `closed`, `reg` and `reg_bu`.<br>\n",
    "    `lambda_reg`: l1 regularizer for `reg` and `reg_bu`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    - [Ben Taieb, S., & Koo, B. (2019). Regularized regression for hierarchical forecasting without \n",
    "    unbiasedness conditions. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge \n",
    "    Discovery & Data Mining KDD '19 (p. 1337{1347). New York, NY, USA: Association for Computing Machinery.]\n",
    "    (https://doi.org/10.1145/3292500.3330976).<br>\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            method: str, \n",
    "            lambda_reg: float = 1e-2 \n",
    "        ):\n",
    "        self.method = method\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "    def reconcile(\n",
    "            self, \n",
    "            S: np.ndarray, \n",
    "            y_hat: np.ndarray, \n",
    "            y_insample: np.ndarray, \n",
    "            y_hat_insample: np.ndarray, \n",
    "            idx_bottom: np.ndarray \n",
    "        ):\n",
    "        \"\"\"ERM Reconciliation Method.\n",
    "        [Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `S`: Summing matrix of size (`base`, `bottom`).<br>\n",
    "        `y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
    "        `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "        `y_hat_insample`: Insample forecasts of size (`base`, `insample_size`).<br>\n",
    "        `idx_bottom`: Indices corresponding to the bottom level of `S`, size (`bottom`).<br>\n",
    "        \"\"\"\n",
    "        return erm(S=S, y_hat=y_hat, \n",
    "                   y_insample=y_insample,\n",
    "                   y_hat_insample=y_hat_insample,\n",
    "                   idx_bottom=idx_bottom,\n",
    "                   method=self.method, lambda_reg=self.lambda_reg)\n",
    "    \n",
    "    __call__ = reconcile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"ERM\" class=\"doc_header\"><code>class</code> <code>ERM</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>ERM</code>(**`method`**:`str`, **`lambda_reg`**:`float`=*`0.01`*)\n",
       "\n",
       "Optimal Combination Reconciliation Class.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "The Empirical Risk Minimization reconciliation strategy relaxes the unbiasedness assumptions from\n",
       "previous reconciliation methods like MinT and optimizes square errors between the reconciled predictions\n",
       "and the validation data to obtain an optimal reconciliation matrix P.\n",
       "\n",
       "The exact solution for $\\mathbf{P}$ (`method='closed'`) follows the expression:\n",
       "\n",
       "$$\\mathbf{P}^{*} = \\left(\\mathbf{S}^{\\intercal}\\mathbf{S}\r",
       "ight)^{-1}\\mathbf{Y}^{\\intercal}\\hat{\\mathbf{Y}}\\left(\\hat{\\mathbf{Y}}\\hat{\\mathbf{Y}}\r",
       "ight)^{-1}$$\n",
       "\n",
       "The alternative Lasso regularized $\\mathbf{P}$ solution (`method='reg_bu'`) is useful when the observations \n",
       "of validation data is limited or the exact solution has low numerical stability.\n",
       "\n",
       "$$\\mathbf{P}^{*} =  ext{argmin}_{\\mathbf{P}} ||\\mathbf{Y}-\\mathbf{S} \\mathbf{P} \\hat{Y} ||^{2}_{2} + \\lambda ||\\mathbf{P}-\\mathbf{P}_{      ext{BU}}||_{1}$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`method`: one of `closed`, `reg` and `reg_bu`.<br>\n",
       "`lambda_reg`: l1 regularizer for `reg` and `reg_bu`.<br>\n",
       "\n",
       "**References:**<br>\n",
       "- [Ben Taieb, S., & Koo, B. (2019). Regularized regression for hierarchical forecasting without \n",
       "unbiasedness conditions. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge \n",
       "Discovery & Data Mining KDD '19 (p. 1337{1347). New York, NY, USA: Association for Computing Machinery.]\n",
       "(https://doi.org/10.1145/3292500.3330976).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ERM, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"ERM.reconcile\" class=\"doc_header\"><code>ERM.reconcile</code><a href=\"__main__.py#L37\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>ERM.reconcile</code>(**`S`**:`ndarray`, **`y_hat`**:`ndarray`, **`y_insample`**:`ndarray`, **`y_hat_insample`**:`ndarray`, **`idx_bottom`**:`ndarray`)\n",
       "\n",
       "ERM Reconciliation Method.\n",
       "[Source code](https://github.com/dluuo/hierarchicalforecast/blob/main/hierarchicalforecast/methods.py).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`S`: Summing matrix of size (`base`, `bottom`).<br>\n",
       "`y_hat`: Forecast values of size (`base`, `horizon`).<br>\n",
       "`y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
       "`y_hat_insample`: Insample forecasts of size (`base`, `insample_size`).<br>\n",
       "`idx_bottom`: Indices corresponding to the bottom level of `S`, size (`bottom`).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ERM.reconcile, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for method in ['reg_bu']:\n",
    "    cls_erm = ERM(method=method, lambda_reg=None)\n",
    "    test_close(\n",
    "        cls_erm(\n",
    "            S=S, \n",
    "            y_hat=S @ y_hat_bottom,\n",
    "            y_insample=S @ y_bottom,\n",
    "            y_hat_insample=S @ y_hat_bottom_insample,\n",
    "            idx_bottom=idx_bottom\n",
    "        ),\n",
    "        S @ y_hat_bottom\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> References </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom Up\n",
    "-  [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition\". OTexts: Melbourne, Australia. OTexts.com/fpp3  Accessed on July 2022](https://otexts.com/fpp3/).\n",
    "\n",
    "- [Shmueli, G., & Lichtendahl Jr, K. C. (2016). \"Practical time series forecasting with R: A hands-on guide\". Axelrod Schnall Publishers](https://www.forecastingbook.com/).\n",
    "\n",
    "#### Top Down\n",
    "- [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "neuralforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
