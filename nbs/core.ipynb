{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HierarchicalForecast contains pure Python implementations of hierarchical reconciliation methods as well as a `core.HierarchicalReconciliation` wrapper class that enables easy interaction with these methods through pandas DataFrames containing the hierarchical time series and the base predictions.\n",
    "\n",
    "The `core.HierarchicalReconciliation` reconciliation class operates with the hierarchical time series pd.DataFrame `Y_df`, the base predictions pd.DataFrame `Y_hat_df`, the aggregation constraints matrix `S`. For more information on the creation of aggregation constraints matrix see the utils [aggregation method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "import copy\n",
    "from inspect import signature\n",
    "from scipy.stats import norm\n",
    "from scipy import sparse\n",
    "from typing import Callable, Dict, List, Optional\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_close, test_eq, test_fail\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _build_fn_name(fn) -> str:\n",
    "    fn_name = type(fn).__name__\n",
    "    func_params = fn.__dict__\n",
    "\n",
    "    # Take default parameter out of names\n",
    "    args_to_remove = ['insample', 'num_threads']\n",
    "    if not func_params.get('nonnegative', False):\n",
    "        args_to_remove.append('nonnegative')\n",
    "\n",
    "    if fn_name == 'MinTrace' and \\\n",
    "        func_params['method']=='mint_shrink':\n",
    "        if func_params['mint_shr_ridge'] == 2e-8:\n",
    "            args_to_remove += ['mint_shr_ridge']\n",
    "\n",
    "    func_params = [f'{name}-{value}' for name, value in func_params.items() if name not in args_to_remove]\n",
    "    if func_params:\n",
    "        fn_name += '_' + '_'.join(func_params)\n",
    "    return fn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test fn name\n",
    "from hierarchicalforecast.methods import BottomUp, MinTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_build_fn_name(BottomUp()), 'BottomUp')\n",
    "test_eq(\n",
    "    _build_fn_name(MinTrace(method='ols')), \n",
    "    'MinTrace_method-ols'\n",
    ")\n",
    "test_eq(\n",
    "    _build_fn_name(MinTrace(method='ols', nonnegative=True)), \n",
    "    'MinTrace_method-ols_nonnegative-True'\n",
    ")\n",
    "test_eq(\n",
    "    _build_fn_name(MinTrace(method='mint_shr')), \n",
    "    'MinTrace_method-mint_shr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core.HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _reverse_engineer_sigmah(Y_hat_df, y_hat, model_name):\n",
    "    \"\"\"\n",
    "    This function assumes that the model creates prediction intervals\n",
    "    under a normality with the following the Equation:\n",
    "    $\\hat{y}_{t+h} + c \\hat{sigma}_{h}$\n",
    "\n",
    "    In the future, we might deprecate this function in favor of a \n",
    "    direct usage of an estimated $\\hat{sigma}_{h}$\n",
    "    \"\"\"\n",
    "\n",
    "    drop_cols = ['ds']\n",
    "    if 'y' in Y_hat_df.columns:\n",
    "        drop_cols.append('y')\n",
    "    if model_name+'-median' in Y_hat_df.columns:\n",
    "        drop_cols.append(model_name+'-median')\n",
    "    model_names = Y_hat_df.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "    pi_model_names = [name for name in model_names if ('-lo' in name or '-hi' in name)]\n",
    "    pi_model_name = [pi_name for pi_name in pi_model_names if model_name in pi_name]\n",
    "    pi = len(pi_model_name) > 0\n",
    "\n",
    "    n_series = len(Y_hat_df.index.unique())\n",
    "\n",
    "    if not pi:\n",
    "        raise Exception(f'Please include `{model_name}` prediction intervals in `Y_hat_df`')\n",
    "\n",
    "    pi_col = pi_model_name[0]\n",
    "    sign = -1 if 'lo' in pi_col else 1\n",
    "    level_col = re.findall('[\\d]+[.,\\d]+|[\\d]*[.][\\d]+|[\\d]+', pi_col)\n",
    "    level_col = float(level_col[-1])\n",
    "    z = norm.ppf(0.5 + level_col / 200)\n",
    "    sigmah = Y_hat_df[pi_col].values.reshape(n_series,-1)\n",
    "    sigmah = sign * (sigmah - y_hat) / z\n",
    "\n",
    "    return sigmah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HierarchicalReconciliation:\n",
    "    \"\"\"Hierarchical Reconciliation Class.\n",
    "\n",
    "    The `core.HierarchicalReconciliation` class allows you to efficiently fit multiple \n",
    "    HierarchicaForecast methods for a collection of time series and base predictions stored in \n",
    "    pandas DataFrames. The `Y_df` dataframe identifies series and datestamps with the unique_id and ds columns while the\n",
    "    y column denotes the target time series variable. The `Y_h` dataframe stores the base predictions, \n",
    "    example ([AutoARIMA](https://nixtla.github.io/statsforecast/models.html#autoarima), [ETS](https://nixtla.github.io/statsforecast/models.html#autoets), etc.).\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `reconcilers`: A list of instantiated classes of the [reconciliation methods](https://nixtla.github.io/hierarchicalforecast/methods.html) module .<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Rob J. Hyndman and George Athanasopoulos (2018). \\\"Forecasting principles and practice, Hierarchical and Grouped Series\\\".](https://otexts.com/fpp3/hierarchical.html)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reconcilers: List[Callable]):\n",
    "        self.reconcilers = reconcilers\n",
    "        self.orig_reconcilers = copy.deepcopy(reconcilers) # TODO: elegant solution\n",
    "        self.insample = any([method.insample for method in reconcilers])\n",
    "    \n",
    "    def _prepare_fit(self,\n",
    "                     Y_hat_df: pd.DataFrame,\n",
    "                     S_df: pd.DataFrame,\n",
    "                     Y_df: Optional[pd.DataFrame],\n",
    "                     tags: Dict[str, np.ndarray],\n",
    "                     level: Optional[List[int]] = None,\n",
    "                     intervals_method: str = 'normality',\n",
    "                     sort_df: bool = True):\n",
    "        \"\"\"\n",
    "        Performs preliminary wrangling and protections\n",
    "        \"\"\"\n",
    "        #-------------------------------- Match Y_hat/Y/S index order --------------------------------#\n",
    "        if sort_df:\n",
    "            Y_hat_df = Y_hat_df.reset_index()\n",
    "            Y_hat_df.unique_id = Y_hat_df.unique_id.astype('category')\n",
    "            Y_hat_df.unique_id = Y_hat_df.unique_id.cat.set_categories(S_df.index)\n",
    "            Y_hat_df = Y_hat_df.sort_values(by=['unique_id', 'ds'])\n",
    "            Y_hat_df = Y_hat_df.set_index('unique_id')\n",
    "\n",
    "            if Y_df is not None:\n",
    "                Y_df = Y_df.reset_index()\n",
    "                Y_df.unique_id = Y_df.unique_id.astype('category')\n",
    "                Y_df.unique_id = Y_df.unique_id.cat.set_categories(S_df.index)\n",
    "                Y_df = Y_df.sort_values(by=['unique_id', 'ds'])\n",
    "                Y_df = Y_df.set_index('unique_id')\n",
    "\n",
    "            S_df.index = pd.CategoricalIndex(S_df.index, categories=S_df.index)\n",
    "\n",
    "        #----------------------------------- Check Input's Validity ----------------------------------#\n",
    "        # Check input's validity\n",
    "        if intervals_method not in ['normality', 'bootstrap', 'permbu']:\n",
    "            raise ValueError(f'Unkwon interval method: {intervals_method}')\n",
    "\n",
    "        if self.insample or (intervals_method in ['bootstrap', 'permbu']):\n",
    "            if Y_df is None:\n",
    "                raise Exception('you need to pass `Y_df`')\n",
    "        \n",
    "        # Protect level list\n",
    "        if (level is not None):\n",
    "            level_outside_domain = np.any((np.array(level) < 0)|(np.array(level) >= 100 ))\n",
    "            if level_outside_domain and (intervals_method in ['normality', 'permbu']):\n",
    "                raise Exception('Level outside domain, send `level` list in [0,100)')\n",
    "\n",
    "        # Declare output names\n",
    "        drop_cols = ['ds', 'y'] if 'y' in Y_hat_df.columns else ['ds']\n",
    "        model_names = Y_hat_df.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "\n",
    "        # Ensure numeric columns\n",
    "        if not len(Y_hat_df[model_names].select_dtypes(include='number').columns) == len(Y_hat_df[model_names].columns):\n",
    "            raise Exception('`Y_hat_df`s columns contain non numeric types')\n",
    "            \n",
    "        #Ensure no null values\n",
    "        if Y_hat_df[model_names].isnull().values.any():\n",
    "            raise Exception('`Y_hat_df` contains null values')\n",
    "        \n",
    "        pi_model_names = [name for name in model_names if ('-lo' in name or '-hi' in name or '-median' in name)]\n",
    "        model_names = [name for name in model_names if name not in pi_model_names]\n",
    "        \n",
    "        # TODO: Complete y_hat_insample protection\n",
    "        if intervals_method in ['bootstrap', 'permbu']:\n",
    "            if not (set(model_names) <= set(Y_df.columns)):\n",
    "                raise Exception('Check `Y_hat_df`s models are included in `Y_df` columns')\n",
    "\n",
    "        uids = Y_hat_df.index.unique()\n",
    "\n",
    "        # Check Y_hat_df\\S_df series difference\n",
    "        S_diff  = len(S_df.index.difference(uids))\n",
    "        Y_hat_diff = len(Y_hat_df.index.difference(S_df.index.unique()))\n",
    "        if S_diff > 0 or Y_hat_diff > 0:\n",
    "            raise Exception(f'Check `S_df`, `Y_hat_df` series difference, S\\Y_hat={S_diff}, Y_hat\\S={Y_hat_diff}')\n",
    "\n",
    "        if Y_df is not None:\n",
    "            # Check Y_hat_df\\Y_df series difference\n",
    "            Y_diff  = len(Y_df.index.difference(uids))\n",
    "            Y_hat_diff = len(Y_hat_df.index.difference(Y_df.index.unique()))\n",
    "            if Y_diff > 0 or Y_hat_diff > 0:\n",
    "                raise Exception(f'Check `Y_hat_df`, `Y_df` series difference, Y_hat\\Y={Y_hat_diff}, Y\\Y_hat={Y_diff}')\n",
    "\n",
    "        # Same Y_hat_df/S_df/Y_df's unique_id order to prevent errors\n",
    "        S_df = S_df.loc[uids]\n",
    "\n",
    "        return Y_hat_df, S_df, Y_df, model_names\n",
    "\n",
    "    def reconcile(self, \n",
    "                  Y_hat_df: pd.DataFrame,\n",
    "                  S: pd.DataFrame,\n",
    "                  tags: Dict[str, np.ndarray],\n",
    "                  Y_df: Optional[pd.DataFrame] = None,\n",
    "                  level: Optional[List[int]] = None,\n",
    "                  intervals_method: str = 'normality',\n",
    "                  num_samples: int = -1,\n",
    "                  seed: int = 0,\n",
    "                  sort_df: bool = True,\n",
    "                  is_balanced: bool = False,\n",
    "        ):\n",
    "        \"\"\"Hierarchical Reconciliation Method.\n",
    "\n",
    "        The `reconcile` method is analogous to SKLearn `fit_predict` method, it \n",
    "        applies different reconciliation techniques instantiated in the `reconcilers` list.\n",
    "\n",
    "        Most reconciliation methods can be described by the following convenient \n",
    "        linear algebra notation:\n",
    "\n",
    "        $$\\\\tilde{\\mathbf{y}}_{[a,b],\\\\tau} = \\mathbf{S}_{[a,b][b]} \\mathbf{P}_{[b][a,b]} \\hat{\\mathbf{y}}_{[a,b],\\\\tau}$$\n",
    "\n",
    "        where $a, b$ represent the aggregate and bottom levels, $\\mathbf{S}_{[a,b][b]}$ contains\n",
    "        the hierarchical aggregation constraints, and $\\mathbf{P}_{[b][a,b]}$ varies across \n",
    "        reconciliation methods. The reconciled predictions are $\\\\tilde{\\mathbf{y}}_{[a,b],\\\\tau}$, and the \n",
    "        base predictions $\\hat{\\mathbf{y}}_{[a,b],\\\\tau}$.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
    "        `Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.<br>\n",
    "        If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
    "        `S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
    "        `tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
    "        `level`: positive float list [0,100), confidence levels for prediction intervals.<br>\n",
    "        `intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
    "        `num_samples`: int=-1, if positive return that many probabilistic coherent samples.\n",
    "        `seed`: int=0, random seed for numpy generator's replicability.<br>\n",
    "        `sort_df` : bool (default=True), if True, sort `df` by [`unique_id`,`ds`].<br>\n",
    "        `is_balanced`: bool=False, wether `Y_df` is balanced, set it to True to speed things up if `Y_df` is balanced.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `Y_tilde_df`: pd.DataFrame, with reconciled predictions.\n",
    "        \"\"\"\n",
    "        # Check input's validity and sort dataframes\n",
    "        Y_hat_df, S_df, Y_df, self.model_names = \\\n",
    "                    self._prepare_fit(Y_hat_df=Y_hat_df,\n",
    "                                      S_df=S,\n",
    "                                      Y_df=Y_df,\n",
    "                                      tags=tags,\n",
    "                                      level=level,\n",
    "                                      intervals_method=intervals_method,\n",
    "                                      sort_df=sort_df)\n",
    "\n",
    "        # Initialize reconciler arguments\n",
    "        reconciler_args = dict(\n",
    "            idx_bottom=S_df.index.get_indexer(S.columns),\n",
    "            tags={key: S_df.index.get_indexer(val) for key, val in tags.items()}\n",
    "        )\n",
    "\n",
    "        any_sparse = any([method.is_sparse_method for method in self.reconcilers])\n",
    "        if any_sparse:\n",
    "            try:\n",
    "                S_for_sparse = sparse.csr_matrix(S_df.sparse.to_coo())\n",
    "            except AttributeError:\n",
    "                warnings.warn('Using dense S matrix for sparse reconciliation method.')\n",
    "                S_for_sparse = S_df.values.astype(np.float32)\n",
    "\n",
    "        if Y_df is not None:\n",
    "            if is_balanced:\n",
    "                y_insample = Y_df['y'].values.reshape(len(S_df), -1).astype(np.float32)\n",
    "            else:\n",
    "                y_insample = Y_df.pivot(columns='ds', values='y').loc[S_df.index].values.astype(np.float32)\n",
    "            reconciler_args['y_insample'] = y_insample\n",
    "\n",
    "        Y_tilde_df= Y_hat_df.copy()\n",
    "        start = time.time()\n",
    "        self.execution_times = {}\n",
    "        self.level_names = {}\n",
    "        self.sample_names = {}\n",
    "        for reconcile_fn, name_copy in zip(self.reconcilers, self.orig_reconcilers):\n",
    "            reconcile_fn_name = _build_fn_name(name_copy)\n",
    "\n",
    "            if reconcile_fn.is_sparse_method:\n",
    "                reconciler_args[\"S\"] = S_for_sparse\n",
    "            else:\n",
    "                reconciler_args[\"S\"] = S_df.values.astype(np.float32)\n",
    "\n",
    "            has_fitted = 'y_hat_insample' in signature(reconcile_fn).parameters\n",
    "            has_level = 'level' in signature(reconcile_fn).parameters\n",
    "\n",
    "            for model_name in self.model_names:\n",
    "                recmodel_name = f'{model_name}/{reconcile_fn_name}'\n",
    "                y_hat = Y_hat_df[model_name].values.reshape(len(S_df), -1).astype(np.float32)\n",
    "                reconciler_args['y_hat'] = y_hat\n",
    "\n",
    "                if (self.insample and has_fitted) or intervals_method in ['bootstrap', 'permbu']:\n",
    "                    if is_balanced:\n",
    "                        y_hat_insample = Y_df[model_name].values.reshape(len(S_df), -1).astype(np.float32)\n",
    "                    else:\n",
    "                        y_hat_insample = Y_df.pivot(columns='ds', values=model_name).loc[S_df.index].values.astype(np.float32)\n",
    "                    reconciler_args['y_hat_insample'] = y_hat_insample\n",
    "\n",
    "                if has_level and (level is not None):\n",
    "                    if intervals_method in ['normality', 'permbu']:\n",
    "                        sigmah = _reverse_engineer_sigmah(Y_hat_df=Y_hat_df,\n",
    "                                    y_hat=y_hat, model_name=model_name)\n",
    "                        reconciler_args['sigmah'] = sigmah\n",
    "\n",
    "                    reconciler_args['intervals_method'] = intervals_method\n",
    "                    reconciler_args['num_samples'] = 200 # TODO: solve duplicated num_samples\n",
    "                    reconciler_args['seed'] = seed\n",
    "\n",
    "                # Mean and Probabilistic reconciliation\n",
    "                kwargs = [key for key in signature(reconcile_fn).parameters if key in reconciler_args.keys()]\n",
    "                kwargs = {key: reconciler_args[key] for key in kwargs}\n",
    "                \n",
    "                if (level is not None) and (num_samples > 0):\n",
    "                    # Store reconciler's memory to generate samples\n",
    "                    reconciler = reconcile_fn.fit(**kwargs)\n",
    "                    fcsts_model = reconciler.predict(S=reconciler_args['S'], \n",
    "                                                     y_hat=reconciler_args['y_hat'], level=level)\n",
    "                else:\n",
    "                    # Memory efficient reconciler's fit_predict\n",
    "                    fcsts_model = reconcile_fn(**kwargs, level=level)\n",
    "\n",
    "                # Parse final outputs\n",
    "                Y_tilde_df[recmodel_name] = fcsts_model['mean'].flatten()\n",
    "                if intervals_method in ['bootstrap', 'normality', 'permbu'] and level is not None:\n",
    "                    level.sort()\n",
    "                    lo_names = [f'{recmodel_name}-lo-{lv}' for lv in reversed(level)]\n",
    "                    hi_names = [f'{recmodel_name}-hi-{lv}' for lv in level]\n",
    "                    self.level_names[recmodel_name] = lo_names + hi_names\n",
    "                    sorted_quantiles = np.reshape(fcsts_model['quantiles'], (len(Y_tilde_df),-1))\n",
    "                    intervals_df = pd.DataFrame(sorted_quantiles, index=Y_tilde_df.index,\n",
    "                                                columns=self.level_names[recmodel_name])\n",
    "                    Y_tilde_df= pd.concat([Y_tilde_df, intervals_df], axis=1)\n",
    "\n",
    "                    if num_samples > 0:\n",
    "                        samples = reconciler.sample(num_samples=num_samples)\n",
    "                        self.sample_names[recmodel_name] = [f'{recmodel_name}-sample-{i}' for i in range(num_samples)]\n",
    "                        samples = np.reshape(samples, (len(Y_tilde_df),-1))\n",
    "                        samples_df = pd.DataFrame(samples, index=Y_tilde_df.index,\n",
    "                                                  columns=self.sample_names[recmodel_name])\n",
    "                        Y_tilde_df= pd.concat([Y_tilde_df, samples_df], axis=1)\n",
    "\n",
    "                    del sorted_quantiles\n",
    "                    del intervals_df\n",
    "                if self.insample and has_fitted:\n",
    "                    del y_hat_insample\n",
    "                gc.collect()\n",
    "\n",
    "                end = time.time()\n",
    "                self.execution_times[f'{model_name}/{reconcile_fn_name}'] = (end - start)\n",
    "\n",
    "        return Y_tilde_df\n",
    "\n",
    "    def bootstrap_reconcile(self,\n",
    "                            Y_hat_df: pd.DataFrame,\n",
    "                            S_df: pd.DataFrame,\n",
    "                            tags: Dict[str, np.ndarray],\n",
    "                            Y_df: Optional[pd.DataFrame] = None,\n",
    "                            level: Optional[List[int]] = None,\n",
    "                            intervals_method: str = 'normality',\n",
    "                            num_samples: int = -1,\n",
    "                            num_seeds: int = 1,\n",
    "                            sort_df: bool = True):\n",
    "        \"\"\"Bootstraped Hierarchical Reconciliation Method.\n",
    "\n",
    "        Applies N times, based on different random seeds, the `reconcile` method \n",
    "        for the different reconciliation techniques instantiated in the `reconcilers` list. \n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
    "        `Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.<br>\n",
    "        If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
    "        `S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
    "        `tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
    "        `level`: positive float list [0,100), confidence levels for prediction intervals.<br>\n",
    "        `intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
    "        `num_samples`: int=-1, if positive return that many probabilistic coherent samples.\n",
    "        `num_seeds`: int=1, random seed for numpy generator's replicability.<br>\n",
    "        `sort_df` : bool (default=True), if True, sort `df` by [`unique_id`,`ds`].<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `Y_bootstrap_df`: pd.DataFrame, with bootstraped reconciled predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check input's validity and sort dataframes\n",
    "        Y_hat_df, S_df, Y_df, self.model_names = \\\n",
    "                    self._prepare_fit(Y_hat_df=Y_hat_df,\n",
    "                                      S_df=S_df,\n",
    "                                      Y_df=Y_df,\n",
    "                                      tags=tags,\n",
    "                                      intervals_method=intervals_method,\n",
    "                                      sort_df=sort_df)\n",
    "\n",
    "        # Bootstrap reconciled predictions\n",
    "        Y_tilde_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            Y_tilde_df = self.reconcile(Y_hat_df=Y_hat_df,\n",
    "                                        S=S_df,\n",
    "                                        tags=tags,\n",
    "                                        Y_df=Y_df,\n",
    "                                        level=level,\n",
    "                                        intervals_method=intervals_method,\n",
    "                                        num_samples=num_samples,\n",
    "                                        seed=seed,\n",
    "                                        sort_df=False)\n",
    "            Y_tilde_df['seed'] = seed\n",
    "            # TODO: fix broken recmodel_names\n",
    "            if seed==0:\n",
    "                first_columns = Y_tilde_df.columns\n",
    "            Y_tilde_df.columns = first_columns\n",
    "            Y_tilde_list.append(Y_tilde_df)\n",
    "\n",
    "        Y_bootstrap_df = pd.concat(Y_tilde_list, axis=0)\n",
    "        del Y_tilde_list\n",
    "        gc.collect()\n",
    "\n",
    "        return Y_bootstrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init\n",
       "\n",
       ">      init (reconcilers:List[Callable])\n",
       "\n",
       "Hierarchical Reconciliation Class.\n",
       "\n",
       "The `core.HierarchicalReconciliation` class allows you to efficiently fit multiple \n",
       "HierarchicaForecast methods for a collection of time series and base predictions stored in \n",
       "pandas DataFrames. The `Y_df` dataframe identifies series and datestamps with the unique_id and ds columns while the\n",
       "y column denotes the target time series variable. The `Y_h` dataframe stores the base predictions, \n",
       "example ([AutoARIMA](https://nixtla.github.io/statsforecast/models.html#autoarima), [ETS](https://nixtla.github.io/statsforecast/models.html#autoets), etc.).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`reconcilers`: A list of instantiated classes of the [reconciliation methods](https://nixtla.github.io/hierarchicalforecast/methods.html) module .<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Hierarchical and Grouped Series\".](https://otexts.com/fpp3/hierarchical.html)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init\n",
       "\n",
       ">      init (reconcilers:List[Callable])\n",
       "\n",
       "Hierarchical Reconciliation Class.\n",
       "\n",
       "The `core.HierarchicalReconciliation` class allows you to efficiently fit multiple \n",
       "HierarchicaForecast methods for a collection of time series and base predictions stored in \n",
       "pandas DataFrames. The `Y_df` dataframe identifies series and datestamps with the unique_id and ds columns while the\n",
       "y column denotes the target time series variable. The `Y_h` dataframe stores the base predictions, \n",
       "example ([AutoARIMA](https://nixtla.github.io/statsforecast/models.html#autoarima), [ETS](https://nixtla.github.io/statsforecast/models.html#autoets), etc.).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`reconcilers`: A list of instantiated classes of the [reconciliation methods](https://nixtla.github.io/hierarchicalforecast/methods.html) module .<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Hierarchical and Grouped Series\".](https://otexts.com/fpp3/hierarchical.html)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HierarchicalReconciliation, \n",
    "         name='init', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### HierarchicalReconciliation\n",
       "\n",
       ">      HierarchicalReconciliation (reconcilers:List[Callable])\n",
       "\n",
       "Hierarchical Reconciliation Class.\n",
       "\n",
       "The `core.HierarchicalReconciliation` class allows you to efficiently fit multiple \n",
       "HierarchicaForecast methods for a collection of time series and base predictions stored in \n",
       "pandas DataFrames. The `Y_df` dataframe identifies series and datestamps with the unique_id and ds columns while the\n",
       "y column denotes the target time series variable. The `Y_h` dataframe stores the base predictions, \n",
       "example ([AutoARIMA](https://nixtla.github.io/statsforecast/models.html#autoarima), [ETS](https://nixtla.github.io/statsforecast/models.html#autoets), etc.).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`reconcilers`: A list of instantiated classes of the [reconciliation methods](https://nixtla.github.io/hierarchicalforecast/methods.html) module .<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Hierarchical and Grouped Series\".](https://otexts.com/fpp3/hierarchical.html)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### HierarchicalReconciliation\n",
       "\n",
       ">      HierarchicalReconciliation (reconcilers:List[Callable])\n",
       "\n",
       "Hierarchical Reconciliation Class.\n",
       "\n",
       "The `core.HierarchicalReconciliation` class allows you to efficiently fit multiple \n",
       "HierarchicaForecast methods for a collection of time series and base predictions stored in \n",
       "pandas DataFrames. The `Y_df` dataframe identifies series and datestamps with the unique_id and ds columns while the\n",
       "y column denotes the target time series variable. The `Y_h` dataframe stores the base predictions, \n",
       "example ([AutoARIMA](https://nixtla.github.io/statsforecast/models.html#autoarima), [ETS](https://nixtla.github.io/statsforecast/models.html#autoets), etc.).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`reconcilers`: A list of instantiated classes of the [reconciliation methods](https://nixtla.github.io/hierarchicalforecast/methods.html) module .<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Hierarchical and Grouped Series\".](https://otexts.com/fpp3/hierarchical.html)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HierarchicalReconciliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### reconcile\n",
       "\n",
       ">      reconcile (Y_hat_df:pandas.core.frame.DataFrame,\n",
       ">                 S:pandas.core.frame.DataFrame, tags:Dict[str,numpy.ndarray],\n",
       ">                 Y_df:Optional[pandas.core.frame.DataFrame]=None,\n",
       ">                 level:Optional[List[int]]=None,\n",
       ">                 intervals_method:str='normality', num_samples:int=-1,\n",
       ">                 seed:int=0, sort_df:bool=True, is_balanced:bool=False)\n",
       "\n",
       "Hierarchical Reconciliation Method.\n",
       "\n",
       "The `reconcile` method is analogous to SKLearn `fit_predict` method, it \n",
       "applies different reconciliation techniques instantiated in the `reconcilers` list.\n",
       "\n",
       "Most reconciliation methods can be described by the following convenient \n",
       "linear algebra notation:\n",
       "\n",
       "$$\\tilde{\\mathbf{y}}_{[a,b],\\tau} = \\mathbf{S}_{[a,b][b]} \\mathbf{P}_{[b][a,b]} \\hat{\\mathbf{y}}_{[a,b],\\tau}$$\n",
       "\n",
       "where $a, b$ represent the aggregate and bottom levels, $\\mathbf{S}_{[a,b][b]}$ contains\n",
       "the hierarchical aggregation constraints, and $\\mathbf{P}_{[b][a,b]}$ varies across \n",
       "reconciliation methods. The reconciled predictions are $\\tilde{\\mathbf{y}}_{[a,b],\\tau}$, and the \n",
       "base predictions $\\hat{\\mathbf{y}}_{[a,b],\\tau}$.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
       "`Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.<br>\n",
       "If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
       "`S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
       "`tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
       "`level`: positive float list [0,100), confidence levels for prediction intervals.<br>\n",
       "`intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
       "`num_samples`: int=-1, if positive return that many probabilistic coherent samples.\n",
       "`seed`: int=0, random seed for numpy generator's replicability.<br>\n",
       "`sort_df` : bool (default=True), if True, sort `df` by [`unique_id`,`ds`].<br>\n",
       "`is_balanced`: bool=False, wether `Y_df` is balanced, set it to True to speed things up if `Y_df` is balanced.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`Y_tilde_df`: pd.DataFrame, with reconciled predictions."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### reconcile\n",
       "\n",
       ">      reconcile (Y_hat_df:pandas.core.frame.DataFrame,\n",
       ">                 S:pandas.core.frame.DataFrame, tags:Dict[str,numpy.ndarray],\n",
       ">                 Y_df:Optional[pandas.core.frame.DataFrame]=None,\n",
       ">                 level:Optional[List[int]]=None,\n",
       ">                 intervals_method:str='normality', num_samples:int=-1,\n",
       ">                 seed:int=0, sort_df:bool=True, is_balanced:bool=False)\n",
       "\n",
       "Hierarchical Reconciliation Method.\n",
       "\n",
       "The `reconcile` method is analogous to SKLearn `fit_predict` method, it \n",
       "applies different reconciliation techniques instantiated in the `reconcilers` list.\n",
       "\n",
       "Most reconciliation methods can be described by the following convenient \n",
       "linear algebra notation:\n",
       "\n",
       "$$\\tilde{\\mathbf{y}}_{[a,b],\\tau} = \\mathbf{S}_{[a,b][b]} \\mathbf{P}_{[b][a,b]} \\hat{\\mathbf{y}}_{[a,b],\\tau}$$\n",
       "\n",
       "where $a, b$ represent the aggregate and bottom levels, $\\mathbf{S}_{[a,b][b]}$ contains\n",
       "the hierarchical aggregation constraints, and $\\mathbf{P}_{[b][a,b]}$ varies across \n",
       "reconciliation methods. The reconciled predictions are $\\tilde{\\mathbf{y}}_{[a,b],\\tau}$, and the \n",
       "base predictions $\\hat{\\mathbf{y}}_{[a,b],\\tau}$.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
       "`Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.<br>\n",
       "If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
       "`S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
       "`tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
       "`level`: positive float list [0,100), confidence levels for prediction intervals.<br>\n",
       "`intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
       "`num_samples`: int=-1, if positive return that many probabilistic coherent samples.\n",
       "`seed`: int=0, random seed for numpy generator's replicability.<br>\n",
       "`sort_df` : bool (default=True), if True, sort `df` by [`unique_id`,`ds`].<br>\n",
       "`is_balanced`: bool=False, wether `Y_df` is balanced, set it to True to speed things up if `Y_df` is balanced.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`Y_tilde_df`: pd.DataFrame, with reconciled predictions."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HierarchicalReconciliation.reconcile, name='reconcile', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### bootstrap_reconcile\n",
       "\n",
       ">      bootstrap_reconcile (Y_hat_df:pandas.core.frame.DataFrame,\n",
       ">                           S_df:pandas.core.frame.DataFrame,\n",
       ">                           tags:Dict[str,numpy.ndarray],\n",
       ">                           Y_df:Optional[pandas.core.frame.DataFrame]=None,\n",
       ">                           level:Optional[List[int]]=None,\n",
       ">                           intervals_method:str='normality',\n",
       ">                           num_samples:int=-1, num_seeds:int=1,\n",
       ">                           sort_df:bool=True)\n",
       "\n",
       "Bootstraped Hierarchical Reconciliation Method.\n",
       "\n",
       "Applies N times, based on different random seeds, the `reconcile` method \n",
       "for the different reconciliation techniques instantiated in the `reconcilers` list. \n",
       "\n",
       "**Parameters:**<br>\n",
       "`Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
       "`Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.<br>\n",
       "If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
       "`S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
       "`tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
       "`level`: positive float list [0,100), confidence levels for prediction intervals.<br>\n",
       "`intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
       "`num_samples`: int=-1, if positive return that many probabilistic coherent samples.\n",
       "`num_seeds`: int=1, random seed for numpy generator's replicability.<br>\n",
       "`sort_df` : bool (default=True), if True, sort `df` by [`unique_id`,`ds`].<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`Y_bootstrap_df`: pd.DataFrame, with bootstraped reconciled predictions."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### bootstrap_reconcile\n",
       "\n",
       ">      bootstrap_reconcile (Y_hat_df:pandas.core.frame.DataFrame,\n",
       ">                           S_df:pandas.core.frame.DataFrame,\n",
       ">                           tags:Dict[str,numpy.ndarray],\n",
       ">                           Y_df:Optional[pandas.core.frame.DataFrame]=None,\n",
       ">                           level:Optional[List[int]]=None,\n",
       ">                           intervals_method:str='normality',\n",
       ">                           num_samples:int=-1, num_seeds:int=1,\n",
       ">                           sort_df:bool=True)\n",
       "\n",
       "Bootstraped Hierarchical Reconciliation Method.\n",
       "\n",
       "Applies N times, based on different random seeds, the `reconcile` method \n",
       "for the different reconciliation techniques instantiated in the `reconcilers` list. \n",
       "\n",
       "**Parameters:**<br>\n",
       "`Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
       "`Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.<br>\n",
       "If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
       "`S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
       "`tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
       "`level`: positive float list [0,100), confidence levels for prediction intervals.<br>\n",
       "`intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
       "`num_samples`: int=-1, if positive return that many probabilistic coherent samples.\n",
       "`num_seeds`: int=1, random seed for numpy generator's replicability.<br>\n",
       "`sort_df` : bool (default=True), if True, sort `df` by [`unique_id`,`ds`].<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`Y_bootstrap_df`: pd.DataFrame, with bootstraped reconciled predictions."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HierarchicalReconciliation.bootstrap_reconcile, name='bootstrap_reconcile', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from hierarchicalforecast.methods import (\n",
    "    BottomUp, TopDown, MiddleOut, MinTrace, ERM,\n",
    ")\n",
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "\n",
    "# non strictly hierarchical structure\n",
    "hierS_grouped_df = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "# strictly hierarchical structure\n",
    "hiers_strictly = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "]\n",
    "\n",
    "# getting df\n",
    "hier_grouped_df, S_grouped_df, tags_grouped = aggregate(df, hierS_grouped_df)\n",
    "hier_strict_df, S_strict, tags_strict = aggregate(df, hiers_strictly)\n",
    "\n",
    "# check categorical input produces same output\n",
    "df2 = df.copy()\n",
    "for col in ['Country', 'State', 'Purpose', 'Region']:\n",
    "    df2[col] = df2[col].astype('category')\n",
    "\n",
    "for spec in [hierS_grouped_df, hiers_strictly]:\n",
    "    Y_orig, S_orig, tags_orig = aggregate(df, spec)\n",
    "    Y_cat, S_cat, tags_cat = aggregate(df2, spec)\n",
    "    pd.testing.assert_frame_equal(Y_cat, Y_orig)\n",
    "    pd.testing.assert_frame_equal(S_cat, S_orig)\n",
    "    assert all(np.array_equal(tags_orig[k], tags_cat[k]) for k in tags_orig.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hier_grouped_df['y_model'] = hier_grouped_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_grouped_hat_df = hier_grouped_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_grouped_hat_df['ds'].unique()\n",
    "hier_grouped_df = hier_grouped_df.query('~(ds in @ds_h)')\n",
    "#adding noise to `y_model` to avoid perfect fited values\n",
    "hier_grouped_df['y_model'] += np.random.uniform(-1, 1, len(hier_grouped_df))\n",
    "\n",
    "#hierachical reconciliation\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols', nonnegative=True),\n",
    "    MinTrace(method='wls_struct', nonnegative=True),\n",
    "    MinTrace(method='wls_var', nonnegative=True),\n",
    "    MinTrace(method='mint_shrink', nonnegative=True),\n",
    "    # ERM recovers but needs bigger eps\n",
    "    #ERM(method='reg_bu', lambda_reg=None),\n",
    "])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_grouped_hat_df, Y_df=hier_grouped_df, \n",
    "                            S=S_grouped_df, tags=tags_grouped)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    elif 'nonnegative' in model:\n",
    "        eps = 1e-1\n",
    "    else:\n",
    "        eps = 1e-1\n",
    "    test_close(reconciled['y'], reconciled[model], eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test incorrect Y_hat_df datatypes\n",
    "hier_grouped_hat_df_nan = hier_grouped_hat_df.copy()\n",
    "hier_grouped_hat_df_nan.loc['Australia', 'y_model'] = float('nan')\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='null values',\n",
    "    args=(hier_grouped_hat_df_nan, S_grouped_df, tags_grouped, hier_grouped_df),\n",
    ")\n",
    "\n",
    "hier_grouped_hat_df_none = hier_grouped_hat_df.copy()\n",
    "hier_grouped_hat_df_none.loc['Australia', 'y_model'] = None\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='null values',\n",
    "    args=(hier_grouped_hat_df_none, S_grouped_df, tags_grouped, hier_grouped_df),\n",
    ")\n",
    "\n",
    "hier_grouped_hat_df_str = hier_grouped_hat_df.copy()\n",
    "hier_grouped_hat_df_str['y_model'] = hier_grouped_hat_df_str['y_model'].astype(str)\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='numeric types',\n",
    "    args=(hier_grouped_hat_df_str, S_grouped_df, tags_grouped, hier_grouped_df),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test expected error\n",
    "# different series S and Y_hat_df\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='series difference',\n",
    "    args=(hier_grouped_hat_df.drop('Australia'), S_grouped_df, tags_grouped, hier_grouped_df),\n",
    "    \n",
    ")\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='series difference',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df.drop('Australia'), tags_grouped, hier_grouped_df),\n",
    "    \n",
    ")\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='series difference',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, hier_grouped_df.drop('Australia')),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# test expected error\n",
    "# different columns Y_df and Y_hat_df\n",
    "hrec = HierarchicalReconciliation(\n",
    "            reconcilers=[ERM(method='reg_bu', lambda_reg=100)])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='Please include ',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, \n",
    "          hier_grouped_df, [80], 'permbu'), # permbu needs y_hat_insample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test reconcile method without insample\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='ols', nonnegative=True),\n",
    "    MinTrace(method='wls_struct', nonnegative=True),\n",
    "])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_grouped_hat_df,\n",
    "                            S=S_grouped_df, tags=tags_grouped)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    elif 'nonnegative' in model:\n",
    "        eps = 1e-1\n",
    "    else:\n",
    "        eps = 1e-1\n",
    "    test_close(reconciled['y'], reconciled[model], eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# top down should break\n",
    "# with non strictly hierarchical structures\n",
    "hrec = HierarchicalReconciliation([TopDown(method='average_proportions')])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='requires strictly hierarchical structures',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped,  hier_grouped_df,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# methods should work with\n",
    "# srtictly hierarchical structures\n",
    "#| hide\n",
    "hier_strict_df['y_model'] = hier_strict_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_strict_df_h = hier_strict_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_strict_df_h['ds'].unique()\n",
    "hier_strict_df = hier_strict_df.query('~(ds in @ds_h)')\n",
    "#adding noise to `y_model` to avoid perfect fited values\n",
    "hier_strict_df['y_model'] += np.random.uniform(-1, 1, len(hier_strict_df))\n",
    "\n",
    "middle_out_level = 'Country/State'\n",
    "# hierarchical reconciliation\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols', nonnegative=True),\n",
    "    MinTrace(method='wls_struct', nonnegative=True),\n",
    "    MinTrace(method='wls_var', nonnegative=True),\n",
    "    MinTrace(method='mint_shrink', nonnegative=True),\n",
    "    # top down doesnt recover the original y\n",
    "    # but it should recover the total level\n",
    "    TopDown(method='forecast_proportions'),\n",
    "    TopDown(method='average_proportions'),\n",
    "    TopDown(method='proportion_averages'),\n",
    "    # middle out doesnt recover the original y\n",
    "    # but it should recover the total level\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='forecast_proportions'),\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='average_proportions'),\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='proportion_averages'),\n",
    "    # ERM recovers but needs bigger eps\n",
    "    #ERM(method='reg_bu', lambda_reg=None),\n",
    "])\n",
    "reconciled = hrec.reconcile(\n",
    "    Y_hat_df=hier_strict_df_h, \n",
    "    Y_df=hier_strict_df, \n",
    "    S=S_strict, \n",
    "    tags=tags_strict\n",
    ")\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    elif 'nonnegative' in model:\n",
    "        eps = 1e-1\n",
    "    else:\n",
    "        eps = 1e-1\n",
    "    if 'TopDown' in model:\n",
    "        if 'forecast_proportions' in model:\n",
    "            test_close(reconciled['y'], reconciled[model], eps)\n",
    "        else:\n",
    "            # top down doesnt recover the original y\n",
    "            test_fail(\n",
    "                test_close,\n",
    "                args=(reconciled['y'], reconciled[model], eps),\n",
    "            )\n",
    "        # but it should recover the total level\n",
    "        total_tag = tags_strict['Country']\n",
    "        test_close(reconciled['y'].loc[total_tag], \n",
    "                   reconciled[model].loc[total_tag], 1e-2)\n",
    "    elif 'MiddleOut' in model:\n",
    "        if 'forecast_proportions' in model:\n",
    "            test_close(reconciled['y'], reconciled[model], eps)\n",
    "        else:\n",
    "            # top down doesnt recover the original y\n",
    "            test_fail(\n",
    "                test_close,\n",
    "                args=(reconciled['y'], reconciled[model], eps),\n",
    "            )\n",
    "        # but it should recover the total level\n",
    "        total_tag = tags_strict[middle_out_level]\n",
    "        test_close(reconciled['y'].loc[total_tag], \n",
    "                   reconciled[model].loc[total_tag], 1e-2)\n",
    "    else:\n",
    "        test_close(reconciled['y'], reconciled[model], eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test is_balanced behaviour\n",
    "reconciled_balanced = hrec.reconcile(\n",
    "    Y_hat_df=hier_strict_df_h, \n",
    "    Y_df=hier_strict_df, \n",
    "    S=S_strict, \n",
    "    tags=tags_strict,\n",
    "    is_balanced=True,\n",
    ")\n",
    "test_close(reconciled.drop(columns='ds').values, reconciled_balanced.drop(columns='ds').values, eps=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.utils import generate_series\n",
    "from statsforecast.models import RandomWalkWithDrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test unbalanced dataset\n",
    "max_tenure = 24\n",
    "dates = pd.date_range(start='2019-01-31', freq='M', periods=max_tenure)\n",
    "cohort_tenure = [24, 23, 22, 21]\n",
    "\n",
    "ts_list = []\n",
    "\n",
    "# Create ts for each cohort\n",
    "for i in range(len(cohort_tenure)):\n",
    "    ts_list.append(\n",
    "        generate_series(n_series=1, freq='M', min_length=cohort_tenure[i], max_length=cohort_tenure[i]).reset_index() \\\n",
    "            .assign(ult=i) \\\n",
    "            .assign(ds=dates[-cohort_tenure[i]:]) \\\n",
    "            .drop(columns=['unique_id'])\n",
    "    )\n",
    "df = pd.concat(ts_list, ignore_index=True)\n",
    "\n",
    "# Create categories\n",
    "df.loc[df['ult'] < 2, 'pen'] = 'a'\n",
    "df.loc[df['ult'] >= 2, 'pen'] = 'b'\n",
    "# Note that unique id requires strings\n",
    "df['ult'] = df['ult'].astype(str)\n",
    "\n",
    "hier_levels = [\n",
    "    ['pen'],\n",
    "    ['pen', 'ult'],\n",
    "]\n",
    "hier_df, S_df, tags = aggregate(df=df, spec=hier_levels)\n",
    "\n",
    "train_df = hier_df.query(\"ds <= @pd.to_datetime('2019-12-31')\")\n",
    "test_df = hier_df.query(\"ds > @pd.to_datetime('2019-12-31')\")\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    models=[\n",
    "        RandomWalkWithDrift(),\n",
    "    ],\n",
    "    freq='M',\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "hrec = HierarchicalReconciliation(\n",
    "    reconcilers=[\n",
    "        BottomUp(),\n",
    "        MinTrace(method='mint_shrink'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fcst_df = fcst.forecast(df=train_df, h=12, fitted=True)\n",
    "fitted_df = fcst.forecast_fitted_values()\n",
    "\n",
    "fcst_df = hrec.reconcile(\n",
    "    Y_hat_df=fcst_df,\n",
    "    Y_df=fitted_df,\n",
    "    S=S_df,\n",
    "    tags=tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# MinTrace should break\n",
    "# with extremely overfitted model, y_model==y\n",
    "\n",
    "zero_df = hier_grouped_df.copy()\n",
    "zero_df['y'] = 0\n",
    "zero_df['y_model'] = 0\n",
    "hrec = HierarchicalReconciliation([MinTrace(method='mint_shrink')])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='Insample residuals',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped,  zero_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test methods that dont use residuals\n",
    "#even if their signature includes\n",
    "#that argument\n",
    "hrec = HierarchicalReconciliation([MinTrace(method='ols')])\n",
    "reconciled = hrec.reconcile(\n",
    "    Y_hat_df=hier_grouped_hat_df, \n",
    "    Y_df=hier_grouped_df.drop(columns=['y_model']), \n",
    "    S=S_grouped_df, \n",
    "    tags=tags_grouped\n",
    ")\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    test_close(reconciled['y'], reconciled[model], eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>y_model</th>\n",
       "      <th>y_model/MinTrace_method-ols</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2015 Q1</td>\n",
       "      <td>566.135463</td>\n",
       "      <td>566.135463</td>\n",
       "      <td>566.135431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2015 Q2</td>\n",
       "      <td>516.870343</td>\n",
       "      <td>516.870343</td>\n",
       "      <td>516.870360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2015 Q3</td>\n",
       "      <td>688.203188</td>\n",
       "      <td>688.203188</td>\n",
       "      <td>688.203222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2015 Q4</td>\n",
       "      <td>597.245569</td>\n",
       "      <td>597.245569</td>\n",
       "      <td>597.245600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2016 Q1</td>\n",
       "      <td>625.141634</td>\n",
       "      <td>625.141634</td>\n",
       "      <td>625.141589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia</th>\n",
       "      <td>2016 Q4</td>\n",
       "      <td>2656.330701</td>\n",
       "      <td>2656.330701</td>\n",
       "      <td>2656.330828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia</th>\n",
       "      <td>2017 Q1</td>\n",
       "      <td>2570.911689</td>\n",
       "      <td>2570.911689</td>\n",
       "      <td>2570.911638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia</th>\n",
       "      <td>2017 Q2</td>\n",
       "      <td>2438.487939</td>\n",
       "      <td>2438.487939</td>\n",
       "      <td>2438.488056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia</th>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>2493.954999</td>\n",
       "      <td>2493.954999</td>\n",
       "      <td>2493.954969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia</th>\n",
       "      <td>2017 Q4</td>\n",
       "      <td>2635.754296</td>\n",
       "      <td>2635.754296</td>\n",
       "      <td>2635.754395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ds            y      y_model  \\\n",
       "unique_id                                                        \n",
       "Australia/ACT                2015 Q1   566.135463   566.135463   \n",
       "Australia/ACT                2015 Q2   516.870343   516.870343   \n",
       "Australia/ACT                2015 Q3   688.203188   688.203188   \n",
       "Australia/ACT                2015 Q4   597.245569   597.245569   \n",
       "Australia/ACT                2016 Q1   625.141634   625.141634   \n",
       "...                              ...          ...          ...   \n",
       "Australia/Western Australia  2016 Q4  2656.330701  2656.330701   \n",
       "Australia/Western Australia  2017 Q1  2570.911689  2570.911689   \n",
       "Australia/Western Australia  2017 Q2  2438.487939  2438.487939   \n",
       "Australia/Western Australia  2017 Q3  2493.954999  2493.954999   \n",
       "Australia/Western Australia  2017 Q4  2635.754296  2635.754296   \n",
       "\n",
       "                             y_model/MinTrace_method-ols  \n",
       "unique_id                                                 \n",
       "Australia/ACT                                 566.135431  \n",
       "Australia/ACT                                 516.870360  \n",
       "Australia/ACT                                 688.203222  \n",
       "Australia/ACT                                 597.245600  \n",
       "Australia/ACT                                 625.141589  \n",
       "...                                                  ...  \n",
       "Australia/Western Australia                  2656.330828  \n",
       "Australia/Western Australia                  2570.911638  \n",
       "Australia/Western Australia                  2438.488056  \n",
       "Australia/Western Australia                  2493.954969  \n",
       "Australia/Western Australia                  2635.754395  \n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "reconciled.loc[tags_grouped['Country/State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test methods with bootstrap prediction intervals\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_grouped_hat_df, \n",
    "                            Y_df=hier_grouped_df, S=S_grouped_df, tags=tags_grouped,\n",
    "                            level=[80, 90], \n",
    "                            intervals_method='bootstrap')\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region/Purpose']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")\n",
    "assert 'y_model/BottomUp-lo-80' in reconciled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test methods with  normality prediction intervals\n",
    "hier_grouped_hat_df['y_model-lo-80'] = hier_grouped_hat_df['y_model'] - 1.96\n",
    "hier_grouped_hat_df['y_model-hi-80'] = hier_grouped_hat_df['y_model'] + 1.96\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_grouped_hat_df,\n",
    "                            Y_df=hier_grouped_df, S=S_grouped_df, tags=tags_grouped,\n",
    "                            level=[80, 90], \n",
    "                            intervals_method='normality')\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region/Purpose']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")\n",
    "assert 'y_model/BottomUp-lo-80' in reconciled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test methods with PERMBU prediction intervals\n",
    "\n",
    "# test expect error with grouped structure\n",
    "# (non strictly hierarchical)\n",
    "hier_grouped_hat_df['y_model-lo-80'] = hier_grouped_hat_df['y_model'] - 1.96\n",
    "hier_grouped_hat_df['y_model-hi-80'] = hier_grouped_hat_df['y_model'] + 1.96\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='requires strictly hierarchical structures',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, hier_grouped_df, [80, 90], 'permbu',)\n",
    ")\n",
    "\n",
    "# test PERMBU\n",
    "hier_strict_df_h['y_model-lo-80'] = hier_strict_df_h['y_model'] - 1.96\n",
    "hier_strict_df_h['y_model-hi-80'] = hier_strict_df_h['y_model'] + 1.96\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_strict_df_h,\n",
    "                            Y_df=hier_strict_df, S=S_strict, \n",
    "                            tags=tags_grouped,\n",
    "                            level=[80, 90], \n",
    "                            intervals_method='permbu')\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")\n",
    "assert 'y_model/BottomUp-lo-80' in reconciled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>y_model</th>\n",
       "      <th>y_model-lo-80</th>\n",
       "      <th>y_model-hi-80</th>\n",
       "      <th>y_model/BottomUp</th>\n",
       "      <th>y_model/BottomUp-lo-90</th>\n",
       "      <th>y_model/BottomUp-lo-80</th>\n",
       "      <th>y_model/BottomUp-hi-80</th>\n",
       "      <th>y_model/BottomUp-hi-90</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2015 Q1</td>\n",
       "      <td>25023.736745</td>\n",
       "      <td>25023.736745</td>\n",
       "      <td>25021.776745</td>\n",
       "      <td>25025.696745</td>\n",
       "      <td>25023.740234</td>\n",
       "      <td>25008.027344</td>\n",
       "      <td>25010.248047</td>\n",
       "      <td>25037.162109</td>\n",
       "      <td>25039.646777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2015 Q2</td>\n",
       "      <td>23798.914367</td>\n",
       "      <td>23798.914367</td>\n",
       "      <td>23796.954367</td>\n",
       "      <td>23800.874367</td>\n",
       "      <td>23798.919922</td>\n",
       "      <td>23781.757812</td>\n",
       "      <td>23784.914062</td>\n",
       "      <td>23811.863281</td>\n",
       "      <td>23815.722656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2015 Q3</td>\n",
       "      <td>23485.745655</td>\n",
       "      <td>23485.745655</td>\n",
       "      <td>23483.785655</td>\n",
       "      <td>23487.705655</td>\n",
       "      <td>23485.744141</td>\n",
       "      <td>23468.589844</td>\n",
       "      <td>23471.744141</td>\n",
       "      <td>23498.741211</td>\n",
       "      <td>23502.607031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2015 Q4</td>\n",
       "      <td>25140.161221</td>\n",
       "      <td>25140.161221</td>\n",
       "      <td>25138.201221</td>\n",
       "      <td>25142.121221</td>\n",
       "      <td>25140.162109</td>\n",
       "      <td>25123.005859</td>\n",
       "      <td>25126.673828</td>\n",
       "      <td>25153.696094</td>\n",
       "      <td>25156.970703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2016 Q1</td>\n",
       "      <td>26660.637689</td>\n",
       "      <td>26660.637689</td>\n",
       "      <td>26658.677690</td>\n",
       "      <td>26662.597689</td>\n",
       "      <td>26660.628906</td>\n",
       "      <td>26645.546875</td>\n",
       "      <td>26648.501367</td>\n",
       "      <td>26674.172656</td>\n",
       "      <td>26677.497559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2016 Q4</td>\n",
       "      <td>439.699451</td>\n",
       "      <td>439.699451</td>\n",
       "      <td>437.739451</td>\n",
       "      <td>441.659450</td>\n",
       "      <td>439.699463</td>\n",
       "      <td>438.771545</td>\n",
       "      <td>438.851196</td>\n",
       "      <td>440.507257</td>\n",
       "      <td>440.618561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2017 Q1</td>\n",
       "      <td>356.867038</td>\n",
       "      <td>356.867038</td>\n",
       "      <td>354.907038</td>\n",
       "      <td>358.827038</td>\n",
       "      <td>356.867035</td>\n",
       "      <td>356.015839</td>\n",
       "      <td>356.050018</td>\n",
       "      <td>357.678070</td>\n",
       "      <td>357.721121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2017 Q2</td>\n",
       "      <td>302.296119</td>\n",
       "      <td>302.296119</td>\n",
       "      <td>300.336119</td>\n",
       "      <td>304.256119</td>\n",
       "      <td>302.296112</td>\n",
       "      <td>301.388199</td>\n",
       "      <td>301.465564</td>\n",
       "      <td>303.170898</td>\n",
       "      <td>303.240173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>373.442070</td>\n",
       "      <td>373.442070</td>\n",
       "      <td>371.482070</td>\n",
       "      <td>375.402070</td>\n",
       "      <td>373.442078</td>\n",
       "      <td>372.512234</td>\n",
       "      <td>372.593811</td>\n",
       "      <td>374.297281</td>\n",
       "      <td>374.361176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2017 Q4</td>\n",
       "      <td>455.316702</td>\n",
       "      <td>455.316702</td>\n",
       "      <td>453.356702</td>\n",
       "      <td>457.276702</td>\n",
       "      <td>455.316711</td>\n",
       "      <td>454.486725</td>\n",
       "      <td>454.538849</td>\n",
       "      <td>456.191498</td>\n",
       "      <td>456.260803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         ds             y  \\\n",
       "unique_id                                                                   \n",
       "Australia                                           2015 Q1  25023.736745   \n",
       "Australia                                           2015 Q2  23798.914367   \n",
       "Australia                                           2015 Q3  23485.745655   \n",
       "Australia                                           2015 Q4  25140.161221   \n",
       "Australia                                           2016 Q1  26660.637689   \n",
       "...                                                     ...           ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...  2016 Q4    439.699451   \n",
       "Australia/Western Australia/Experience Perth/Vi...  2017 Q1    356.867038   \n",
       "Australia/Western Australia/Experience Perth/Vi...  2017 Q2    302.296119   \n",
       "Australia/Western Australia/Experience Perth/Vi...  2017 Q3    373.442070   \n",
       "Australia/Western Australia/Experience Perth/Vi...  2017 Q4    455.316702   \n",
       "\n",
       "                                                         y_model  \\\n",
       "unique_id                                                          \n",
       "Australia                                           25023.736745   \n",
       "Australia                                           23798.914367   \n",
       "Australia                                           23485.745655   \n",
       "Australia                                           25140.161221   \n",
       "Australia                                           26660.637689   \n",
       "...                                                          ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...    439.699451   \n",
       "Australia/Western Australia/Experience Perth/Vi...    356.867038   \n",
       "Australia/Western Australia/Experience Perth/Vi...    302.296119   \n",
       "Australia/Western Australia/Experience Perth/Vi...    373.442070   \n",
       "Australia/Western Australia/Experience Perth/Vi...    455.316702   \n",
       "\n",
       "                                                    y_model-lo-80  \\\n",
       "unique_id                                                           \n",
       "Australia                                            25021.776745   \n",
       "Australia                                            23796.954367   \n",
       "Australia                                            23483.785655   \n",
       "Australia                                            25138.201221   \n",
       "Australia                                            26658.677690   \n",
       "...                                                           ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...     437.739451   \n",
       "Australia/Western Australia/Experience Perth/Vi...     354.907038   \n",
       "Australia/Western Australia/Experience Perth/Vi...     300.336119   \n",
       "Australia/Western Australia/Experience Perth/Vi...     371.482070   \n",
       "Australia/Western Australia/Experience Perth/Vi...     453.356702   \n",
       "\n",
       "                                                    y_model-hi-80  \\\n",
       "unique_id                                                           \n",
       "Australia                                            25025.696745   \n",
       "Australia                                            23800.874367   \n",
       "Australia                                            23487.705655   \n",
       "Australia                                            25142.121221   \n",
       "Australia                                            26662.597689   \n",
       "...                                                           ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...     441.659450   \n",
       "Australia/Western Australia/Experience Perth/Vi...     358.827038   \n",
       "Australia/Western Australia/Experience Perth/Vi...     304.256119   \n",
       "Australia/Western Australia/Experience Perth/Vi...     375.402070   \n",
       "Australia/Western Australia/Experience Perth/Vi...     457.276702   \n",
       "\n",
       "                                                    y_model/BottomUp  \\\n",
       "unique_id                                                              \n",
       "Australia                                               25023.740234   \n",
       "Australia                                               23798.919922   \n",
       "Australia                                               23485.744141   \n",
       "Australia                                               25140.162109   \n",
       "Australia                                               26660.628906   \n",
       "...                                                              ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...        439.699463   \n",
       "Australia/Western Australia/Experience Perth/Vi...        356.867035   \n",
       "Australia/Western Australia/Experience Perth/Vi...        302.296112   \n",
       "Australia/Western Australia/Experience Perth/Vi...        373.442078   \n",
       "Australia/Western Australia/Experience Perth/Vi...        455.316711   \n",
       "\n",
       "                                                    y_model/BottomUp-lo-90  \\\n",
       "unique_id                                                                    \n",
       "Australia                                                     25008.027344   \n",
       "Australia                                                     23781.757812   \n",
       "Australia                                                     23468.589844   \n",
       "Australia                                                     25123.005859   \n",
       "Australia                                                     26645.546875   \n",
       "...                                                                    ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...              438.771545   \n",
       "Australia/Western Australia/Experience Perth/Vi...              356.015839   \n",
       "Australia/Western Australia/Experience Perth/Vi...              301.388199   \n",
       "Australia/Western Australia/Experience Perth/Vi...              372.512234   \n",
       "Australia/Western Australia/Experience Perth/Vi...              454.486725   \n",
       "\n",
       "                                                    y_model/BottomUp-lo-80  \\\n",
       "unique_id                                                                    \n",
       "Australia                                                     25010.248047   \n",
       "Australia                                                     23784.914062   \n",
       "Australia                                                     23471.744141   \n",
       "Australia                                                     25126.673828   \n",
       "Australia                                                     26648.501367   \n",
       "...                                                                    ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...              438.851196   \n",
       "Australia/Western Australia/Experience Perth/Vi...              356.050018   \n",
       "Australia/Western Australia/Experience Perth/Vi...              301.465564   \n",
       "Australia/Western Australia/Experience Perth/Vi...              372.593811   \n",
       "Australia/Western Australia/Experience Perth/Vi...              454.538849   \n",
       "\n",
       "                                                    y_model/BottomUp-hi-80  \\\n",
       "unique_id                                                                    \n",
       "Australia                                                     25037.162109   \n",
       "Australia                                                     23811.863281   \n",
       "Australia                                                     23498.741211   \n",
       "Australia                                                     25153.696094   \n",
       "Australia                                                     26674.172656   \n",
       "...                                                                    ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...              440.507257   \n",
       "Australia/Western Australia/Experience Perth/Vi...              357.678070   \n",
       "Australia/Western Australia/Experience Perth/Vi...              303.170898   \n",
       "Australia/Western Australia/Experience Perth/Vi...              374.297281   \n",
       "Australia/Western Australia/Experience Perth/Vi...              456.191498   \n",
       "\n",
       "                                                    y_model/BottomUp-hi-90  \\\n",
       "unique_id                                                                    \n",
       "Australia                                                     25039.646777   \n",
       "Australia                                                     23815.722656   \n",
       "Australia                                                     23502.607031   \n",
       "Australia                                                     25156.970703   \n",
       "Australia                                                     26677.497559   \n",
       "...                                                                    ...   \n",
       "Australia/Western Australia/Experience Perth/Vi...              440.618561   \n",
       "Australia/Western Australia/Experience Perth/Vi...              357.721121   \n",
       "Australia/Western Australia/Experience Perth/Vi...              303.240173   \n",
       "Australia/Western Australia/Experience Perth/Vi...              374.361176   \n",
       "Australia/Western Australia/Experience Perth/Vi...              456.260803   \n",
       "\n",
       "                                                    seed  \n",
       "unique_id                                                 \n",
       "Australia                                              0  \n",
       "Australia                                              0  \n",
       "Australia                                              0  \n",
       "Australia                                              0  \n",
       "Australia                                              0  \n",
       "...                                                  ...  \n",
       "Australia/Western Australia/Experience Perth/Vi...     1  \n",
       "Australia/Western Australia/Experience Perth/Vi...     1  \n",
       "Australia/Western Australia/Experience Perth/Vi...     1  \n",
       "Australia/Western Australia/Experience Perth/Vi...     1  \n",
       "Australia/Western Australia/Experience Perth/Vi...     1  \n",
       "\n",
       "[10200 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "# test methods with Bootraped Bootstap prediction intervals\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "bootstrap_df = hrec.bootstrap_reconcile(Y_hat_df=hier_grouped_hat_df,\n",
    "                                        Y_df=hier_grouped_df, S_df=S_grouped_df, tags=tags_grouped,\n",
    "                                        level=[80, 90],\n",
    "                                        intervals_method='bootstrap',\n",
    "                                        num_seeds=2)\n",
    "assert 'y_model/BottomUp-lo-80' in bootstrap_df.columns\n",
    "assert 'seed' in bootstrap_df.columns\n",
    "assert len(bootstrap_df.seed.unique())==2\n",
    "bootstrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test level protection for PERMBU and Normality probabilistic methods\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='Level outside domain',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, hier_grouped_df, [-1, 80, 90], 'permbu',)\n",
    ")\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='Level outside domain',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, hier_grouped_df, [80, 90, 101], 'normality',)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive/BottomUp</th>\n",
       "      <th>Naive/MinTrace_method-mint_shrink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>26347.601562</td>\n",
       "      <td>26347.583984</td>\n",
       "      <td>26347.600970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>26347.601562</td>\n",
       "      <td>26347.583984</td>\n",
       "      <td>26347.600970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>667.214111</td>\n",
       "      <td>667.214111</td>\n",
       "      <td>667.214126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/ACT</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>667.214111</td>\n",
       "      <td>667.214111</td>\n",
       "      <td>667.214126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/New South Wales</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>7995.501953</td>\n",
       "      <td>7995.502930</td>\n",
       "      <td>7995.502137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Holiday</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>310.973419</td>\n",
       "      <td>310.973419</td>\n",
       "      <td>310.973408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Other</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>89.863976</td>\n",
       "      <td>89.863976</td>\n",
       "      <td>89.863975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Other</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>89.863976</td>\n",
       "      <td>89.863976</td>\n",
       "      <td>89.863975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>439.699463</td>\n",
       "      <td>439.699463</td>\n",
       "      <td>439.699458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/Western Australia/Experience Perth/Visiting</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>439.699463</td>\n",
       "      <td>439.699463</td>\n",
       "      <td>439.699458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           ds         Naive  \\\n",
       "unique_id                                                                     \n",
       "Australia                                          2016-12-31  26347.601562   \n",
       "Australia                                          2017-03-31  26347.601562   \n",
       "Australia/ACT                                      2016-12-31    667.214111   \n",
       "Australia/ACT                                      2017-03-31    667.214111   \n",
       "Australia/New South Wales                          2016-12-31   7995.501953   \n",
       "...                                                       ...           ...   \n",
       "Australia/Western Australia/Experience Perth/Ho... 2017-03-31    310.973419   \n",
       "Australia/Western Australia/Experience Perth/Other 2016-12-31     89.863976   \n",
       "Australia/Western Australia/Experience Perth/Other 2017-03-31     89.863976   \n",
       "Australia/Western Australia/Experience Perth/Vi... 2016-12-31    439.699463   \n",
       "Australia/Western Australia/Experience Perth/Vi... 2017-03-31    439.699463   \n",
       "\n",
       "                                                    Naive/BottomUp  \\\n",
       "unique_id                                                            \n",
       "Australia                                             26347.583984   \n",
       "Australia                                             26347.583984   \n",
       "Australia/ACT                                           667.214111   \n",
       "Australia/ACT                                           667.214111   \n",
       "Australia/New South Wales                              7995.502930   \n",
       "...                                                            ...   \n",
       "Australia/Western Australia/Experience Perth/Ho...      310.973419   \n",
       "Australia/Western Australia/Experience Perth/Other       89.863976   \n",
       "Australia/Western Australia/Experience Perth/Other       89.863976   \n",
       "Australia/Western Australia/Experience Perth/Vi...      439.699463   \n",
       "Australia/Western Australia/Experience Perth/Vi...      439.699463   \n",
       "\n",
       "                                                    Naive/MinTrace_method-mint_shrink  \n",
       "unique_id                                                                              \n",
       "Australia                                                                26347.600970  \n",
       "Australia                                                                26347.600970  \n",
       "Australia/ACT                                                              667.214126  \n",
       "Australia/ACT                                                              667.214126  \n",
       "Australia/New South Wales                                                 7995.502137  \n",
       "...                                                                               ...  \n",
       "Australia/Western Australia/Experience Perth/Ho...                         310.973408  \n",
       "Australia/Western Australia/Experience Perth/Other                          89.863975  \n",
       "Australia/Western Australia/Experience Perth/Other                          89.863975  \n",
       "Australia/Western Australia/Experience Perth/Vi...                         439.699458  \n",
       "Australia/Western Australia/Experience Perth/Vi...                         439.699458  \n",
       "\n",
       "[850 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import ETS, Naive\n",
    "\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import BottomUp, MinTrace\n",
    "\n",
    "# Load TourismSmall dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "\n",
    "# Create hierarchical seires based on geographic levels and purpose\n",
    "# And Convert quarterly ds string to pd.datetime format\n",
    "hierarchy_levels = [['Country'],\n",
    "                    ['Country', 'State'], \n",
    "                    ['Country', 'Purpose'], \n",
    "                    ['Country', 'State', 'Region'], \n",
    "                    ['Country', 'State', 'Purpose'], \n",
    "                    ['Country', 'State', 'Region', 'Purpose']]\n",
    "\n",
    "Y_df, S_df, tags = aggregate(df=df, spec=hierarchy_levels)\n",
    "qs = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(qs, freq='Q').to_timestamp()\n",
    "Y_df = Y_df.reset_index()\n",
    "\n",
    "# Split train/test sets\n",
    "Y_test_df  = Y_df.groupby('unique_id').tail(4)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)\n",
    "\n",
    "# Compute base auto-ETS predictions\n",
    "# Careful identifying correct data freq, this data quarterly 'Q'\n",
    "fcst = StatsForecast(models=[Naive()], freq='Q', n_jobs=-1)\n",
    "Y_hat_df = fcst.forecast(df=Y_train_df, h=4, fitted=True)\n",
    "Y_fitted_df = fcst.forecast_fitted_values()\n",
    "\n",
    "# Reconcile the base predictions\n",
    "Y_train_df = Y_train_df.reset_index().set_index('unique_id')\n",
    "Y_hat_df = Y_hat_df.reset_index().set_index('unique_id')\n",
    "reconcilers = [BottomUp(),\n",
    "               MinTrace(method='mint_shrink')]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, \n",
    "                          Y_df=Y_fitted_df,\n",
    "                          S=S_df, tags=tags)\n",
    "Y_rec_df.groupby('unique_id', observed=True).head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
