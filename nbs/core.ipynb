{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Hierarchical \n",
    "\n",
    "> Module for Hierarchical Reconciliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial\n",
    "from inspect import signature\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _build_fn_name(fn) -> str:\n",
    "    fn_name = type(fn).__name__\n",
    "    func_params = fn.__dict__\n",
    "    func_params = [f'{name}-{value}' for name, value in func_params.items()]\n",
    "    if func_params:\n",
    "        fn_name += '_' + '_'.join(func_params)\n",
    "    return fn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HierarchicalReconciliation:\n",
    "    \n",
    "    def __init__(self, reconcilers: List[Callable]):\n",
    "        self.reconcilers = reconcilers\n",
    "        \n",
    "    def reconcile(self, Y_h: pd.DataFrame, Y_df: pd.DataFrame, S: pd.DataFrame):\n",
    "        \"\"\"Reconcile base forecasts.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            Y_h: pd.DataFrame\n",
    "                Base forecasts with columns ['ds'] \n",
    "                and models to reconcile indexed by 'unique_id'.\n",
    "            Y_df: pd.DataFrame\n",
    "                Training set of base time series with columns \n",
    "                ['ds', 'y'] indexed by 'unique_id'\n",
    "                If a function of `self.reconcile_fns` receives\n",
    "                residuals, `Y_df` must include them as columns.\n",
    "            S: pd.DataFrame\n",
    "                Summing matrix of size (hierarchies, bottom).\n",
    "        \"\"\"\n",
    "        drop_cols = ['ds', 'y'] if 'y' in Y_h.columns else ['ds']\n",
    "        model_names = Y_h.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "        uids = Y_h.index.unique()\n",
    "        # same order of Y_h to prevent errors\n",
    "        S_ = S.loc[uids]\n",
    "        common_vals = dict(\n",
    "            y = Y_df.pivot(columns='ds', values='y').loc[uids].values,\n",
    "            S = S_.values,\n",
    "            idx_bottom = [S_.index.get_loc(col) for col in S.columns]\n",
    "        )\n",
    "        fcsts = Y_h.copy()\n",
    "        for reconcile_fn in self.reconcilers:\n",
    "            reconcile_fn_name = _build_fn_name(reconcile_fn)\n",
    "            has_res = 'residuals' in signature(reconcile_fn).parameters\n",
    "            for model_name in model_names:\n",
    "                # Remember: pivot sorts uid\n",
    "                y_hat_model = Y_h.pivot(columns='ds', values=model_name).loc[uids].values\n",
    "                if has_res:\n",
    "                    if model_name in Y_df:\n",
    "                        common_vals['residuals'] = Y_df.pivot(columns='ds', values=model_name).loc[uids].values.T\n",
    "                    else:\n",
    "                        # some methods have the residuals argument\n",
    "                        # but they don't need them\n",
    "                        # ej MinTrace(method='ols')\n",
    "                        common_vals['residuals'] = None\n",
    "                kwargs = [key for key in signature(reconcile_fn).parameters if key in common_vals.keys()]\n",
    "                kwargs = {key: common_vals[key] for key in kwargs}\n",
    "                fcsts_model = reconcile_fn(y_hat=y_hat_model, **kwargs)\n",
    "                fcsts[f'{model_name}/{reconcile_fn_name}'] = fcsts_model.flatten()\n",
    "                if has_res:\n",
    "                    del common_vals['residuals']\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from hierarchicalforecast.methods import (\n",
    "    BottomUp, TopDown, MinTrace, ERM, bottom_up\n",
    ")\n",
    "from hierarchicalforecast.utils import hierarchize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "hiers_grouped = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "hier_df, S, tags = hierarchize(df, hiers_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hier_df['y_model'] = hier_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_df_h = hier_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_df_h['ds'].unique()\n",
    "hier_df = hier_df.query('~(ds in @ds_h)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink')\n",
    "])\n",
    "reconciled = hrec.reconcile(hier_df_h, hier_df, S)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    test_close(reconciled['y'], reconciled[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test methods that dont use residuals\n",
    "#even if their signature includes\n",
    "#that argument\n",
    "hrec = HierarchicalReconciliation([MinTrace(method='ols')])\n",
    "reconciled = hrec.reconcile(hier_df_h, hier_df.drop(columns=['y_model']), S)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    test_close(reconciled['y'], reconciled[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "reconciled.loc[tags['Country/State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HierarchicalEvaluation:\n",
    "    \n",
    "    def __init__(self, evaluators: List[Callable]):\n",
    "        self.evaluators = evaluators\n",
    "        \n",
    "    def evaluate(self, \n",
    "                 Y_h: pd.DataFrame, \n",
    "                 Y_test: pd.DataFrame, \n",
    "                 tags: Dict[str, np.ndarray],\n",
    "                 benchmark: Optional[str] = None):\n",
    "        \"\"\"Evaluate hierarchical forecasts.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            Y_h: pd.DataFrame\n",
    "                Forecasts with columns ['ds'] \n",
    "                and models to evaluate.\n",
    "            Y_test: pd.DataFrame\n",
    "                True values with columns ['ds', 'y']\n",
    "            tags: Dict[str, np.ndarray]\n",
    "                Dictionary of levels.\n",
    "                Each key is a level and its value \n",
    "                contains tags associated to that level.\n",
    "            benchmark: Optional[str]\n",
    "                Optional benchmark model. \n",
    "                When passed, the evaluators are scaled by\n",
    "                the error of this benchark.\n",
    "                If passed, should be part of `Y_h`.\n",
    "        \"\"\"\n",
    "        drop_cols = ['ds', 'y'] if 'y' in Y_h.columns else ['ds']\n",
    "        model_names = Y_h.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "        fn_names = [fn.__name__ for fn in self.evaluators]\n",
    "        if benchmark is not None:\n",
    "            fn_names = [f'{fn_name}-scaled' for fn_name in fn_names]\n",
    "        tags_ = {'Overall': np.concatenate(list(tags.values()))}\n",
    "        tags_ = {**tags_, **tags}\n",
    "        index = pd.MultiIndex.from_product([tags_.keys(), fn_names], names=['level', 'metric'])\n",
    "        evaluation = pd.DataFrame(columns=model_names, index=index)\n",
    "        for level, cats in tags_.items():\n",
    "            Y_h_cats = Y_h.loc[cats]\n",
    "            y_test_cats = Y_test.loc[cats, 'y'].values\n",
    "            for i_fn, fn in enumerate(self.evaluators):\n",
    "                fn_name = fn_names[i_fn]\n",
    "                for model in model_names:\n",
    "                    loss = fn(y_test_cats, Y_h_cats[model].values)\n",
    "                    if benchmark is not None:\n",
    "                        scale = fn(y_test_cats, Y_h_cats[benchmark].values)\n",
    "                        if np.isclose(scale, 0., atol=np.finfo(float).eps):\n",
    "                            scale += np.finfo(float).eps\n",
    "                            if np.isclose(scale, loss, atol=1e-8):\n",
    "                                scale = 1.\n",
    "                        loss /= scale\n",
    "                    evaluation.loc[(level, fn_name), model] = loss\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def mse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)\n",
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(mse(y, y_hat))\n",
    "evaluator = HierarchicalEvaluation([mse, rmse])\n",
    "evaluator.evaluate(Y_h=reconciled.drop(columns='y'), \n",
    "                   Y_test=reconciled[['ds', 'y']], \n",
    "                   tags=tags,\n",
    "                   benchmark='y_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
