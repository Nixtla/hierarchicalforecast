{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\"> Core </span>\n",
    "\n",
    "> HierarchicalForecast contains pure Python implementations of hierarchical reconciliation methods as well as a `core.HierarchicalReconciliation` wrapper class that enables easy interaction with these methods through pandas DataFrames containing the hierarchical time series and the base predictions.<br><br> The `core.HierarchicalReconciliation` reconciliation class operates with the hierarchical time series pd.DataFrame `Y_df`, the base predictions pd.DataFrame `Y_hat_df`, the aggregation constraints matrix `S`. For more information on the creation of aggregation constraints matrix see the utils [aggregation method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from functools import partial\n",
    "from inspect import signature\n",
    "from scipy.stats import norm\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hierarchicalforecast.methods import _bootstrap_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_close, test_fail\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _build_fn_name(fn) -> str:\n",
    "    fn_name = type(fn).__name__\n",
    "    func_params = fn.__dict__\n",
    "    func_params = [f'{name}-{value}' for name, value in func_params.items()]\n",
    "    if func_params:\n",
    "        fn_name += '_' + '_'.join(func_params)\n",
    "    return fn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HierarchicalReconciliation:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            reconcilers: List[Callable] # Reconciliation classes of the `methods` module \n",
    "        ):\n",
    "        self.reconcilers = reconcilers\n",
    "        \n",
    "    def reconcile(\n",
    "            self, \n",
    "            Y_h: pd.DataFrame, # Base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.\n",
    "            Y_df: pd.DataFrame, # Training set of base time series with columns `['ds', 'y']` indexed by `unique_id`\n",
    "                                # If a class of `self.reconciles` receives\n",
    "                                # `y_hat_insample`, `Y_df` must include them as columns.\n",
    "            S: pd.DataFrame,    #  Summing matrix of size `(base, bottom)`.\n",
    "            tags: Dict[str, np.ndarray], # Each key is a level and its value contains tags associated to that level.\n",
    "            level: Optional[List[int]] = None, # Levels for probabilistic intervals\n",
    "            bootstrap: bool = False, # Compute leves using bootstrap\n",
    "        ):\n",
    "        drop_cols = ['ds', 'y'] if 'y' in Y_h.columns else ['ds']\n",
    "        model_names = Y_h.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "        # store pi names\n",
    "        pi_model_names = [name for name in model_names if ('-lo' in name or '-hi' in name)]\n",
    "        #remove prediction intervals\n",
    "        model_names = [name for name in model_names if name not in pi_model_names]\n",
    "        uids = Y_h.index.unique()\n",
    "        # same order of Y_h to prevent errors\n",
    "        S_ = S.loc[uids]\n",
    "        common_vals = dict(\n",
    "            y_insample = Y_df.pivot(columns='ds', values='y').loc[uids].values.astype(np.float32),\n",
    "            S = S_.values.astype(np.float32),\n",
    "            idx_bottom = S_.index.get_indexer(S.columns),\n",
    "            tags={key: S_.index.get_indexer(val) for key, val in tags.items()}\n",
    "        )\n",
    "        fcsts = Y_h.copy()\n",
    "        for reconcile_fn in self.reconcilers:\n",
    "            reconcile_fn_name = _build_fn_name(reconcile_fn)\n",
    "            has_fitted = 'y_hat_insample' in signature(reconcile_fn).parameters\n",
    "            has_level = 'level' in signature(reconcile_fn).parameters\n",
    "            for model_name in model_names:\n",
    "                # should we calculate prediction intervals?\n",
    "                pi_model_name = [pi_name for pi_name in pi_model_names if model_name in pi_name]\n",
    "                pi = len(pi_model_name) > 0\n",
    "                # Remember: pivot sorts uid\n",
    "                y_hat_model = Y_h.pivot(columns='ds', values=model_name).loc[uids].values\n",
    "                if pi and has_level and level is not None and not bootstrap:\n",
    "                    # we need to construct sigmah and add it\n",
    "                    # to the common_vals\n",
    "                    # to recover sigmah we only need \n",
    "                    # one prediction intervals\n",
    "                    pi_col = pi_model_name[0]\n",
    "                    sign = -1 if 'lo' in pi_col else 1\n",
    "                    level_col = re.findall('[\\d]+[.,\\d]+|[\\d]*[.][\\d]+|[\\d]+', pi_col)\n",
    "                    level_col = float(level_col[0])\n",
    "                    z = norm.ppf(0.5 + level_col / 200)\n",
    "                    sigmah = Y_h.pivot(columns='ds', values=pi_col).loc[uids].values\n",
    "                    sigmah = sign * (y_hat_model - sigmah) / z\n",
    "                    common_vals['sigmah'] = sigmah\n",
    "                    common_vals['level'] = level\n",
    "                if has_fitted or bootstrap:\n",
    "                    if model_name in Y_df:\n",
    "                        y_hat_insample = Y_df.pivot(columns='ds', values=model_name).loc[uids].values\n",
    "                        y_hat_insample = y_hat_insample.astype(np.float32)\n",
    "                        if has_fitted:\n",
    "                            common_vals['y_hat_insample'] = y_hat_insample \n",
    "                        if bootstrap and has_level:\n",
    "                            common_vals['bootstrap_samples'] = _bootstrap_samples(\n",
    "                                y_insample=common_vals['y_insample'],\n",
    "                                y_hat_insample=y_hat_insample, \n",
    "                                y_hat=y_hat_model, \n",
    "                                n_samples=1_000\n",
    "                            )\n",
    "                            common_vals['bootstrap'] = bootstrap\n",
    "                            common_vals['level'] = level\n",
    "                    else:\n",
    "                        # some methods have the residuals argument\n",
    "                        # but they don't need them\n",
    "                        # ej MinTrace(method='ols')\n",
    "                        common_vals['y_hat_insample'] = None\n",
    "                kwargs = [key for key in signature(reconcile_fn).parameters if key in common_vals.keys()]\n",
    "                kwargs = {key: common_vals[key] for key in kwargs}\n",
    "                fcsts_model = reconcile_fn(y_hat=y_hat_model, **kwargs)\n",
    "                fcsts[f'{model_name}/{reconcile_fn_name}'] = fcsts_model['mean'].flatten()\n",
    "                if (pi and has_level and level is not None) or (bootstrap and level is not None):\n",
    "                    for lv in level:\n",
    "                        fcsts[f'{model_name}/{reconcile_fn_name}-lo-{lv}'] = fcsts_model[f'lo-{lv}'].flatten()\n",
    "                        fcsts[f'{model_name}/{reconcile_fn_name}-hi-{lv}'] = fcsts_model[f'hi-{lv}'].flatten()\n",
    "                    del common_vals['level']\n",
    "                    if not bootstrap:\n",
    "                        del common_vals['sigmah']\n",
    "                    else:\n",
    "                        del common_vals['bootstrap_samples']\n",
    "                        del common_vals['bootstrap']\n",
    "                if has_fitted:\n",
    "                    del common_vals['y_hat_insample']\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "add_docs(HierarchicalReconciliation, \"Apply distinct reconciliation methods to a pandas dataframe.\",\n",
    "         reconcile=\"Reconcile using distinct approaches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalReconciliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalReconciliation.reconcile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from hierarchicalforecast.methods import (\n",
    "    BottomUp, TopDown, MiddleOut, MinTrace, ERM,\n",
    ")\n",
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "\n",
    "# non strictly hierarchical structure\n",
    "hiers_grouped = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "# strictly hierarchical structure\n",
    "hiers_strictly = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "]\n",
    "\n",
    "# getting df\n",
    "hier_grouped_df, S_grouped, tags_grouped = aggregate(df, hiers_grouped)\n",
    "hier_strict_df, S_strict, tags_strict = aggregate(df, hiers_strictly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hier_grouped_df['y_model'] = hier_grouped_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_grouped_df_h = hier_grouped_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_grouped_df_h['ds'].unique()\n",
    "hier_grouped_df = hier_grouped_df.query('~(ds in @ds_h)')\n",
    "#adding noise to `y_model` to avoid perfect fited values\n",
    "hier_grouped_df['y_model'] += np.random.uniform(-1, 1, len(hier_grouped_df))\n",
    "\n",
    "#hierachical reconciliation\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    # ERM recovers but needs bigger eps\n",
    "    #ERM(method='reg_bu', lambda_reg=None),\n",
    "])\n",
    "reconciled = hrec.reconcile(hier_grouped_df_h, hier_grouped_df, S_grouped, tags_grouped)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    else:\n",
    "        eps = 1e-5\n",
    "    test_close(reconciled['y'], reconciled[model], eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# top down should break\n",
    "# with non strictly hierarchical structures\n",
    "hrec = HierarchicalReconciliation([TopDown(method='average_proportions')])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='requires strictly hierarchical structures',\n",
    "    args=(hier_grouped_df_h, hier_grouped_df, S_grouped, tags_grouped)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# methods should work with\n",
    "# srtictly hierarchical structures\n",
    "#| hide\n",
    "hier_strict_df['y_model'] = hier_strict_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_strict_df_h = hier_strict_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_strict_df_h['ds'].unique()\n",
    "hier_strict_df = hier_strict_df.query('~(ds in @ds_h)')\n",
    "#adding noise to `y_model` to avoid perfect fited values\n",
    "hier_strict_df['y_model'] += np.random.uniform(-1, 1, len(hier_strict_df))\n",
    "\n",
    "middle_out_level = 'Country/State'\n",
    "# hierarchical reconciliation\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    # top down doesnt recover the original y\n",
    "    # but it should recover the total level\n",
    "    TopDown(method='forecast_proportions'),\n",
    "    TopDown(method='average_proportions'),\n",
    "    TopDown(method='proportion_averages'),\n",
    "    # middle out doesnt recover the original y\n",
    "    # but it should recover the total level\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='forecast_proportions'),\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='average_proportions'),\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='proportion_averages'),\n",
    "    # ERM recovers but needs bigger eps\n",
    "    #ERM(method='reg_bu', lambda_reg=None),\n",
    "])\n",
    "reconciled = hrec.reconcile(hier_strict_df_h, hier_strict_df, S_strict, tags_strict)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    else:\n",
    "        eps = 1e-5\n",
    "    if 'TopDown' in model:\n",
    "        if 'forecast_proportions' in model:\n",
    "            test_close(reconciled['y'], reconciled[model], eps)\n",
    "        else:\n",
    "            # top down doesnt recover the original y\n",
    "            test_fail(\n",
    "                test_close,\n",
    "                args=(reconciled['y'], reconciled[model], eps),\n",
    "            )\n",
    "        # but it should recover the total level\n",
    "        total_tag = tags_strict['Country']\n",
    "        test_close(reconciled['y'].loc[total_tag], \n",
    "                   reconciled[model].loc[total_tag], 1e-2)\n",
    "    elif 'MiddleOut' in model:\n",
    "        if 'forecast_proportions' in model:\n",
    "            test_close(reconciled['y'], reconciled[model], eps)\n",
    "        else:\n",
    "            # top down doesnt recover the original y\n",
    "            test_fail(\n",
    "                test_close,\n",
    "                args=(reconciled['y'], reconciled[model], eps),\n",
    "            )\n",
    "        # but it should recover the total level\n",
    "        total_tag = tags_strict[middle_out_level]\n",
    "        test_close(reconciled['y'].loc[total_tag], \n",
    "                   reconciled[model].loc[total_tag], 1e-2)\n",
    "    else:\n",
    "        test_close(reconciled['y'], reconciled[model], eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test methods that dont use residuals\n",
    "#even if their signature includes\n",
    "#that argument\n",
    "hrec = HierarchicalReconciliation([MinTrace(method='ols')])\n",
    "reconciled = hrec.reconcile(hier_grouped_df_h, hier_grouped_df.drop(columns=['y_model']), S_grouped, tags_grouped)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    test_close(reconciled['y'], reconciled[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "reconciled.loc[tags_grouped['Country/State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test methods bootrap prediction\n",
    "#intervals\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(hier_grouped_df_h, \n",
    "                            hier_grouped_df, S_grouped, tags_grouped,\n",
    "                            level=[80, 90], bootstrap=True)\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region/Purpose']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
