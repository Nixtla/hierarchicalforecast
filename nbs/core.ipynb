{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\"> Core </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HierarchicalForecast contains pure Python implementations of hierarchical reconciliation methods as well as a `core.HierarchicalReconciliation` wrapper class that enables easy interaction with these methods through pandas DataFrames containing the hierarchical time series and the base predictions.\n",
    "\n",
    "The `core.HierarchicalReconciliation` reconciliation class operates with the hierarchical time series pd.DataFrame `Y_df`, the base predictions pd.DataFrame `Y_hat_df`, the aggregation constraints matrix `S`. For more information on the creation of aggregation constraints matrix see the utils [aggregation method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from inspect import signature\n",
    "from scipy.stats import norm\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hierarchicalforecast.probabilistic_methods import Normality, Bootstrap, PERMBU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_close, test_eq, test_fail\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _build_fn_name(fn) -> str:\n",
    "    fn_name = type(fn).__name__\n",
    "    func_params = fn.__dict__\n",
    "\n",
    "    # Take default parameter out of names\n",
    "    args_to_remove = ['insample']\n",
    "    if not func_params.get('nonnegative', False):\n",
    "        args_to_remove += ['nonnegative']\n",
    "\n",
    "    if fn_name == 'MinTrace' and \\\n",
    "        func_params['method']=='mint_shrink':\n",
    "        if func_params['mint_shr_ridge'] == 2e-8:\n",
    "            args_to_remove += ['mint_shr_ridge']\n",
    "\n",
    "    func_params = [f'{name}-{value}' for name, value in func_params.items() if name not in args_to_remove]\n",
    "    if func_params:\n",
    "        fn_name += '_' + '_'.join(func_params)\n",
    "    return fn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test fn name\n",
    "from hierarchicalforecast.methods import BottomUp, MinTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(_build_fn_name(BottomUp()), 'BottomUp')\n",
    "test_eq(\n",
    "    _build_fn_name(MinTrace(method='ols')), \n",
    "    'MinTrace_method-ols'\n",
    ")\n",
    "test_eq(\n",
    "    _build_fn_name(MinTrace(method='ols', nonnegative=True)), \n",
    "    'MinTrace_method-ols_nonnegative-True'\n",
    ")\n",
    "test_eq(\n",
    "    _build_fn_name(MinTrace(method='mint_shr')), \n",
    "    'MinTrace_method-mint_shr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> core.HierarchicalReconciliation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _reverse_engineer_sigmah(Y_hat_df, y_hat, model_name, uids):\n",
    "    \"\"\"\n",
    "    This function assumes that the model creates prediction intervals\n",
    "    under a normality assumption with the following the Equation:\n",
    "    $\\hat{y}_{t+h} + c \\hat{sigma}_{h}$\n",
    "\n",
    "    In the future, we might deprecate this function in favor of a \n",
    "    direct usage of an estimated $\\hat{sigma}_{h}$\n",
    "    \"\"\"\n",
    "    drop_cols = ['ds', 'y'] if 'y' in Y_hat_df.columns else ['ds']\n",
    "    model_names = Y_hat_df.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "    pi_model_names = [name for name in model_names if ('-lo' in name or '-hi' in name)]\n",
    "    pi_model_name = [pi_name for pi_name in pi_model_names if model_name in pi_name]\n",
    "    pi = len(pi_model_name) > 0\n",
    "\n",
    "    if not pi:\n",
    "        raise Exception(f'Please include {model_name} prediction intervals in `Y_hat_df`')\n",
    "\n",
    "    pi_col = pi_model_name[0]\n",
    "    sign = -1 if 'lo' in pi_col else 1\n",
    "    level_col = re.findall('[\\d]+[.,\\d]+|[\\d]*[.][\\d]+|[\\d]+', pi_col)\n",
    "    level_col = float(level_col[0])\n",
    "    z = norm.ppf(0.5 + level_col / 200)\n",
    "    sigmah = Y_hat_df.pivot(columns='ds', values=pi_col).loc[uids].values\n",
    "    sigmah = sign * (sigmah - y_hat) / z\n",
    "\n",
    "    return sigmah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HierarchicalReconciliation:\n",
    "    \"\"\"Hierarchical Reconciliation Class.\n",
    "\n",
    "    The `core.HierarchicalReconciliation` class allows you to efficiently fit multiple \n",
    "    HierarchicaForecast methods for a collection of time series and base predictions stored in \n",
    "    pandas DataFrames. The `Y_df` dataframe identifies series and datestamps with the unique_id and ds columns while the\n",
    "    y column denotes the target time series variable. The `Y_h` dataframe stores the base predictions, \n",
    "    example ([AutoARIMA](https://nixtla.github.io/statsforecast/models.html#autoarima), [ETS](https://nixtla.github.io/statsforecast/models.html#autoets), etc.).\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `reconcilers`: A list of instantiated classes of the [reconciliation methods](https://nixtla.github.io/hierarchicalforecast/methods.html) module .<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Rob J. Hyndman and George Athanasopoulos (2018). \\\"Forecasting principles and practice, Hierarchical and Grouped Series\\\".](https://otexts.com/fpp3/hierarchical.html)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reconcilers: List[Callable]):\n",
    "        self.reconcilers = reconcilers\n",
    "        self.insample = any([method.insample for method in reconcilers])\n",
    "\n",
    "    def reconcile(self, \n",
    "                  Y_hat_df: pd.DataFrame,\n",
    "                  S: pd.DataFrame,\n",
    "                  tags: Dict[str, np.ndarray],\n",
    "                  Y_df: Optional[pd.DataFrame] = None,\n",
    "                  level: Optional[List[int]] = None,\n",
    "                  intervals_method: str = 'normality'):\n",
    "        \"\"\"Hierarchical Reconciliation Method.\n",
    "\n",
    "        The `reconcile` method is analogous to SKLearn `fit` method, it applies different \n",
    "        reconciliation methods instantiated in the `reconcilers` list. \n",
    "\n",
    "        Most reconciliation methods can be described by the following convenient \n",
    "        linear algebra notation:\n",
    "\n",
    "        $$\\\\tilde{\\mathbf{y}}_{[a,b],\\\\tau} = \\mathbf{S}_{[a,b][b]} \\mathbf{P}_{[b][a,b]} \\hat{\\mathbf{y}}_{[a,b],\\\\tau}$$\n",
    "\n",
    "        where $a, b$ represent the aggregate and bottom levels, $\\mathbf{S}_{[a,b][b]}$ contains\n",
    "        the hierarchical aggregation constraints, and $\\mathbf{P}_{[b][a,b]}$ varies across \n",
    "        reconciliation methods. The reconciled predictions are $\\\\tilde{\\mathbf{y}}_{[a,b],\\\\tau}$, and the \n",
    "        base predictions $\\hat{\\mathbf{y}}_{[a,b],\\\\tau}$.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `Y_hat_df`: pd.DataFrame, base forecasts with columns `ds` and models to reconcile indexed by `unique_id`.<br>\n",
    "        `Y_df`: pd.DataFrame, training set of base time series with columns `['ds', 'y']` indexed by `unique_id`.\n",
    "        If a class of `self.reconciles` receives `y_hat_insample`, `Y_df` must include them as columns.<br>\n",
    "        `S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate method](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
    "        `tags`: Each key is a level and its value contains tags associated to that level.<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `intervals_method`: str, method used to calculate prediction intervals, one of `normality`, `bootstrap`, `permbu`.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `y_tilde`: pd.DataFrame, with reconciled predictions.        \n",
    "        \"\"\"\n",
    "        #----------------------------- Preliminary Wrangling/Protections -----------------------------#\n",
    "        # Check input's validity\n",
    "        if intervals_method not in ['normality', 'bootstrap', 'permbu']:\n",
    "            raise ValueError(f'Unkwon interval method: {intervals_method}')\n",
    "\n",
    "        if self.insample or (intervals_method in ['bootstrap', 'permbu']):\n",
    "            if Y_df is None:\n",
    "                raise Exception('you need to pass `Y_df`')            \n",
    "\n",
    "        # Declare output names\n",
    "        drop_cols = ['ds', 'y'] if 'y' in Y_hat_df.columns else ['ds']\n",
    "        model_names = Y_hat_df.drop(columns=drop_cols, axis=1).columns.to_list()\n",
    "        pi_model_names = [name for name in model_names if ('-lo' in name or '-hi' in name)]\n",
    "        model_names = [name for name in model_names if name not in pi_model_names]\n",
    "\n",
    "        uids = Y_hat_df.index.unique()\n",
    "\n",
    "        # Check Y_hat_df\\S_df series difference\n",
    "        S_diff  = len(S.index.difference(uids))\n",
    "        Y_hat_diff = len(Y_hat_df.index.difference(S.index.unique()))\n",
    "        if S_diff > 0 or Y_hat_diff > 0:\n",
    "            raise Exception(f'Check `S_df`, `Y_hat_df` series difference, S\\Y_hat={S_diff}, Y_hat\\S={Y_hat_diff}')\n",
    "\n",
    "        if Y_df is not None:\n",
    "            # Check Y_hat_df\\Y_df series difference\n",
    "            Y_diff  = len(Y_df.index.difference(uids))\n",
    "            Y_hat_diff = len(Y_hat_df.index.difference(Y_df.index.unique()))\n",
    "            if Y_diff > 0 or  Y_hat_diff > 0:\n",
    "                raise Exception(f'Check `Y_hat_df`, `Y_df` series difference, Y_hat\\Y={Y_hat_diff}, Y\\Y_hat={Y_diff}')\n",
    "\n",
    "        # Same Y_hat_df/S_df/Y_df's unique_id order to prevent errors\n",
    "        S_ = S.loc[uids]\n",
    "    \n",
    "\n",
    "        #---------------------------------------- Predictions ----------------------------------------#\n",
    "        # Initialize reconciler arguments\n",
    "        reconciler_args = dict(\n",
    "            S=S_.values.astype(np.float32),\n",
    "            idx_bottom=S_.index.get_indexer(S.columns),\n",
    "            tags={key: S_.index.get_indexer(val) for key, val in tags.items()}\n",
    "        )\n",
    "        if Y_df is not None:\n",
    "            reconciler_args['y_insample'] = Y_df.pivot(columns='ds', values='y').loc[uids].values.astype(np.float32)\n",
    "\n",
    "        fcsts = Y_hat_df.copy()\n",
    "        for reconcile_fn in self.reconcilers:\n",
    "            reconcile_fn_name = _build_fn_name(reconcile_fn)\n",
    "            has_fitted = 'y_hat_insample' in signature(reconcile_fn).parameters\n",
    "            has_level = 'level' in signature(reconcile_fn).parameters\n",
    "            \n",
    "            # TODO: maybe sort in advance by uids and avoid .loc[uids]\n",
    "            # This change affects y_hat_model, y_insample, y_hat_insample, sigmah\n",
    "            # change pivot for df.values and reshapes.\n",
    "            for model_name in model_names:\n",
    "                y_hat = Y_hat_df.pivot(columns='ds', values=model_name).loc[uids].values\n",
    "                reconciler_args['y_hat'] = y_hat\n",
    "\n",
    "                if (self.insample and has_fitted) or intervals_method in ['bootstrap', 'permbu']:\n",
    "                    y_hat_insample = Y_df.pivot(columns='ds', values=model_name).loc[uids].values\n",
    "                    y_hat_insample = y_hat_insample.astype(np.float32)\n",
    "                    reconciler_args['y_hat_insample'] = y_hat_insample\n",
    "\n",
    "                if has_level and (level is not None):\n",
    "                    reconciler_args['level'] = level\n",
    "\n",
    "                    if intervals_method in ['normality', 'permbu']:\n",
    "                        sigmah = _reverse_engineer_sigmah(Y_hat_df=Y_hat_df,\n",
    "                                    y_hat=y_hat, model_name=model_name, uids=uids)\n",
    "\n",
    "                    reconciler_args['intervals_method'] = intervals_method\n",
    "\n",
    "                # Mean reconciliation\n",
    "                kwargs = [key for key in signature(reconcile_fn).parameters if key in reconciler_args.keys()]\n",
    "                kwargs = {key: reconciler_args[key] for key in kwargs}\n",
    "                fcsts_model = reconcile_fn(**kwargs)\n",
    "\n",
    "                # TODO: instantiate prob reconcilers after mean reconc \n",
    "                # and use _prob_reconcile function from probabilistic_methods.py\n",
    "                # this will greatly simplify code above, and improve its readability\n",
    "                # this will require outputs of reconcile_fn to include P, W\n",
    "\n",
    "                fcsts[f'{model_name}/{reconcile_fn_name}'] = fcsts_model['mean'].flatten()\n",
    "                if intervals_method in ['bootstrap', 'normality', 'permbu'] and level is not None:\n",
    "                    for lv in level:\n",
    "                        fcsts[f'{model_name}/{reconcile_fn_name}-lo-{lv}'] = fcsts_model[f'lo-{lv}'].flatten()\n",
    "                        fcsts[f'{model_name}/{reconcile_fn_name}-hi-{lv}'] = fcsts_model[f'hi-{lv}'].flatten()\n",
    "                    del reconciler_args['level']\n",
    "                    del reconciler_args['sampler']\n",
    "                if self.insample and has_fitted:\n",
    "                    del reconciler_args['y_hat_insample']\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalReconciliation, \n",
    "         name='init', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalReconciliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalReconciliation.reconcile,\n",
    "         name='reconcile', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from hierarchicalforecast.methods import (\n",
    "    BottomUp, TopDown, MiddleOut, MinTrace, ERM,\n",
    ")\n",
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "\n",
    "# non strictly hierarchical structure\n",
    "hierS_grouped_df = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "# strictly hierarchical structure\n",
    "hiers_strictly = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "]\n",
    "\n",
    "# getting df\n",
    "hier_grouped_df, S_grouped_df, tags_grouped = aggregate(df, hierS_grouped_df)\n",
    "hier_strict_df, S_strict, tags_strict = aggregate(df, hiers_strictly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hier_grouped_df['y_model'] = hier_grouped_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_grouped_hat_df = hier_grouped_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_grouped_hat_df['ds'].unique()\n",
    "hier_grouped_df = hier_grouped_df.query('~(ds in @ds_h)')\n",
    "#adding noise to `y_model` to avoid perfect fited values\n",
    "hier_grouped_df['y_model'] += np.random.uniform(-1, 1, len(hier_grouped_df))\n",
    "\n",
    "#hierachical reconciliation\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols', nonnegative=True),\n",
    "    MinTrace(method='wls_struct', nonnegative=True),\n",
    "    MinTrace(method='wls_var', nonnegative=True),\n",
    "    MinTrace(method='mint_shrink', nonnegative=True),\n",
    "    # ERM recovers but needs bigger eps\n",
    "    #ERM(method='reg_bu', lambda_reg=None),\n",
    "])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_grouped_hat_df, Y_df=hier_grouped_df, \n",
    "                            S=S_grouped_df, tags=tags_grouped)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    elif 'nonnegative' in model:\n",
    "        eps = 1e-1\n",
    "    else:\n",
    "        eps = 1e-5\n",
    "    test_close(reconciled['y'], reconciled[model], eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test expected error\n",
    "# different series S and Y_hat_df\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='series difference',\n",
    "    args=(hier_grouped_hat_df.drop('Australia'), S_grouped_df, tags_grouped, hier_grouped_df),\n",
    "    \n",
    ")\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='series difference',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df.drop('Australia'), tags_grouped, hier_grouped_df),\n",
    "    \n",
    ")\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='series difference',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, hier_grouped_df.drop('Australia')),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test reconcile method without insample\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='ols', nonnegative=True),\n",
    "    MinTrace(method='wls_struct', nonnegative=True),\n",
    "])\n",
    "reconciled = hrec.reconcile(Y_hat_df=hier_grouped_hat_df,\n",
    "                            S=S_grouped_df, tags=tags_grouped)\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    elif 'nonnegative' in model:\n",
    "        eps = 1e-1\n",
    "    else:\n",
    "        eps = 1e-5\n",
    "    test_close(reconciled['y'], reconciled[model], eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# top down should break\n",
    "# with non strictly hierarchical structures\n",
    "hrec = HierarchicalReconciliation([TopDown(method='average_proportions')])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='requires strictly hierarchical structures',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped,  hier_grouped_df,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# methods should work with\n",
    "# srtictly hierarchical structures\n",
    "#| hide\n",
    "hier_strict_df['y_model'] = hier_strict_df['y']\n",
    "# we should be able to recover y using the methods\n",
    "hier_strict_df_h = hier_strict_df.groupby('unique_id').tail(12)\n",
    "ds_h = hier_strict_df_h['ds'].unique()\n",
    "hier_strict_df = hier_strict_df.query('~(ds in @ds_h)')\n",
    "#adding noise to `y_model` to avoid perfect fited values\n",
    "hier_strict_df['y_model'] += np.random.uniform(-1, 1, len(hier_strict_df))\n",
    "\n",
    "middle_out_level = 'Country/State'\n",
    "# hierarchical reconciliation\n",
    "hrec = HierarchicalReconciliation(reconcilers=[\n",
    "    #these methods should reconstruct the original y\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='wls_struct'),\n",
    "    MinTrace(method='wls_var'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols', nonnegative=True),\n",
    "    MinTrace(method='wls_struct', nonnegative=True),\n",
    "    MinTrace(method='wls_var', nonnegative=True),\n",
    "    MinTrace(method='mint_shrink', nonnegative=True),\n",
    "    # top down doesnt recover the original y\n",
    "    # but it should recover the total level\n",
    "    TopDown(method='forecast_proportions'),\n",
    "    TopDown(method='average_proportions'),\n",
    "    TopDown(method='proportion_averages'),\n",
    "    # middle out doesnt recover the original y\n",
    "    # but it should recover the total level\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='forecast_proportions'),\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='average_proportions'),\n",
    "    MiddleOut(middle_level=middle_out_level, top_down_method='proportion_averages'),\n",
    "    # ERM recovers but needs bigger eps\n",
    "    #ERM(method='reg_bu', lambda_reg=None),\n",
    "])\n",
    "reconciled = hrec.reconcile(\n",
    "    Y_hat_df=hier_strict_df_h, \n",
    "    Y_df=hier_strict_df, \n",
    "    S=S_strict, \n",
    "    tags=tags_strict\n",
    ")\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    if 'ERM' in model:\n",
    "        eps = 3\n",
    "    elif 'nonnegative' in model:\n",
    "        eps = 1e-1\n",
    "    else:\n",
    "        eps = 1e-5\n",
    "    if 'TopDown' in model:\n",
    "        if 'forecast_proportions' in model:\n",
    "            test_close(reconciled['y'], reconciled[model], eps)\n",
    "        else:\n",
    "            # top down doesnt recover the original y\n",
    "            test_fail(\n",
    "                test_close,\n",
    "                args=(reconciled['y'], reconciled[model], eps),\n",
    "            )\n",
    "        # but it should recover the total level\n",
    "        total_tag = tags_strict['Country']\n",
    "        test_close(reconciled['y'].loc[total_tag], \n",
    "                   reconciled[model].loc[total_tag], 1e-2)\n",
    "    elif 'MiddleOut' in model:\n",
    "        if 'forecast_proportions' in model:\n",
    "            test_close(reconciled['y'], reconciled[model], eps)\n",
    "        else:\n",
    "            # top down doesnt recover the original y\n",
    "            test_fail(\n",
    "                test_close,\n",
    "                args=(reconciled['y'], reconciled[model], eps),\n",
    "            )\n",
    "        # but it should recover the total level\n",
    "        total_tag = tags_strict[middle_out_level]\n",
    "        test_close(reconciled['y'].loc[total_tag], \n",
    "                   reconciled[model].loc[total_tag], 1e-2)\n",
    "    else:\n",
    "        test_close(reconciled['y'], reconciled[model], eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# MinTrace should break\n",
    "# with extremely overfitted model, y_model==y\n",
    "\n",
    "zero_df = hier_grouped_df.copy()\n",
    "zero_df['y'] = 0\n",
    "zero_df['y_model'] = 0\n",
    "hrec = HierarchicalReconciliation([MinTrace(method='mint_shrink')])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='Insample residuals',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped,  zero_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test methods that dont use residuals\n",
    "#even if their signature includes\n",
    "#that argument\n",
    "hrec = HierarchicalReconciliation([MinTrace(method='ols')])\n",
    "reconciled = hrec.reconcile(\n",
    "    Y_hat_df=hier_grouped_hat_df, \n",
    "    Y_df=hier_grouped_df.drop(columns=['y_model']), \n",
    "    S=S_grouped_df, \n",
    "    tags=tags_grouped\n",
    ")\n",
    "for model in reconciled.drop(columns=['ds', 'y']).columns:\n",
    "    test_close(reconciled['y'], reconciled[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "reconciled.loc[tags_grouped['Country/State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test methods bootstrap prediction\n",
    "#intervals\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(hier_grouped_hat_df, \n",
    "                            Y_df=hier_grouped_df, S=S_grouped_df, tags=tags_grouped,\n",
    "                            level=[80, 90], \n",
    "                            intervals_method='bootstrap')\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region/Purpose']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")\n",
    "assert 'y_model/BottomUp-lo-80' in reconciled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test methods that require prediction intervals\n",
    "# normality\n",
    "hier_grouped_hat_df['y_model-lo-80'] = hier_grouped_hat_df['y_model'] - 1.96\n",
    "hier_grouped_hat_df['y_model-hi-80'] = hier_grouped_hat_df['y_model'] + 1.96\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(hier_grouped_hat_df, \n",
    "                            Y_df=hier_grouped_df, S=S_grouped_df, tags=tags_grouped,\n",
    "                            level=[80, 90], \n",
    "                            intervals_method='normality')\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region/Purpose']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")\n",
    "assert 'y_model/BottomUp-lo-80' in reconciled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test methods that require prediction intervals\n",
    "# PERMBU\n",
    "\n",
    "# test expect error with grouped structure \n",
    "# (non strictly hierarchical)\n",
    "hier_grouped_hat_df['y_model-lo-80'] = hier_grouped_hat_df['y_model'] - 1.96\n",
    "hier_grouped_hat_df['y_model-hi-80'] = hier_grouped_hat_df['y_model'] + 1.96\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "test_fail(\n",
    "    hrec.reconcile,\n",
    "    contains='requires strictly hierarchical structures',\n",
    "    args=(hier_grouped_hat_df, S_grouped_df, tags_grouped, hier_grouped_df, [80, 90], 'permbu',)\n",
    ")\n",
    "\n",
    "# test PERMBU\n",
    "hier_strict_df_h['y_model-lo-80'] = hier_strict_df_h['y_model'] - 1.96\n",
    "hier_strict_df_h['y_model-hi-80'] = hier_strict_df_h['y_model'] + 1.96\n",
    "hrec = HierarchicalReconciliation([BottomUp()])\n",
    "reconciled = hrec.reconcile(hier_strict_df_h, \n",
    "                            Y_df=hier_strict_df, S=S_strict, tags=tags_grouped,\n",
    "                            level=[80, 90], \n",
    "                            intervals_method='permbu')\n",
    "total = reconciled.loc[tags_grouped['Country/State/Region']].groupby('ds').sum().reset_index()\n",
    "pd.testing.assert_frame_equal(\n",
    "    total[['ds', 'y_model/BottomUp']],\n",
    "    reconciled.loc['Australia'][['ds', 'y_model/BottomUp']].reset_index(drop=True)\n",
    ")\n",
    "assert 'y_model/BottomUp-lo-80' in reconciled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> Example </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import ETS, Naive\n",
    "\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import BottomUp, MinTrace\n",
    "\n",
    "# Load TourismSmall dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "\n",
    "# Create hierarchical seires based on geographic levels and purpose\n",
    "# And Convert quarterly ds string to pd.datetime format\n",
    "hierarchy_levels = [['Country'],\n",
    "                    ['Country', 'State'], \n",
    "                    ['Country', 'Purpose'], \n",
    "                    ['Country', 'State', 'Region'], \n",
    "                    ['Country', 'State', 'Purpose'], \n",
    "                    ['Country', 'State', 'Region', 'Purpose']]\n",
    "\n",
    "Y_df, S_df, tags = aggregate(df=df, spec=hierarchy_levels)\n",
    "qs = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(qs, freq='Q').to_timestamp()\n",
    "Y_df = Y_df.reset_index()\n",
    "\n",
    "# Split train/test sets\n",
    "Y_test_df  = Y_df.groupby('unique_id').tail(4)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)\n",
    "\n",
    "# Compute base auto-ETS predictions\n",
    "# Careful identifying correct data freq, this data quarterly 'Q'\n",
    "fcst = StatsForecast(df=Y_train_df,\n",
    "                     #models=[ETS(season_length=12), Naive()],\n",
    "                     models=[Naive()],\n",
    "                     freq='Q', n_jobs=-1)\n",
    "Y_hat_df = fcst.forecast(h=4, fitted=True)\n",
    "Y_fitted_df = fcst.forecast_fitted_values()\n",
    "\n",
    "# Reconcile the base predictions\n",
    "Y_train_df = Y_train_df.reset_index().set_index('unique_id')\n",
    "Y_hat_df = Y_hat_df.reset_index().set_index('unique_id')\n",
    "reconcilers = [BottomUp(),\n",
    "               MinTrace(method='mint_shrink')]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, \n",
    "                          Y_df=Y_fitted_df,\n",
    "                          S=S_df, tags=tags)\n",
    "Y_rec_df.groupby('unique_id').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchicalforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:43:44) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "231ab5be553983f5d18761458fd09479b8ea8fd2f7d5e70fe8cc57d3219e6899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
