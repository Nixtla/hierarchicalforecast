{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "> Introduction to Hierarchial Forecasting using `HierarchialForecast`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hierarchical Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, a set of time series is hierarchically organized. Examples include the presence of geographic levels, products, or categories that define different types of aggregations. \n",
    "\n",
    "In such scenarios, forecasters are often required to provide predictions for all disaggregate and aggregate series. A natural desire is for those predictions to be **\"coherent\"**, that is, for the bottom series to add up precisely to the forecasts of the aggregated series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. A two level time series hierarchical structure, with four bottom level variables.](./imgs/hierarchical_motivation1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1. shows a simple hierarchical structure where we have four bottom-level series, two middle-level series, and the top level representing the total aggregation. Its hierarchical aggregations or coherency constraints are:\n",
    "\n",
    "\\begin{align}\n",
    "        y_{\\mathrm{Total},\\tau} = y_{\\beta_{1},\\tau}+y_{\\beta_{2},\\tau}+y_{\\beta_{3},\\tau}+y_{\\beta_{4},\\tau} \n",
    "        \\qquad \\qquad \\qquad \\qquad \\qquad \\\\\n",
    "        \\mathbf{y}_{[a],\\tau}=\\left[y_{\\mathrm{Total},\\tau},\\; y_{\\beta_{1},\\tau}+y_{\\beta_{2},\\tau},\\;y_{\\beta_{3},\\tau}+y_{\\beta_{4},\\tau}\\right]^{\\intercal} \n",
    "        \\qquad\n",
    "        \\mathbf{y}_{[b],\\tau}=\\left[ y_{\\beta_{1},\\tau},\\; y_{\\beta_{2},\\tau},\\; y_{\\beta_{3},\\tau},\\; y_{\\beta_{4},\\tau} \\right]^{\\intercal}\n",
    "\\end{align}\n",
    "\n",
    "Luckily these constraints can be compactly expressed with the following matrices:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{S}_{[a,b][b]}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{A}_{\\mathrm{[a][b]}} \\\\ \n",
    "           \\\\\n",
    "           \\\\\n",
    "\\mathbf{I}_{\\mathrm{[b][b]}} \\\\\n",
    "           \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 1 \\\\\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathbf{A}_{[a,b][b]}$ aggregates the bottom series to the upper levels, and $\\mathbf{I}_{\\mathrm{[b][b]}}$ is an identity matrix. The representation of the hierarchical series is then:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y}_{[a,b],\\tau} = \\mathbf{S}_{[a,b][b]} \\mathbf{y}_{[b],\\tau}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize an example, in Figure 2. One can think of the hierarchical time series structure levels to represent different geographical aggregations. For example, in Figure 2. the top level is the total aggregation of series within a country, the middle level being its states and the bottom level its regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2. A hierarchy can be composed of geographic levels. In this example the top level corresponds to country aggregation, middle level to states, and bottom level to regions.](./imgs/hierarchical_motivation2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hierarchical Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve **\"coherency\"**, most statistical solutions to the hierarchical forecasting challenge implement a two-stage reconciliation process.  \n",
    "1. First, we obtain a set of the base forecast $\\mathbf{\\hat{y}}_{[a,b],\\tau}$ \n",
    "2. Later, we reconcile them into coherent forecasts $\\mathbf{\\tilde{y}}_{[a,b],\\tau}$.\n",
    "\n",
    "Most hierarchical reconciliation methods can be expressed by the following transformations:\n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{\\mathbf{y}}_{[a,b],\\tau} = \\mathbf{S}_{[a,b][b]} \\mathbf{P}_{[b][a,b]} \\hat{\\mathbf{y}}_{[a,b],\\tau}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HierarchicalForecast library offers a Python collection of reconciliation methods, datasets, evaluation and visualization tools for the task. Among its available reconciliation methods we have `BottomUp`, `TopDown`, `MiddleOut`, `MinTrace`, `ERM`. Among its probabilistic coherent methods we have `Normality`, `Bootstrap`, `PERMBU`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimal Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast\n",
    "!pip install -U numba statsforecast datasetsforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to creat a synthetic data set to illustrate a hierarchical time series structure like the one in Figure 1.\n",
    "\n",
    "We will create a two level structure with four bottom series where aggregations of the series are self evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>top_level</th>\n",
       "      <th>middle_level</th>\n",
       "      <th>bottom_level</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State1</td>\n",
       "      <td>r1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State1</td>\n",
       "      <td>r1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State1</td>\n",
       "      <td>r2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State1</td>\n",
       "      <td>r2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State2</td>\n",
       "      <td>r3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State2</td>\n",
       "      <td>r3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State2</td>\n",
       "      <td>r4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>State2</td>\n",
       "      <td>r4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds  top_level middle_level bottom_level    y\n",
       "0  2000-01-01  Australia       State1           r1   10\n",
       "1  2000-02-01  Australia       State1           r1   20\n",
       "8  2000-01-01  Australia       State1           r2   10\n",
       "9  2000-02-01  Australia       State1           r2   20\n",
       "16 2000-01-01  Australia       State2           r3  100\n",
       "17 2000-02-01  Australia       State2           r3  200\n",
       "24 2000-01-01  Australia       State2           r4  100\n",
       "25 2000-02-01  Australia       State2           r4  200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Figure 1. synthetic bottom data\n",
    "ds = pd.date_range(start='2000-01-01', end='2000-08-01', freq='MS')\n",
    "y_base = np.arange(1,9)\n",
    "r1 = y_base * (10**1)\n",
    "r2 = y_base * (10**1)\n",
    "r3 = y_base * (10**2)\n",
    "r4 = y_base * (10**2)\n",
    "\n",
    "ys = np.concatenate([r1, r2, r3, r4])\n",
    "ds = np.tile(ds, 4)\n",
    "unique_ids = ['r1'] * 8 + ['r2'] * 8 + ['r3'] * 8 + ['r4'] * 8\n",
    "top_level = 'Australia'\n",
    "middle_level = ['State1'] * 16 + ['State2'] * 16\n",
    "bottom_level = unique_ids\n",
    "\n",
    "bottom_df = dict(ds=ds,\n",
    "                 top_level=top_level, \n",
    "                 middle_level=middle_level, \n",
    "                 bottom_level=bottom_level,\n",
    "                 y=ys)\n",
    "bottom_df = pd.DataFrame(bottom_df)\n",
    "bottom_df.groupby('bottom_level').head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previously introduced hierarchical series $\\mathbf{y}_{[a,b]\\tau}$ is captured within the `Y_hier_df` dataframe.\n",
    "\n",
    "The aggregation constraints matrix $\\mathbf{S}_{[a][b]}$ is captured within the `S_df` dataframe.\n",
    "\n",
    "Finally the `tags` contains a list within `Y_hier_df` composing each hierarchical level, for example\n",
    "the `tags['top_level']` contains `Australia`'s aggregated series index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_df.shape (7, 4)\n",
      "Y_hier_df.shape (56, 3)\n",
      "tags['top_level'] ['Australia']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cchallu/opt/anaconda3/envs/hierarchicalforecast/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create hierarchical structure and constraints\n",
    "hierarchy_levels = [['top_level'],\n",
    "                    ['top_level', 'middle_level'],\n",
    "                    ['top_level', 'middle_level', 'bottom_level']]\n",
    "Y_hier_df, S_df, tags = aggregate(df=bottom_df, spec=hierarchy_levels)\n",
    "Y_hier_df = Y_hier_df.reset_index()\n",
    "print('S_df.shape', S_df.shape)\n",
    "print('Y_hier_df.shape', Y_hier_df.shape)\n",
    "print(\"tags['top_level']\", tags['top_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia/State1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia/State1</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Australia/State2</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Australia/State2</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Australia/State1/r1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Australia/State1/r1</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Australia/State1/r2</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Australia/State1/r2</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Australia/State2/r3</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Australia/State2/r3</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Australia/State2/r4</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Australia/State2/r4</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_id         ds      y\n",
       "0             Australia 2000-01-01  220.0\n",
       "1             Australia 2000-02-01  440.0\n",
       "8      Australia/State1 2000-01-01   20.0\n",
       "9      Australia/State1 2000-02-01   40.0\n",
       "16     Australia/State2 2000-01-01  200.0\n",
       "17     Australia/State2 2000-02-01  400.0\n",
       "24  Australia/State1/r1 2000-01-01   10.0\n",
       "25  Australia/State1/r1 2000-02-01   20.0\n",
       "32  Australia/State1/r2 2000-01-01   10.0\n",
       "33  Australia/State1/r2 2000-02-01   20.0\n",
       "40  Australia/State2/r3 2000-01-01  100.0\n",
       "41  Australia/State2/r3 2000-02-01  200.0\n",
       "48  Australia/State2/r4 2000-01-01  100.0\n",
       "49  Australia/State2/r4 2000-02-01  200.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hier_df.groupby('unique_id').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australia/State1/r1</th>\n",
       "      <th>Australia/State1/r2</th>\n",
       "      <th>Australia/State2/r3</th>\n",
       "      <th>Australia/State2/r4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1/r1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1/r2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2/r3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2/r4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Australia/State1/r1  Australia/State1/r2  \\\n",
       "Australia                            1.0                  1.0   \n",
       "Australia/State1                     1.0                  1.0   \n",
       "Australia/State2                     0.0                  0.0   \n",
       "Australia/State1/r1                  1.0                  0.0   \n",
       "Australia/State1/r2                  0.0                  1.0   \n",
       "Australia/State2/r3                  0.0                  0.0   \n",
       "Australia/State2/r4                  0.0                  0.0   \n",
       "\n",
       "                     Australia/State2/r3  Australia/State2/r4  \n",
       "Australia                            1.0                  1.0  \n",
       "Australia/State1                     0.0                  0.0  \n",
       "Australia/State2                     1.0                  1.0  \n",
       "Australia/State1/r1                  0.0                  0.0  \n",
       "Australia/State1/r2                  0.0                  0.0  \n",
       "Australia/State2/r3                  1.0                  0.0  \n",
       "Australia/State2/r4                  0.0                  1.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the *base forecast* for each time series using the `naive` model. Observe that `Y_hat_df` contains the forecasts but they are not coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.core import StatsForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test sets\n",
    "Y_test_df  = Y_hier_df.groupby('unique_id').tail(4)\n",
    "Y_train_df = Y_hier_df.drop(Y_test_df.index)\n",
    "\n",
    "# Compute base Naive predictions\n",
    "# Careful identifying correct data freq, this data quarterly 'Q'\n",
    "fcst = StatsForecast(df=Y_train_df,\n",
    "                     models=[Naive()],\n",
    "                     freq='Q', n_jobs=-1)\n",
    "Y_hat_df = fcst.forecast(h=4, fitted=True)\n",
    "Y_fitted_df = fcst.forecast_fitted_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive/BottomUp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>880.0</td>\n",
       "      <td>880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>880.0</td>\n",
       "      <td>880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1/r1</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1/r1</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1/r2</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State1/r2</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2/r3</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2/r3</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2/r4</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia/State2/r4</th>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ds  Naive  Naive/BottomUp\n",
       "unique_id                                            \n",
       "Australia           2000-06-30  880.0           880.0\n",
       "Australia           2000-09-30  880.0           880.0\n",
       "Australia/State1    2000-06-30   80.0            80.0\n",
       "Australia/State1    2000-09-30   80.0            80.0\n",
       "Australia/State2    2000-06-30  800.0           800.0\n",
       "Australia/State2    2000-09-30  800.0           800.0\n",
       "Australia/State1/r1 2000-06-30   40.0            40.0\n",
       "Australia/State1/r1 2000-09-30   40.0            40.0\n",
       "Australia/State1/r2 2000-06-30   40.0            40.0\n",
       "Australia/State1/r2 2000-09-30   40.0            40.0\n",
       "Australia/State2/r3 2000-06-30  400.0           400.0\n",
       "Australia/State2/r3 2000-09-30  400.0           400.0\n",
       "Australia/State2/r4 2000-06-30  400.0           400.0\n",
       "Australia/State2/r4 2000-09-30  400.0           400.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can select a reconciler from our collection\n",
    "reconcilers = [BottomUp()] # MinTrace(method='mint_shrink')\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, \n",
    "                          Y_df=Y_fitted_df,\n",
    "                          S=S_df, tags=tags)\n",
    "Y_rec_df.groupby('unique_id').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition: \n",
    "Chapter 11: Forecasting hierarchical and grouped series.\". OTexts: Melbourne, Australia. OTexts.com/fpp3 \n",
    "Accessed on July 2022.](https://otexts.com/fpp3/hierarchical.html)<br>\n",
    "- [Orcutt, G.H., Watts, H.W., & Edwards, J.B.(1968). Data aggregation and information loss. The American \n",
    "Economic Review, 58 , 773{787).](http://www.jstor.org/stable/1815532)<br>\n",
    "- [Disaggregation methods to expedite product line forecasting. Journal of Forecasting, 9 , 233–254. \n",
    "doi:10.1002/for.3980090304.](https://onlinelibrary.wiley.com/doi/abs/10.1002/for.3980090304)<br>\n",
    "- [Wickramasuriya, S. L., Athanasopoulos, G., & Hyndman, R. J. (2019). \\\"Optimal forecast reconciliation for\n",
    "hierarchical and grouped time series through trace minimization\\\". Journal of the American Statistical Association, \n",
    "114 , 804–819. doi:10.1080/01621459.2018.1448825.](https://robjhyndman.com/publications/mint/)<br>\n",
    "- [Ben Taieb, S., & Koo, B. (2019). Regularized regression for hierarchical forecasting without \n",
    "unbiasedness conditions. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge \n",
    "Discovery & Data Mining KDD '19 (p. 1337{1347). New York, NY, USA: Association for Computing Machinery.](https://doi.org/10.1145/3292500.3330976)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
