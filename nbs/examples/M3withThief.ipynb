{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Aggregation with THIEF\n",
    "\n",
    "> Temporal Hierarchical Forecasting on M3 monthly and quarterly data with THIEF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we present an example on how to use `HierarchicalForecast` to produce coherent forecasts between temporal levels. We will use the monthly and quarterly timeseries of the `M3` dataset. We will first load the `M3` data and produce base forecasts using an `AutoETS` model from `StatsForecast`. Then, we reconcile the forecasts with `THIEF` (Temporal HIerarchical Forecasting) from `HierarchicalForecast` according to a specified temporal hierarchy.  \n",
    "\n",
    "### References\n",
    "[Athanasopoulos, G, Hyndman, Rob J., Kourentzes, N., Petropoulos, Fotios (2017). Forecasting with temporal hierarchies. European Journal of Operational Research, 262, 60-74](https://www.sciencedirect.com/science/article/pii/S0377221717301911)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/M3withThief.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast statsforecast datasetsforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.m3 import M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_monthly, _, _ = M3.load(directory='data', group='Monthly')\n",
    "m3_quarterly, _, _ = M3.load(directory='data', group='Quarterly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be making aggregations up to yearly levels, so for both monthly and quarterly data we make sure each time series has an integer multiple of bottom-level timesteps. \n",
    "\n",
    "For example, the first time series in m3_monthly (with `unique_id='M1'`) has 68 timesteps. This is not a multiple of 12 (12 months in one year), so we would not be able to aggregate all timesteps into full years. Hence, we truncate (remove) the first 8 timesteps, resulting in 60 timesteps for this series. We do something similar for the quarterly data, albeit with a multiple of 4 (4 quarters in one year).\n",
    "\n",
    "Depending on the highest temporal aggregation in your reconciliation problem, you may want to truncate your data differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_monthly = m3_monthly.groupby(\"unique_id\", group_keys=False)\\\n",
    "                       .apply(lambda x: x.tail(len(x) //  12 * 12))\\\n",
    "                       .reset_index(drop=True)\n",
    "\n",
    "m3_quarterly = m3_quarterly.groupby(\"unique_id\", group_keys=False)\\\n",
    "                           .apply(lambda x: x.tail(len(x) //  4 * 4))\\\n",
    "                           .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Split Train/Test sets\n",
    "\n",
    "We use as test samples the last 24 observations from the Monthly series and the last 8 observations of each quarterly series, following the original THIEF paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_monthly = 24\n",
    "horizon_quarterly = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_monthly_test = m3_monthly.groupby(\"unique_id\", as_index=False).tail(horizon_monthly)\n",
    "m3_monthly_train = m3_monthly.drop(m3_monthly_test.index)\n",
    "\n",
    "m3_quarterly_test = m3_quarterly.groupby(\"unique_id\", as_index=False).tail(horizon_quarterly)\n",
    "m3_quarterly_train = m3_quarterly.drop(m3_quarterly_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Aggregating the dataset according to temporal hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the temporal aggregation spec. The spec is a dictionary in which the keys are the name of the aggregation and the value is the amount of bottom-level timesteps that should be aggregated in that aggregation. For example, `year` consists of `12` months, so we define a key, value pair `\"yearly\":12`. We can do something similar for other aggregations that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_temporal_monthly = {\"yearly\": 12, \"semiannually\": 6, \"fourmonthly\": 4, \"quarterly\": 3, \"bimonthly\": 2, \"monthly\": 1}\n",
    "spec_temporal_quarterly = {\"yearly\": 4, \"semiannually\": 2, \"quarterly\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compute the temporally aggregated train- and test sets using the `aggregate_temporal` function. Note that we have different aggregation matrices `S` for the train- and test set, as the test set contains temporal hierarchies that are not included in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import aggregate_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly\n",
    "Y_monthly_train, S_monthly_train, tags_monthly_train = aggregate_temporal(df=m3_monthly_train, spec=spec_temporal_monthly)\n",
    "Y_monthly_test, S_monthly_test, tags_monthly_test = aggregate_temporal(df=m3_monthly_test, spec=spec_temporal_monthly)\n",
    "\n",
    "# Quarterly\n",
    "Y_quarterly_train, S_quarterly_train, tags_quarterly_train = aggregate_temporal(df=m3_quarterly_train, spec=spec_temporal_quarterly)\n",
    "Y_quarterly_test, S_quarterly_test, tags_quarterly_test = aggregate_temporal(df=m3_quarterly_test,  spec=spec_temporal_quarterly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aggregation matrices aggregate the lowest temporal granularity (quarters) up to years, for the train- and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_monthly_train.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_monthly_test.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Computing base forecasts\n",
    "\n",
    "Now, we need to compute base forecasts for each temporal aggregation. The following cell computes the **base forecasts** for each temporal aggregation in `Y_monthly_train` and `Y_quarterly_train` using the `AutoARIMA` model. Observe that `Y_hats` contains the forecasts but they are not coherent.\n",
    "\n",
    "Note also that both frequency and horizon are different for each temporal aggregation. For the monthly data, the lowest level has a monthly frequency, and a horizon of `24` (constituting 2 years). However, as example, the `year` aggregation has a yearly frequency with a horizon of 2.\n",
    "\n",
    "It is of course possible to choose a different model for each level in the temporal aggregation - you can be as creative as you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast.core import StatsForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hats = []\n",
    "id_cols = [\"unique_id\", \"temporal_id\", \"ds\", \"y\"]\n",
    "\n",
    "# We loop over the monthly and quarterly data\n",
    "for tags_train, tags_test, Y_train, Y_test in zip([tags_monthly_train, tags_quarterly_train], \n",
    "                                                  [tags_monthly_test, tags_quarterly_test],\n",
    "                                                  [Y_monthly_train, Y_quarterly_train], \n",
    "                                                  [Y_monthly_test, Y_quarterly_test]):\n",
    "    # We will train a model for each temporal level\n",
    "    Y_hats_tags = []\n",
    "    for level, temporal_ids_train in tags_train.items():\n",
    "        # Filter the data for the level\n",
    "        Y_level_train = Y_train.query(\"temporal_id in @temporal_ids_train\")\n",
    "        temporal_ids_test = tags_test[level]\n",
    "        Y_level_test = Y_test.query(\"temporal_id in @temporal_ids_test\")\n",
    "        # For each temporal level we have a different frequency and forecast horizon. We use the timestamps of the first timeseries to automatically derive the frequency & horizon of the temporally aggregated series.\n",
    "        unique_id = Y_level_train[\"unique_id\"].iloc[0]\n",
    "        freq_level = pd.infer_freq(Y_level_train.query(\"unique_id == @unique_id\")[\"ds\"])\n",
    "        horizon_level = Y_level_test.query(\"unique_id == @unique_id\")[\"ds\"].nunique()\n",
    "        # Train a model and create forecasts\n",
    "        fcst = StatsForecast(models=[AutoARIMA()], freq=freq_level, n_jobs=-1)\n",
    "        Y_hat_level = fcst.forecast(df=Y_level_train[[\"ds\", \"unique_id\", \"y\"]], h=horizon_level)\n",
    "        # Add the test set to the forecast\n",
    "        Y_hat_level = pd.concat([Y_level_test.reset_index(drop=True), Y_hat_level.drop(columns=[\"unique_id\", \"ds\"])], axis=1)\n",
    "        # Put cols in the right order (for readability)\n",
    "        Y_hat_cols = id_cols + [col for col in Y_hat_level.columns if col not in id_cols]\n",
    "        Y_hat_level = Y_hat_level[Y_hat_cols]\n",
    "        # Append the forecast to the list\n",
    "        Y_hats_tags.append(Y_hat_level)\n",
    "\n",
    "    Y_hat_tag = pd.concat(Y_hats_tags, ignore_index=True)\n",
    "    Y_hats.append(Y_hat_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Reconcile forecasts\n",
    "\n",
    "We can use the `HierarchicalReconciliation` class to reconcile the forecasts. In this example we use `BottomUp` and `MinTrace(wls_struct)`. The latter is the 'structural scaling' method introduced in [Forecasting with temporal hierarchies\n",
    "](https://robjhyndman.com/publications/temporal-hierarchies/). \n",
    "\n",
    "Note that we have to set `temporal=True` in the `reconcile` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, MinTrace\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method=\"wls_struct\"),\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_recs = []\n",
    "# We loop over the monthly and quarterly data\n",
    "for Y_hat, S, tags in zip(Y_hats, \n",
    "                          [S_monthly_test, S_quarterly_test], \n",
    "                          [tags_monthly_test, tags_quarterly_test]):\n",
    "    Y_rec = hrec.reconcile(Y_hat_df=Y_hat, S=S, tags=tags, temporal=True)\n",
    "    Y_recs.append(Y_rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes the `evaluate` function to evaluate the different hierarchies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the temporally aggregated forecasts _across all temporal aggregations_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Monthly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_monthly = Y_recs[0]\n",
    "evaluation = evaluate(df = Y_rec_monthly.drop(columns = 'unique_id'),\n",
    "                      tags = tags_monthly_test,\n",
    "                      metrics = [mae],\n",
    "                      id_col='temporal_id',\n",
    "                      benchmark=\"AutoARIMA\")\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp', 'MinTrace(wls_struct)']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MinTrace(wls_struct)` is the best overall method, scoring the lowest `mae` on all levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_quarterly = Y_recs[1]\n",
    "evaluation = evaluate(df = Y_rec_quarterly.drop(columns = 'unique_id'),\n",
    "                      tags = tags_quarterly_test,\n",
    "                      metrics = [mae],\n",
    "                      id_col='temporal_id',\n",
    "                      benchmark=\"AutoARIMA\")\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp', 'MinTrace(wls_struct)']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, `MinTrace(wls_struct)` is the best overall method, scoring the lowest `mae` on all levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
