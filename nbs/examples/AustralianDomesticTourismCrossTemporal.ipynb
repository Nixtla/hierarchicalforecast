{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical and Temporal Aggregation (Tourism)\n",
    "\n",
    "> Geographical and Temporal Hierarchical Forecasting on Australian Tourism Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, a set of time series is hierarchically organized. Examples include the presence of geographic levels, products, or categories that define different types of aggregations. In such scenarios, forecasters are often required to provide predictions for all disaggregate and aggregate series. A natural desire is for those predictions to be **\"coherent\"**, that is, for the bottom series to add up precisely to the forecasts of the aggregated series.\n",
    "\n",
    "In this notebook we present an example on how to use `HierarchicalForecast` to produce coherent forecasts between both geographical levels and temporal levels. We will use the classic Australian Domestic Tourism (`Tourism`) dataset, which contains monthly time series of the number of visitors to each state of Australia.\n",
    "\n",
    "We will first load the `Tourism` data and produce base forecasts using an `AutoETS` model from `StatsForecast`. Then, we reconciliate the forecasts with several reconciliation algorithms from `HierarchicalForecast` according to the cross-sectional geographical hierarchies. Finally, we reconciliate the forecasts in the temporal dimension according to a temporal hierarchy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/AustralianDomesticTourismCrossTemporal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast statsforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the [Tourism](https://otexts.com/fpp3/tourism.html) dataset from the [Forecasting: Principles and Practice](https://otexts.com/fpp3/) book.\n",
    "\n",
    "The dataset only contains the time series at the lowest level, so we need to create the time series for all hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "Y_df = Y_df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "Y_df.insert(0, 'Country', 'Australia')\n",
    "Y_df = Y_df[['Country', 'Region', 'State', 'Purpose', 'ds', 'y']]\n",
    "Y_df['ds'] = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(Y_df[\"ds\"], freq='Q').to_timestamp()\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-sectional reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Aggregating the dataset according to cross-sectional hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be grouped in the following non-strictly hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `aggregate` function from `HierarchicalForecast` we can get the full set of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df_cs, S_df_cs, tags_cs = aggregate(Y_df, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_df_cs.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Split Train/Test sets\n",
    "\n",
    "We use the final two years (8 quarters) as test set. Consequently, our forecast horizon=8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df_cs = Y_df_cs.groupby(\"unique_id\", as_index=False).tail(horizon)\n",
    "Y_train_df_cs = Y_df_cs.drop(Y_test_df_cs.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Computing base forecasts\n",
    "\n",
    "The following cell computes the **base forecasts** for each time series in `Y_df` using the `AutoETS` model. Observe that `Y_hat_df` contains the forecasts but they are not coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoETS\n",
    "from statsforecast.core import StatsForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(models=[AutoETS(season_length=4, model='ZZA')], \n",
    "                     freq='QS', n_jobs=-1)\n",
    "Y_hat_df_cs = fcst.forecast(df=Y_train_df_cs, h=horizon, fitted=True)\n",
    "Y_fitted_df_cs = fcst.forecast_fitted_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Reconcile forecasts\n",
    "\n",
    "The following cell makes the previous forecasts coherent using the `HierarchicalReconciliation` class. Since the hierarchy structure is not strict, we can't use methods such as `TopDown` or `MiddleOut`. In this example we use `BottomUp` and `MinTrace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, MinTrace\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols')\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df_cs = hrec.reconcile(Y_hat_df=Y_hat_df_cs, Y_df=Y_fitted_df_cs, S=S_df_cs, tags=tags_cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `Y_rec_df` contains the reconciled forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df_cs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we aim to reconcile our forecasts also in the temporal domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Aggregating the dataset according to temporal hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the temporal aggregation spec. You can use string aliases of timestamp attributes to compute temporal aggregations. For Pandas, see an overview of allowable attributes [here](https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html). \n",
    "\n",
    "In this example, we choose a temporal aggregation of `[\"year\"]` and the bottom level `[\"year\", \"ds\"]`. The bottom level timesteps have a quarterly frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_temporal = {\"year\": 4, \"quarter\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compute the temporally aggregated train- and test sets using the `aggregate_temporal` function. Note that we have different aggregation matrices `S` for the train- and test set, as the test set contains temporal hierarchies that are not included in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import aggregate_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df_te, S_train_df_te, tags_te_train = aggregate_temporal(df=Y_train_df_cs, spec=spec_temporal)\n",
    "Y_test_df_te, S_test_df_te, tags_te_test = aggregate_temporal(df=Y_test_df_cs, spec=spec_temporal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train_df_te.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_test_df_te.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a test set available, as is usually the case when you're making forecasts, it is necessary to create a future dataframe that holds the correct bottom-level unique_ids and timestamps so that they can be temporally aggregated. We can use the `make_future_dataframe` helper function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import make_future_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df_te_new = make_future_dataframe(Y_train_df_te, freq=\"QS\", h=horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Y_test_df_te_new` can be then used in `aggregate_temporal` to construct the temporally aggregated structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df_te_new, S_test_df_te_new, tags_te_test_new = aggregate_temporal(df=Y_test_df_te_new, spec=spec_temporal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can verify that we have the same temporally aggregated test set, except that `Y_df_te_test_new` doesn't contain the ground truth values `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df_te_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Computing base forecasts\n",
    "\n",
    "Now, we need to compute base forecasts for each temporal aggregation. The following cell computes the **base forecasts** for each temporal aggregation in `Y_train_df_te` using the `AutoETS` model. Observe that `Y_hat_df_te` contains the forecasts but they are not coherent.\n",
    "\n",
    "Note also that both frequency and horizon are different for each temporal aggregation. In this example, the lowest level has a quarterly frequency, and a horizon of `8` (constituting `2` years). The `year` aggregation thus has a yearly frequency with a horizon of `2`.\n",
    "\n",
    "It is of course possible to choose a different model for each level in the temporal aggregation - you can be as creative as you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_dfs_te = []\n",
    "id_cols = [\"unique_id\", \"temporal_id\", \"ds\", \"y\"]\n",
    "# We will train a model for each temporal level\n",
    "for level, temporal_ids_train in tags_te_train.items():\n",
    "    # Filter the data for the level\n",
    "    Y_level_train = Y_train_df_te.query(\"temporal_id in @temporal_ids_train\")\n",
    "    temporal_ids_test = tags_te_test[level]\n",
    "    Y_level_test = Y_test_df_te.query(\"temporal_id in @temporal_ids_test\")\n",
    "    # For each temporal level we have a different frequency and forecast horizon\n",
    "    freq_level = pd.infer_freq(Y_level_train[\"ds\"].unique())\n",
    "    horizon_level = Y_level_test[\"ds\"].nunique()\n",
    "    # Train a model and create forecasts\n",
    "    fcst = StatsForecast(models=[AutoETS(model='ZZZ')], freq=freq_level, n_jobs=-1)\n",
    "    Y_hat_df_te_level = fcst.forecast(df=Y_level_train[[\"ds\", \"unique_id\", \"y\"]], h=horizon_level)\n",
    "    # Add the test set to the forecast\n",
    "    Y_hat_df_te_level = Y_hat_df_te_level.merge(Y_level_test, on=[\"ds\", \"unique_id\"], how=\"left\")\n",
    "    # Put cols in the right order (for readability)\n",
    "    Y_hat_cols = id_cols + [col for col in Y_hat_df_te_level.columns if col not in id_cols]\n",
    "    Y_hat_df_te_level = Y_hat_df_te_level[Y_hat_cols]\n",
    "    # Append the forecast to the list\n",
    "    Y_hat_dfs_te.append(Y_hat_df_te_level)\n",
    "\n",
    "Y_hat_df_te = pd.concat(Y_hat_dfs_te, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Reconcile forecasts\n",
    "\n",
    "We can again use the `HierarchicalReconciliation` class to reconcile the forecasts. In this example we use `BottomUp` and `MinTrace`. Note that we have to set `temporal=True` in the `reconcile` function.\n",
    "\n",
    "Note that temporal reconcilation currently isn't supported for insample reconciliation methods, such as `MinTrace(method='mint_shrink')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method='ols')\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df_te = hrec.reconcile(Y_hat_df=Y_hat_df_te, S=S_test_df_te, tags=tags_te_test, temporal=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes the `evaluate` function to evaluate the different hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Cross-sectional evaluation\n",
    "\n",
    "We first evaluate the forecasts _across all cross-sectional aggregations_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['Total'] = tags_cs['Country']\n",
    "eval_tags['Purpose'] = tags_cs['Country/Purpose']\n",
    "eval_tags['State'] = tags_cs['Country/State']\n",
    "eval_tags['Regions'] = tags_cs['Country/State/Region']\n",
    "eval_tags['Bottom'] = tags_cs['Country/State/Region/Purpose']\n",
    "\n",
    "evaluation = evaluate(df = Y_rec_df_te.drop(columns = 'temporal_id'),\n",
    "                      tags = eval_tags,\n",
    "                      metrics = [rmse])\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp', 'MinTrace(ols)']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen `MinTrace(ols)` seems to be the best forecasting method across each cross-sectional aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Temporal evaluation\n",
    "\n",
    "We then evaluate the temporally aggregated forecasts _across all temporal aggregations_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['Year'] = tags_te_test['year']\n",
    "eval_tags['Quarter'] = tags_te_test['year/quarter']\n",
    "\n",
    "evaluation = evaluate(df = Y_rec_df_te.drop(columns = 'unique_id'),\n",
    "                      tags = eval_tags,\n",
    "                      metrics = [rmse],\n",
    "                      id_col=\"temporal_id\")\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp', 'MinTrace(ols)']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, `MinTrace(ols)` is the best overall method, scoring the lowest `rmse` on the `Quarter` aggregated forecasts, and being slightly worse than the `Base` forecasts on the `Year` aggregated forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Cross-temporal evaluation\n",
    "\n",
    "Finally, we evaluate cross-temporally. To do so, we first need to obtain the combination of cross-sectional and temporal hierarchies, for which we can use the `get_cross_temporal_tags` helper function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import get_cross_temporal_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df_te, tags_ct = get_cross_temporal_tags(Y_rec_df_te, tags_cs=tags_cs, tags_te=tags_te_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we now have a tag `Country//year` that contains `Australia//year-2016` and `Australia//year-2017`, indicating the cross-sectional hierarchy `Australia` at the temporal hierarchies `2016` and `2017`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our dataset and cross-temporal tags ready for evaluation.\n",
    "\n",
    "We again define a set of eval_tags, and now we split each cross-sectional aggregation also by each temporal aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['TotalByYear'] = tags_ct['Country//year']\n",
    "eval_tags['RegionsByYear'] = tags_ct['Country/State/Region//year']\n",
    "eval_tags['BottomByYear'] = tags_ct['Country/State/Region/Purpose//year']\n",
    "eval_tags['TotalByQuarter'] = tags_ct['Country//year/quarter']\n",
    "eval_tags['RegionsByQuarter'] = tags_ct['Country/State/Region//year/quarter']\n",
    "eval_tags['BottomByQuarter'] = tags_ct['Country/State/Region/Purpose//year/quarter']\n",
    "\n",
    "\n",
    "evaluation = evaluate(df = Y_rec_df_te.drop(columns=['unique_id', 'temporal_id']),\n",
    "                      tags = eval_tags,\n",
    "                      id_col = 'cross_temporal_id',\n",
    "                      metrics = [rmse])\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp', 'MinTrace(ols)']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the best method is the cross-temporally reconciled method `AutoETS/MinTrace_method-ols`, which achieves overall lowest RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition: \n",
    "Chapter 11: Forecasting hierarchical and grouped series.\". OTexts: Melbourne, Australia. OTexts.com/fpp3 \n",
    "Accessed on July 2022.](https://otexts.com/fpp3/hierarchical.html)\n",
    "- [Rob Hyndman, Alan Lee, Earo Wang, Shanika Wickramasuriya, and Maintainer Earo Wang (2021). \"hts: Hierarchical and Grouped Time Series\". URL https://CRAN.R-project.org/package=hts. R package version 0.3.1.](https://cran.r-project.org/web/packages/hts/index.html)\n",
    "- [Mitchell Oâ€™Hara-Wild, Rob Hyndman, Earo Wang, Gabriel Caceres, Tim-Gunnar Hensel, and Timothy Hyndman (2021). \"fable: Forecasting Models for Tidy Time Series\". URL https://CRAN.R-project.org/package=fable. R package version 6.0.2.](https://CRAN.R-project.org/package=fable)\n",
    "- [Athanasopoulos, G, Hyndman, Rob J., Kourentzes, N., Petropoulos, Fotios (2017). Forecasting with temporal hierarchies. European Journal of Operational Research, 262, 60-74](https://www.sciencedirect.com/science/article/pii/S0377221717301911)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
