{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical Aggregation (Tourism)\n",
    "\n",
    "> Geographical Hierarchical Forecasting on Australian Tourism Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, a set of time series is hierarchically organized. Examples include the presence of geographic levels, products, or categories that define different types of aggregations. In such scenarios, forecasters are often required to provide predictions for all disaggregate and aggregate series. A natural desire is for those predictions to be **\"coherent\"**, that is, for the bottom series to add up precisely to the forecasts of the aggregated series.\n",
    "\n",
    "In this notebook we present an example on how to use `HierarchicalForecast` to produce coherent forecasts between geographical levels. We will use the classic Australian Domestic Tourism (`Tourism`) dataset, which contains monthly time series of the number of visitors to each state of Australia.\n",
    "\n",
    "We will first load the Tourism data and produce base forecasts using a diverse set of models, including `AutoETS` from `StatsForecast`, and machine learning models like `lightgbm` and `HistGradientBoostingRegressor` using `MLForecast`, as well as neural network models like `MLP` and `NBEATS` from `NeuralForecast`. We will then reconcile these base forecasts with several reconciliation algorithms from `HierarchicalForecast`. \n",
    "\n",
    "Finally, we show the performance is comparable with the results reported by the [Forecasting: Principles and Practice](https://otexts.com/fpp3/tourism.html) which uses the R package [fable](https://github.com/tidyverts/fable)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/AustralianDomesticTourism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast statsforecast mlforecast datasetsforecast lightgbm sklearn neuralforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the [Tourism](https://otexts.com/fpp3/tourism.html) dataset from the [Forecasting: Principles and Practice](https://otexts.com/fpp3/) book.\n",
    "\n",
    "The dataset only contains the time series at the lowest level, so we need to create the time series for all hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "Y_df = Y_df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "Y_df.insert(0, 'Country', 'Australia')\n",
    "Y_df = Y_df[['Country', 'Region', 'State', 'Purpose', 'ds', 'y']]\n",
    "Y_df['ds'] = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(Y_df[\"ds\"], freq='Q').to_timestamp()\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be grouped in the following non-strictly hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `aggregate` function from `HierarchicalForecast` we can get the full set of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Y_df, S_df, tags = aggregate(Y_df, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags['Country/Purpose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test sets\n",
    "\n",
    "We use the final two years (8 quarters) as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df = Y_df.groupby('unique_id', as_index=False).tail(8)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df.groupby('unique_id').size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing base forecasts\n",
    "\n",
    "The following cell computes the **base forecasts** for each time series in `Y_df` using the `ETS` model. Observe that `Y_hat_df` contains the forecasts but they are not coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from statsforecast.models import AutoETS\n",
    "from statsforecast.core import StatsForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fcst = StatsForecast(models=[AutoETS(season_length=4, model='ZZA')], \n",
    "                     freq='QS', n_jobs=-1)\n",
    "Y_hat_df_stats = fcst.forecast(df=Y_train_df, h=8, fitted=True)\n",
    "Y_fitted_df_stats = fcst.forecast_fitted_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Computing MLForecast models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean, ExpandingStd\n",
    "from mlforecast.target_transforms import Differences\n",
    "from mlforecast import MLForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "mlf = MLForecast(\n",
    "    models = {\n",
    "        'lgbm': lgb.LGBMRegressor(verbosity=-1),\n",
    "        'gbm':HistGradientBoostingRegressor()\n",
    "    }, \n",
    "    freq='QS',\n",
    "    target_transforms=[Differences([1, 4])],\n",
    "    lags=[1, 2, 3, 4, 5, 6, 7, 8, 12],\n",
    "    lag_transforms={  \n",
    "        1: [ExpandingMean(), RollingMean(window_size=4)],\n",
    "        4: [ExpandingMean(), RollingMean(window_size=2), RollingMean(window_size=4)],\n",
    "        8: [RollingMean(window_size=4)]\n",
    "    },\n",
    "    date_features=['quarter', 'year']\n",
    ")\n",
    "mlf.fit(Y_train_df, fitted=True)\n",
    "Y_hat_df_ml = mlf.predict(new_df=Y_train_df, h=8)\n",
    "Y_fitted_df_ml = mlf.forecast_fitted_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Computing Neuralforecast models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP\n",
    "from neuralforecast.losses.pytorch import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NeuralForecast(\n",
    "    models=[\n",
    "        NBEATS(\n",
    "            h=4,\n",
    "            input_size=16,\n",
    "            mlp_units=[[256, 256], [256, 256], [256, 256]],\n",
    "            learning_rate=1e-3,\n",
    "            loss=MAE(),\n",
    "            random_seed=42\n",
    "        ),\n",
    "        MLP(\n",
    "            h=4,\n",
    "            input_size=16,\n",
    "            num_layers=2,\n",
    "            hidden_size=64,\n",
    "            max_steps=500,\n",
    "            learning_rate=1e-3,\n",
    "            loss=MAE(),\n",
    "            random_seed=42\n",
    "        )\n",
    "    ],\n",
    "    freq='QS'\n",
    ")\n",
    "nf.fit(df=Y_train_df, val_size=4)\n",
    "Y_hat_df_nf = nf.predict()\n",
    "Y_fitted_df_nf = nf.predict_insample(step_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Y_hat_df = Y_hat_df_stats.merge(Y_hat_df_ml, on=['unique_id', 'ds']).merge(Y_hat_df_nf, on=['unique_id', 'ds'])\n",
    "Y_fitted_df = Y_fitted_df_stats.merge(Y_fitted_df_ml.drop(columns=['y']), on=['unique_id', 'ds']).merge(Y_fitted_df_nf.drop(columns=['cutoff', 'y']), on=['unique_id', 'ds'], how=\"left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconcile forecasts\n",
    "\n",
    "The following cell makes the previous forecasts coherent using the `HierarchicalReconciliation` class. Since the hierarchy structure is not strict, we can't use methods such as `TopDown` or `MiddleOut`. In this example we use `BottomUp` and `MinTrace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, MinTrace\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols')\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S=S_df, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `Y_rec_df` contains the reconciled forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes an `evaluate` function to evaluate the different hierarchies and also is capable of compute scaled metrics compared to a benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import rmse, mase\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be cleaning the columns names and the following function will help us do it in a more structured way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_evaluation_columns(\n",
    "        evaluation_df: pd.DataFrame,\n",
    "        base_model_name: str = 'AutoETS',\n",
    "        other_model_names: list = ['AutoETS', 'lgbm', 'knn', 'gbm', 'NBEATS', 'MLP'],\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "    cleaned_column_mapping = {}\n",
    "\n",
    "    def _clean_recon_method(raw_name: str) -> str:\n",
    "        if raw_name.startswith('MinTrace_method-'):\n",
    "            method_part = raw_name.replace('MinTrace_method-', '')\n",
    "            return f\"MinTrace({method_part})\"\n",
    "        else:\n",
    "            return raw_name.replace('-', ' ')\n",
    "\n",
    "    for col in evaluation_df.columns:\n",
    "        if col in ['level', 'metric']:\n",
    "            cleaned_column_mapping[col] = col\n",
    "        elif col == base_model_name:\n",
    "            cleaned_column_mapping[col] = 'Base'\n",
    "        elif col.startswith(f'{base_model_name}/'): \n",
    "            recon_method_raw = col.split('/', 1)[1]\n",
    "            cleaned_column_mapping[col] = _clean_recon_method(recon_method_raw)\n",
    "        else: \n",
    "            is_other_base_model = False\n",
    "            for model in other_model_names:\n",
    "                if col == model:\n",
    "                    cleaned_column_mapping[col] = model\n",
    "                    is_other_base_model = True\n",
    "                    break\n",
    "            if is_other_base_model:\n",
    "                continue\n",
    "            \n",
    "            parts = col.split('/', 1)\n",
    "            if len(parts) == 2:\n",
    "                model_name = parts[0]\n",
    "                recon_method_raw = parts[1]\n",
    "                \n",
    "                recon_method_clean = _clean_recon_method(recon_method_raw)\n",
    "                \n",
    "                new_name = f\"{model_name} {recon_method_clean}\"\n",
    "                cleaned_column_mapping[col] = new_name\n",
    "            else:\n",
    "                cleaned_column_mapping[col] = col\n",
    "    \n",
    "    return evaluation_df.rename(columns=cleaned_column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['Total'] = tags['Country']\n",
    "eval_tags['Purpose'] = tags['Country/Purpose']\n",
    "eval_tags['State'] = tags['Country/State']\n",
    "eval_tags['Regions'] = tags['Country/State/Region']\n",
    "eval_tags['Bottom'] = tags['Country/State/Region/Purpose']\n",
    "\n",
    "df = Y_rec_df.merge(Y_test_df, on=['unique_id', 'ds'])\n",
    "evaluation = evaluate(df = df,\n",
    "                      tags = eval_tags,\n",
    "                      train_df = Y_train_df,\n",
    "                      metrics = [rmse,\n",
    "                                 partial(mase, seasonality=4)])\n",
    "\n",
    "evaluation = rename_evaluation_columns(evaluation)\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "\n",
    "The following table shows the performance measured using RMSE across levels for each reconciliation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.query('metric == \"rmse\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASE\n",
    "\n",
    "\n",
    "The following table shows the performance measured using MASE across levels for each reconciliation method. Focusing only in AutoETS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.query('metric == \"mase\"')[['level', 'metric', 'Base', 'BottomUp', 'MinTrace(mint_shrink)', 'MinTrace(ols)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.query('metric == \"mase\"')[['level', 'metric', 'Base', 'BottomUp', 'MinTrace(mint_shrink)', 'MinTrace(ols)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison fable\n",
    "\n",
    "Observe that we can recover the results reported by the [Forecasting: Principles and Practice](https://otexts.com/fpp3/tourism.html). The original results were calculated using the R package [fable](https://github.com/tidyverts/fable).\n",
    "\n",
    "![Fable's reconciliation results](./imgs/AustralianDomesticTourism-results-fable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition: \n",
    "Chapter 11: Forecasting hierarchical and grouped series.\". OTexts: Melbourne, Australia. OTexts.com/fpp3 \n",
    "Accessed on July 2022.](https://otexts.com/fpp3/hierarchical.html)\n",
    "- [Rob Hyndman, Alan Lee, Earo Wang, Shanika Wickramasuriya, and Maintainer Earo Wang (2021). \"hts: Hierarchical and Grouped Time Series\". URL https://CRAN.R-project.org/package=hts. R package version 0.3.1.](https://cran.r-project.org/web/packages/hts/index.html)\n",
    "- [Mitchell O’Hara-Wild, Rob Hyndman, Earo Wang, Gabriel Caceres, Tim-Gunnar Hensel, and Timothy Hyndman (2021). \"fable: Forecasting Models for Tidy Time Series\". URL https://CRAN.R-project.org/package=fable. R package version 6.0.2.](https://CRAN.R-project.org/package=fable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
