{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Probabilistic Reconciliation Methods Comparison\n",
                "\n",
                "This notebook compares the different probabilistic reconciliation methods available in HierarchicalForecast:\n",
                "- **Normality**: Gaussian-based, parametric approach\n",
                "- **Bootstrap**: Non-parametric residual resampling\n",
                "- **PERMBU**: Empirical copula-based with rank permutation\n",
                "- **Conformal**: Distribution-free with coverage guarantees under exchangeability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if needed\n",
                "# !pip install hierarchicalforecast statsforecast"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from statsforecast.models import AutoARIMA\n",
                "from statsforecast.core import StatsForecast\n",
                "\n",
                "from hierarchicalforecast.utils import aggregate\n",
                "from hierarchicalforecast.core import HierarchicalReconciliation\n",
                "from hierarchicalforecast.methods import BottomUp, MinTrace"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Prepare Data\n",
                "\n",
                "We use the Australian Tourism dataset for this example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load tourism data\n",
                "Y_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
                "Y_df = Y_df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
                "Y_df = Y_df[['Country', 'Region', 'State', 'Purpose', 'ds', 'y']]\n",
                "Y_df['ds'] = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
                "Y_df['ds'] = pd.PeriodIndex(Y_df[\"ds\"], freq='Q').to_timestamp()\n",
                "Y_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define hierarchical structure\n",
                "spec = [\n",
                "    ['Country'],\n",
                "    ['Country', 'State'],\n",
                "    ['Country', 'State', 'Region'],\n",
                "]\n",
                "\n",
                "Y_df, S_df, tags = aggregate(df=Y_df, spec=spec)\n",
                "print(f\"Hierarchy has {S_df.shape[0]} series ({S_df.shape[1]} bottom-level)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/test split\n",
                "Y_test_df = Y_df.groupby('unique_id').tail(8)\n",
                "Y_train_df = Y_df.drop(Y_test_df.index)\n",
                "\n",
                "print(f\"Training: {len(Y_train_df)} observations\")\n",
                "print(f\"Testing: {len(Y_test_df)} observations\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Compute Base Forecasts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit base forecaster\n",
                "fcst = StatsForecast(\n",
                "    models=[AutoARIMA(season_length=4)],\n",
                "    freq='QE',\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "# Get forecasts and fitted values for probabilistic methods\n",
                "Y_hat_df = fcst.forecast(df=Y_train_df, h=8, fitted=True)\n",
                "Y_fitted_df = fcst.forecast_fitted_values()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Probabilistic Reconciliation Methods\n",
                "\n",
                "### Method Comparison Table\n",
                "\n",
                "| Method | Assumptions | Speed | Use Case |\n",
                "|--------|-------------|-------|----------|\n",
                "| **Normality** | Gaussian errors | Fast | When normality holds, need analytical intervals |\n",
                "| **Bootstrap** | None (non-parametric) | Medium | General purpose, flexible |\n",
                "| **PERMBU** | Strictly hierarchical | Medium | Preserve empirical correlations |\n",
                "| **Conformal** | Exchangeability | Fast | Distribution-free coverage guarantees |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reconcile with different probabilistic methods\n",
                "reconcilers = [\n",
                "    MinTrace(method='ols'),\n",
                "]\n",
                "\n",
                "hrec = HierarchicalReconciliation(reconcilers=reconcilers)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normality-based intervals\n",
                "Y_rec_normality = hrec.reconcile(\n",
                "    Y_hat_df=Y_hat_df,\n",
                "    Y_df=Y_fitted_df,\n",
                "    S_df=S_df,\n",
                "    tags=tags,\n",
                "    level=[90],\n",
                "    intervals_method='normality'\n",
                ")\n",
                "print(\"Normality reconciliation complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bootstrap-based intervals\n",
                "Y_rec_bootstrap = hrec.reconcile(\n",
                "    Y_hat_df=Y_hat_df,\n",
                "    Y_df=Y_fitted_df,\n",
                "    S_df=S_df,\n",
                "    tags=tags,\n",
                "    level=[90],\n",
                "    intervals_method='bootstrap'\n",
                ")\n",
                "print(\"Bootstrap reconciliation complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conformal-based intervals\n",
                "Y_rec_conformal = hrec.reconcile(\n",
                "    Y_hat_df=Y_hat_df,\n",
                "    Y_df=Y_fitted_df,\n",
                "    S_df=S_df,\n",
                "    tags=tags,\n",
                "    level=[90],\n",
                "    intervals_method='conformal'\n",
                ")\n",
                "print(\"Conformal reconciliation complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Prediction Intervals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_intervals(series_id, ax, rec_df, method_name, color):\n",
                "    \"\"\"Helper to plot prediction intervals for a series.\"\"\"\n",
                "    df = rec_df[rec_df['unique_id'] == series_id].copy()\n",
                "    \n",
                "    col_mean = 'AutoARIMA/MinTrace_method-ols'\n",
                "    col_lo = f'{col_mean}-lo-90'\n",
                "    col_hi = f'{col_mean}-hi-90'\n",
                "    \n",
                "    ax.fill_between(df['ds'], df[col_lo], df[col_hi], alpha=0.3, color=color, label=f'{method_name} 90% PI')\n",
                "    ax.plot(df['ds'], df[col_mean], color=color, linewidth=2)\n",
                "\n",
                "# Plot comparison for top-level series\n",
                "series_id = 'Australia'\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "plot_intervals(series_id, axes[0], Y_rec_normality, 'Normality', 'blue')\n",
                "axes[0].set_title('Normality')\n",
                "axes[0].legend()\n",
                "\n",
                "plot_intervals(series_id, axes[1], Y_rec_bootstrap, 'Bootstrap', 'green')\n",
                "axes[1].set_title('Bootstrap')\n",
                "axes[1].legend()\n",
                "\n",
                "plot_intervals(series_id, axes[2], Y_rec_conformal, 'Conformal', 'orange')\n",
                "axes[2].set_title('Conformal')\n",
                "axes[2].legend()\n",
                "\n",
                "fig.suptitle(f'Prediction Intervals Comparison: {series_id}')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Method Pros and Cons\n",
                "\n",
                "### Normality\n",
                "**Pros:**\n",
                "- Fast computation using closed-form solutions\n",
                "- Well-understood theoretical properties\n",
                "- Works with any reconciliation method\n",
                "\n",
                "**Cons:**\n",
                "- Assumes Gaussian distribution of errors\n",
                "- May underestimate uncertainty for heavy-tailed distributions\n",
                "\n",
                "---\n",
                "\n",
                "### Bootstrap\n",
                "**Pros:**\n",
                "- Non-parametric, no distributional assumptions\n",
                "- Captures empirical error distribution\n",
                "- Flexible and widely applicable\n",
                "\n",
                "**Cons:**\n",
                "- Requires sufficient historical residuals\n",
                "- Computationally more expensive than Normality\n",
                "\n",
                "---\n",
                "\n",
                "### PERMBU\n",
                "**Pros:**\n",
                "- Preserves empirical dependencies using copulas\n",
                "- Respects marginal distributions\n",
                "\n",
                "**Cons:**\n",
                "- Only works with strictly hierarchical structures\n",
                "- Computationally intensive for large hierarchies\n",
                "\n",
                "---\n",
                "\n",
                "### Conformal\n",
                "**Pros:**\n",
                "- Distribution-free (no parametric assumptions)\n",
                "- Valid coverage under exchangeability\n",
                "- Simple to implement and interpret\n",
                "\n",
                "**Cons:**\n",
                "- Requires exchangeability assumption\n",
                "- May produce wider intervals than well-specified parametric methods\n",
                "- Coverage guarantees are marginal, not simultaneous"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Recommendations\n",
                "\n",
                "| Scenario | Recommended Method |\n",
                "|----------|-------------------|\n",
                "| Quick analysis, Gaussian errors expected | Normality |\n",
                "| Unknown error distribution, general use | Bootstrap |\n",
                "| Strict hierarchies, preserve correlations | PERMBU |\n",
                "| Need coverage guarantees, no assumptions | Conformal |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}