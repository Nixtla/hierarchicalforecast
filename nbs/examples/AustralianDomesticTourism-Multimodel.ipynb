{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model Aggregation\n",
    "\n",
    "> Geographical Hierarchical Forecasting on Australian Tourism Data using multiple models for each level in the hierarchy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extends the classic Australian Domestic Tourism (`Tourism`) geographical aggregation example to showcase how `HierarchicalForecast` can be used to produce coherent forecasts when **different forecasting models are applied at each level of the hierarchy**. We will use the `Tourism` dataset, which contains monthly time series of the number of visitors to each state of Australia.\n",
    "\n",
    "Specifically, we will demonstrate fitting a diverse set of models across the hierarchical levels. This includes statistical models like `AutoETS` from `StatsForecast`, machine learning models such as `HistGradientBoostingRegressor` using `MLForecast`, and neural network models like `NBEATS` from `NeuralForecast`. After generating these base forecasts, we will reconcile them using `BottomUp`, `MinTrace(mint_shrink)`, `TopDown(forecast_proportions)` reconciliators from `HierarchicalForecast`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href='https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/AustralianDomesticTourism-Multimodel.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast statsforecast mlforecast datasetsforecast neuralforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the [Tourism](https://otexts.com/fpp3/tourism.html) dataset from the [Forecasting: Principles and Practice](https://otexts.com/fpp3/) book.\n",
    "\n",
    "The dataset only contains the time series at the lowest level, so we need to create the time series for all hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>State</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>658.553895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>449.853935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-07-01</td>\n",
       "      <td>592.904597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-10-01</td>\n",
       "      <td>524.242760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>548.394105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country    Region            State         ds           y\n",
       "0  Australia  Adelaide  South Australia 1998-01-01  658.553895\n",
       "1  Australia  Adelaide  South Australia 1998-04-01  449.853935\n",
       "2  Australia  Adelaide  South Australia 1998-07-01  592.904597\n",
       "3  Australia  Adelaide  South Australia 1998-10-01  524.242760\n",
       "4  Australia  Adelaide  South Australia 1999-01-01  548.394105"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "Y_df = Y_df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "Y_df.insert(0, 'Country', 'Australia')\n",
    "Y_df = Y_df[['Country', 'Region', 'State', 'ds', 'y']]\n",
    "Y_df['ds'] = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(Y_df['ds'], freq='Q').to_timestamp()\n",
    "Y_df_first = Y_df.groupby(['Country', 'Region', 'State', 'ds'], as_index=False).agg({'y':'sum'})\n",
    "Y_df_first.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be grouped in the following hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'],\n",
    "    ['Country', 'State', 'Region']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `aggregate` function from `HierarchicalForecast` we can get the full set of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, S_df, tags = aggregate(Y_df_first, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test sets\n",
    "\n",
    "We use the final two years (8 quarters) as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df = Y_df.groupby('unique_id', as_index=False).tail(8)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing different models for different hierarchies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we illustrate how to fit a different type of model for each level of the hierarchy. In particular, for each level, we will fit the following models:\n",
    "\n",
    "* **Country**: `AutoETS` model from `StatsForecast`.\n",
    "* **Country/State**: `HistGradientBoostingRegressor` model from `scikit-learn` through the `MLForecast` API.\n",
    "* **Country/State/Region**: `NBEATS` model from `NeuralForecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoETS\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `fit_predict_any_models` function is a helper function for training and forecasting with models from `StatsForecast`, `MLForecast`, and `NeuralForecast`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_any_models(models, df, h):\n",
    "    if isinstance(models, StatsForecast):\n",
    "        yhat = models.forecast(df=df, h=h, fitted=True)\n",
    "        yfitted = models.forecast_fitted_values()\n",
    "    elif isinstance(models, MLForecast):\n",
    "        models.fit(df, fitted=True)\n",
    "        yhat = models.predict(new_df=df, h=h)\n",
    "        yfitted = models.forecast_fitted_values()\n",
    "\n",
    "    elif isinstance(models, NeuralForecast):\n",
    "        models.fit(df=df, val_size=h)\n",
    "        yhat = models.predict()\n",
    "        yfitted = models.predict_insample(step_size=h)\n",
    "        yfitted = yfitted.drop(columns=['cutoff'])\n",
    "    else:\n",
    "        raise ValueError(\"Model is not a StatsForecast, MLForecast or NeuralForecast object.\")\n",
    "\n",
    "    return yhat, yfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the models that we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "h = 8\n",
    "stat_models = StatsForecast(models=[AutoETS(season_length=4, model='ZZA')], freq='QS', n_jobs=-1)\n",
    "ml_models = MLForecast(models = [HistGradientBoostingRegressor()], freq='QS', lags=[1, 4])\n",
    "neural_models = NeuralForecast(models=[NBEATS(h=h, input_size=16)],freq='QS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined a hierarchy consisting of three levels. We will use the different model types for each of the levels in the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Country': stat_models,\n",
    "    'Country/State': ml_models,\n",
    "    'Country/State/Region': neural_models\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit each model and create forecasts with it, we loop over the timeseries that are present in each level of the hierarchy, using the `tags` we created earlier using the `aggregate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Y_hat = []\n",
    "Y_fitted = []\n",
    "# We loop through the tags to fit and predict for each level of the hierarchy.\n",
    "for key, value in tags.items():\n",
    "    # We filter the training dataframe for the current level of the hierarchy.\n",
    "    df_level = Y_train_df.query('unique_id.isin(@value)')\n",
    "    # We fit and predict using the corresponding model for the current level.\n",
    "    yhat_level, yfitted_level = fit_predict_any_models(models[key], df_level, h=h)\n",
    "    # We add the predictions for this level\n",
    "    Y_hat.append(yhat_level)\n",
    "    Y_fitted.append(yfitted_level)\n",
    "\n",
    "# Concatenate the predictions for all levels into a single DataFrame\n",
    "Y_hat_df = pd.concat(Y_hat, ignore_index=True)\n",
    "Y_fitted_df = pd.concat(Y_fitted, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created forecasts for different levels of the hierarchy, using different model types. Let's look at the forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoETS</th>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <th>NBEATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia/ACT</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>571.433902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia/ACT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>548.060532</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id         ds       AutoETS  HistGradientBoostingRegressor  \\\n",
       "0      Australia 2016-01-01  25990.068004                            NaN   \n",
       "1      Australia 2016-04-01  24458.490282                            NaN   \n",
       "2      Australia 2016-07-01  23974.055984                            NaN   \n",
       "3      Australia 2016-10-01  24563.454495                            NaN   \n",
       "4      Australia 2017-01-01  25990.068004                            NaN   \n",
       "5      Australia 2017-04-01  24458.490282                            NaN   \n",
       "6      Australia 2017-07-01  23974.055984                            NaN   \n",
       "7      Australia 2017-10-01  24563.454495                            NaN   \n",
       "8  Australia/ACT 2016-01-01           NaN                     571.433902   \n",
       "9  Australia/ACT 2016-04-01           NaN                     548.060532   \n",
       "\n",
       "   NBEATS  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "5     NaN  \n",
       "6     NaN  \n",
       "7     NaN  \n",
       "8     NaN  \n",
       "9     NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `AutoETS` only has entries for the `unique_id=Australia`, which is because we only created forecasts for the level `Country` using `AutoETS`. \n",
    "\n",
    "Secondly, we also only have forecasts using `HistGradientBoostingRegressor` for timeseries in the level `Country/State`, again as we only created forecasts for the level `Country/State` using `HistGradientBoostingRegressor`.\n",
    "\n",
    "Finally, `NBEATS` shows no forecasts at all in this view, but when we look at the tail of the predictions we see that `NBEATS` only has forecasts for the level `Country/State/Region`, which was also what we intended to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoETS</th>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <th>NBEATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Australia/Western Australia/Australia's South ...</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.720154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Australia/Western Australia/Australia's South ...</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>605.681030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1139.827393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017.152527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>917.289673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1141.263062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134.063477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1021.346558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839.628418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Australia/Western Australia/Experience Perth</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>972.161499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             unique_id         ds  AutoETS  \\\n",
       "670  Australia/Western Australia/Australia's South ... 2017-07-01      NaN   \n",
       "671  Australia/Western Australia/Australia's South ... 2017-10-01      NaN   \n",
       "672       Australia/Western Australia/Experience Perth 2016-01-01      NaN   \n",
       "673       Australia/Western Australia/Experience Perth 2016-04-01      NaN   \n",
       "674       Australia/Western Australia/Experience Perth 2016-07-01      NaN   \n",
       "675       Australia/Western Australia/Experience Perth 2016-10-01      NaN   \n",
       "676       Australia/Western Australia/Experience Perth 2017-01-01      NaN   \n",
       "677       Australia/Western Australia/Experience Perth 2017-04-01      NaN   \n",
       "678       Australia/Western Australia/Experience Perth 2017-07-01      NaN   \n",
       "679       Australia/Western Australia/Experience Perth 2017-10-01      NaN   \n",
       "\n",
       "     HistGradientBoostingRegressor       NBEATS  \n",
       "670                            NaN   416.720154  \n",
       "671                            NaN   605.681030  \n",
       "672                            NaN  1139.827393  \n",
       "673                            NaN  1017.152527  \n",
       "674                            NaN   917.289673  \n",
       "675                            NaN  1141.263062  \n",
       "676                            NaN  1134.063477  \n",
       "677                            NaN  1021.346558  \n",
       "678                            NaN   839.628418  \n",
       "679                            NaN   972.161499  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconcile forecasts\n",
    "\n",
    "First, we need to make sure we have one forecast column containing all the forecasts across all the levels, as we want to reconcile the forecasts across the levels. We do so by taking the mean across the forecast columns. In this case, because there's only a single entry for each unique_id, it would be equivalent to just combine or sum the forecast columns. However, you might want to use more than one model _per level_ in the hierarchy. In that case, you'd need to think about how to ensemble the multiple forecasts - a simple mean ensemble generally works well in those cases, so you can directly use the below code also for the more complex case where you have multiple models for each level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_cols = [col for col in Y_hat_df.columns if col not in ['unique_id', 'ds', 'y']]\n",
    "Y_hat_df[\"all_forecasts\"] = Y_hat_df[forecast_cols].mean(axis=1)\n",
    "Y_fitted_df[\"all_forecasts\"] = Y_fitted_df[forecast_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we now have a single column `all_forecasts` that includes the forecasts across all the levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoETS</th>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <th>NBEATS</th>\n",
       "      <th>all_forecasts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25990.068004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24458.490282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23974.055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24563.454495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25990.068004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24458.490282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23974.055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24563.454495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia/ACT</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>571.433902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>571.433902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia/ACT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>548.060532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>548.060532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id         ds       AutoETS  HistGradientBoostingRegressor  \\\n",
       "0      Australia 2016-01-01  25990.068004                            NaN   \n",
       "1      Australia 2016-04-01  24458.490282                            NaN   \n",
       "2      Australia 2016-07-01  23974.055984                            NaN   \n",
       "3      Australia 2016-10-01  24563.454495                            NaN   \n",
       "4      Australia 2017-01-01  25990.068004                            NaN   \n",
       "5      Australia 2017-04-01  24458.490282                            NaN   \n",
       "6      Australia 2017-07-01  23974.055984                            NaN   \n",
       "7      Australia 2017-10-01  24563.454495                            NaN   \n",
       "8  Australia/ACT 2016-01-01           NaN                     571.433902   \n",
       "9  Australia/ACT 2016-04-01           NaN                     548.060532   \n",
       "\n",
       "   NBEATS  all_forecasts  \n",
       "0     NaN   25990.068004  \n",
       "1     NaN   24458.490282  \n",
       "2     NaN   23974.055984  \n",
       "3     NaN   24563.454495  \n",
       "4     NaN   25990.068004  \n",
       "5     NaN   24458.490282  \n",
       "6     NaN   23974.055984  \n",
       "7     NaN   24563.454495  \n",
       "8     NaN     571.433902  \n",
       "9     NaN     548.060532  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to make the forecasts coherent using the `HierarchicalReconciliation` class. In this example we use `BottomUp`, `MinTrace(mint_shrink)`, `TopDown(forecast_proportions)` reconcilers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, MinTrace, TopDown\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    TopDown(method='forecast_proportions')\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df[[\"unique_id\", \"ds\", \"all_forecasts\"]], Y_df=Y_fitted_df[[\"unique_id\", \"ds\", \"y\", \"all_forecasts\"]], S_df=S_df, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `Y_rec_df` contains the reconciled forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>all_forecasts</th>\n",
       "      <th>all_forecasts/BottomUp</th>\n",
       "      <th>all_forecasts/MinTrace_method-mint_shrink</th>\n",
       "      <th>all_forecasts/TopDown_method-forecast_proportions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>24916.914513</td>\n",
       "      <td>25959.517939</td>\n",
       "      <td>25990.068004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>22867.133526</td>\n",
       "      <td>24656.012177</td>\n",
       "      <td>24458.490282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>22845.050221</td>\n",
       "      <td>24933.182437</td>\n",
       "      <td>23974.055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>23901.916314</td>\n",
       "      <td>26382.869677</td>\n",
       "      <td>24563.454495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>25246.089151</td>\n",
       "      <td>26923.282464</td>\n",
       "      <td>25990.068004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds  all_forecasts  all_forecasts/BottomUp  \\\n",
       "0  Australia 2016-01-01   25990.068004            24916.914513   \n",
       "1  Australia 2016-04-01   24458.490282            22867.133526   \n",
       "2  Australia 2016-07-01   23974.055984            22845.050221   \n",
       "3  Australia 2016-10-01   24563.454495            23901.916314   \n",
       "4  Australia 2017-01-01   25990.068004            25246.089151   \n",
       "\n",
       "   all_forecasts/MinTrace_method-mint_shrink  \\\n",
       "0                               25959.517939   \n",
       "1                               24656.012177   \n",
       "2                               24933.182437   \n",
       "3                               26382.869677   \n",
       "4                               26923.282464   \n",
       "\n",
       "   all_forecasts/TopDown_method-forecast_proportions  \n",
       "0                                       25990.068004  \n",
       "1                                       24458.490282  \n",
       "2                                       23974.055984  \n",
       "3                                       24563.454495  \n",
       "4                                       25990.068004  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_rec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes an `evaluate` function to evaluate the different hierarchies. To evaluate models we use `mase` metric and compare it to base predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mase\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['Total'] = tags['Country']\n",
    "eval_tags['State'] = tags['Country/State']\n",
    "eval_tags['Regions'] = tags['Country/State/Region']\n",
    "\n",
    "df = Y_rec_df.merge(Y_test_df, on=['unique_id', 'ds'])\n",
    "evaluation = evaluate(df = df,\n",
    "                      tags = eval_tags,\n",
    "                      train_df = Y_train_df,\n",
    "                      metrics = [partial(mase, seasonality=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>metric</th>\n",
       "      <th>all_forecasts</th>\n",
       "      <th>all_forecasts/BottomUp</th>\n",
       "      <th>all_forecasts/MinTrace_method-mint_shrink</th>\n",
       "      <th>all_forecasts/TopDown_method-forecast_proportions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.589074</td>\n",
       "      <td>3.002085</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>1.589074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>mase</td>\n",
       "      <td>2.166374</td>\n",
       "      <td>1.905035</td>\n",
       "      <td>1.882345</td>\n",
       "      <td>2.361169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regions</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.342429</td>\n",
       "      <td>1.342429</td>\n",
       "      <td>1.423867</td>\n",
       "      <td>1.458773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overall</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.422878</td>\n",
       "      <td>1.414905</td>\n",
       "      <td>1.455446</td>\n",
       "      <td>1.545237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level metric  all_forecasts  all_forecasts/BottomUp  \\\n",
       "0    Total   mase       1.589074                3.002085   \n",
       "1    State   mase       2.166374                1.905035   \n",
       "2  Regions   mase       1.342429                1.342429   \n",
       "3  Overall   mase       1.422878                1.414905   \n",
       "\n",
       "   all_forecasts/MinTrace_method-mint_shrink  \\\n",
       "0                                   0.440261   \n",
       "1                                   1.882345   \n",
       "2                                   1.423867   \n",
       "3                                   1.455446   \n",
       "\n",
       "   all_forecasts/TopDown_method-forecast_proportions  \n",
       "0                                           1.589074  \n",
       "1                                           2.361169  \n",
       "2                                           1.458773  \n",
       "3                                           1.545237  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that:\n",
    "\n",
    "- **No Single Best Method**: The results indicate that there is no universally superior reconciliation method. The optimal choice depends on which level of the hierarchy is most important.\n",
    "- **MinTrace for Country and Country/State**: The `MinTrace(mint_shrink)` reconciler shows best performance for the upper levels of the hierarchy, reducing the MASE from 1.59 (base forecast) to just 0.44. \n",
    "- **BottomUp for Country/State/Region and Overall**: The `BottomUp` method preserves only the NBEATS forecast of the most granular **Country/State/Regions** level, and aggregates those forecasts for the upper levels. It yields the **best Overall MASE score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recap\n",
    "\n",
    "This notebook demonstrated the power and flexibility of HierarchicalForecast in a multi-model forecasting scenario.\n",
    "\n",
    "In this example we fitted:\n",
    "\n",
    "- `StatsForecast` with `AutoETS` model for the **Country** level.\n",
    "- `MLForecast` with `HistGradientBoostingRegressor` model for the **Country/State** level.\n",
    "- `NeuralForecast` with `NBEATS` model for the **Country/State/Region** level. \n",
    "\n",
    "We then combined the results into a single prediction.\n",
    "\n",
    "For the reconciliation of the forecasts, we used `HierarchicalReconciliation` with three different methods:\n",
    "\n",
    "- `BottomUp`\n",
    "- `MinTrace(method='mint_shrink')`\n",
    "- `TopDown(method='forecast_proportions')`\n",
    "\n",
    "Finally, we evaluated the performance of these reconciliation methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
