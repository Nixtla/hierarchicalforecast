{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model Aggregation\n",
    "\n",
    "> Geographical Hierarchical Forecasting on Australian Tourism Data using multiple models for each level in the hierarchy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extends the classic Australian Domestic Tourism (`Tourism`) geographical aggregation example to showcase how `HierarchicalForecast` can be used to produce coherent forecasts when **different forecasting models are applied at each level of the hierarchy**. We will use the `Tourism` dataset, which contains monthly time series of the number of visitors to each state of Australia.\n",
    "\n",
    "Specifically, we will demonstrate fitting a diverse set of models across the hierarchical levels. This includes statistical models like `AutoETS` from `StatsForecast`, machine learning models such as `HistGradientBoostingRegressor` using `MLForecast`, and neural network models like `NBEATS` from `NeuralForecast`. After generating these base forecasts, we will reconcile them using `BottomUp`, `MinTrace(mint_shrink)`, `TopDown(forecast_proportions)` reconciliators from `HierarchicalForecast`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href='https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/AustralianDomesticTourism-Multimodel.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast statsforecast mlforecast datasetsforecast sklearn neuralforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the [Tourism](https://otexts.com/fpp3/tourism.html) dataset from the [Forecasting: Principles and Practice](https://otexts.com/fpp3/) book.\n",
    "\n",
    "The dataset only contains the time series at the lowest level, so we need to create the time series for all hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>State</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>658.553895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>449.853935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-07-01</td>\n",
       "      <td>592.904597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-10-01</td>\n",
       "      <td>524.242760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>548.394105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country    Region            State         ds           y\n",
       "0  Australia  Adelaide  South Australia 1998-01-01  658.553895\n",
       "1  Australia  Adelaide  South Australia 1998-04-01  449.853935\n",
       "2  Australia  Adelaide  South Australia 1998-07-01  592.904597\n",
       "3  Australia  Adelaide  South Australia 1998-10-01  524.242760\n",
       "4  Australia  Adelaide  South Australia 1999-01-01  548.394105"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "Y_df = Y_df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "Y_df.insert(0, 'Country', 'Australia')\n",
    "Y_df = Y_df[['Country', 'Region', 'State', 'ds', 'y']]\n",
    "Y_df['ds'] = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(Y_df['ds'], freq='Q').to_timestamp()\n",
    "Y_df_first = Y_df.groupby(['Country', 'Region', 'State', 'ds'], as_index=False).agg({'y':'sum'})\n",
    "Y_df_first.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be grouped in the following hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'],\n",
    "    ['Country', 'State', 'Region']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `aggregate` function from `HierarchicalForecast` we can get the full set of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, S_df, tags = aggregate(Y_df_first, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test sets\n",
    "\n",
    "We use the final two years (8 quarters) as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df = Y_df.groupby('unique_id', as_index=False).tail(8)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing different models for different hierarchies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we illustrate how to fit a different type of model for each level of the hierarchy. In particular, for each level, we will fit the following models:\n",
    "\n",
    "* **Country**: `AutoETS` model from `StatsForecast`.\n",
    "* **Country/State**: `HistGradientBoostingRegressor` model from `scikit-learn` through the `MLForecast` API.\n",
    "* **Country/State/Region**: `NBEATS` model from `NeuralForecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoETS\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS\n",
    "\n",
    "# The following helps suppress the Pytorch logging information\n",
    "import logging  \n",
    "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)  \n",
    "logging.getLogger('lightning_fabric').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `fit_predict_any_models` function provides a unified interface for training and forecasting with models from `StatsForecast`, `MLForecast`, and `NeuralForecast`. By abstracting away the specific fit and predict methods of each library, it simplifies the process of applying diverse model types across different levels of a hierarchy. This utility streamlines the experimentation and implementation of multi-model hierarchical forecasting strategies, enhancing code readability and reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_any_models(models: StatsForecast | MLForecast | NeuralForecast, df: pd.DataFrame, h:int):\n",
    "    if isinstance(models, StatsForecast):\n",
    "        yhat = models.forecast(df=df, h=h, fitted=True)\n",
    "        yfitted = models.forecast_fitted_values()\n",
    "\n",
    "    elif isinstance(models, MLForecast):\n",
    "        models.fit(df, fitted=True)\n",
    "        yhat = models.predict(new_df=df, h=h)\n",
    "        yfitted = models.forecast_fitted_values()\n",
    "\n",
    "    elif isinstance(models, NeuralForecast):\n",
    "        models.fit(df=df, val_size=h)\n",
    "        yhat = models.predict()\n",
    "        yfitted = models.predict_insample(step_size=h)\n",
    "\n",
    "    else:\n",
    "        print('Model is not a StatsForecast, MLForecast or NeuralForecast object.')\n",
    "\n",
    "    return yhat, yfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "stat_models = StatsForecast(models=[AutoETS(season_length=4, model='ZZA')], freq='QS', n_jobs=-1)\n",
    "ml_models = MLForecast(models = {'gbm': HistGradientBoostingRegressor()}, freq='QS', lags=[1, 4])\n",
    "neural_models = NeuralForecast(models=[NBEATS(h=8, input_size=16, learning_rate=1e-3, enable_progress_bar=False, logger=False, enable_model_summary=False)],freq='QS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Country': stat_models,\n",
    "    'Country/State': ml_models,\n",
    "    'Country/State/Region': neural_models\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we only have one model per type of `Forecast` however it may be useful to determine which one is the best and which one we'll be using in each level, i.e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\n",
    "    'Country': 'AutoETS',\n",
    "    'Country/State': 'gbm',\n",
    "    'Country/State/Region': 'NBEATS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Y_hat = []\n",
    "Y_fitted = []\n",
    "\n",
    "for key, value in tags.items():\n",
    "    df_level = Y_train_df.query('unique_id.isin(@value)')\n",
    "    yhat_level, yfitted_level = fit_predict_any_models(models[key], df_level, h=8)\n",
    "    \n",
    "    yhat_level = yhat_level[['unique_id', 'ds', best_models[key]]].rename(columns={best_models[key]: 'best_pred'})\n",
    "    yfitted_level = yfitted_level[['unique_id', 'ds', 'y', best_models[key]]].rename(columns={best_models[key]: 'best_pred'})\n",
    "\n",
    "    Y_hat.append(yhat_level)\n",
    "    Y_fitted.append(yfitted_level)\n",
    "\n",
    "Y_hat_df = pd.concat(Y_hat, ignore_index=True)\n",
    "Y_fitted_df = pd.concat(Y_fitted, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconcile forecasts\n",
    "\n",
    "The following cell makes the previous forecasts coherent using the `HierarchicalReconciliation` class. In this example we use `BottomUp`, `MinTrace(mint_shrink)`, `TopDown(forecast_proportions)` reconcilers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, MinTrace, TopDown\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    TopDown(method='forecast_proportions')\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S=S_df, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `Y_rec_df` contains the reconciled forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>best_pred</th>\n",
       "      <th>best_pred/BottomUp</th>\n",
       "      <th>best_pred/MinTrace_method-mint_shrink</th>\n",
       "      <th>best_pred/TopDown_method-forecast_proportions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>24776.339488</td>\n",
       "      <td>26205.549950</td>\n",
       "      <td>25990.068004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>22953.216803</td>\n",
       "      <td>24834.758654</td>\n",
       "      <td>24458.490282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>22466.372158</td>\n",
       "      <td>25318.922379</td>\n",
       "      <td>23974.055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>23772.236997</td>\n",
       "      <td>26448.698961</td>\n",
       "      <td>24563.454495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>25599.068889</td>\n",
       "      <td>26806.016540</td>\n",
       "      <td>25990.068004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds     best_pred  best_pred/BottomUp  \\\n",
       "0  Australia 2016-01-01  25990.068004        24776.339488   \n",
       "1  Australia 2016-04-01  24458.490282        22953.216803   \n",
       "2  Australia 2016-07-01  23974.055984        22466.372158   \n",
       "3  Australia 2016-10-01  24563.454495        23772.236997   \n",
       "4  Australia 2017-01-01  25990.068004        25599.068889   \n",
       "\n",
       "   best_pred/MinTrace_method-mint_shrink  \\\n",
       "0                           26205.549950   \n",
       "1                           24834.758654   \n",
       "2                           25318.922379   \n",
       "3                           26448.698961   \n",
       "4                           26806.016540   \n",
       "\n",
       "   best_pred/TopDown_method-forecast_proportions  \n",
       "0                                   25990.068004  \n",
       "1                                   24458.490282  \n",
       "2                                   23974.055984  \n",
       "3                                   24563.454495  \n",
       "4                                   25990.068004  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_rec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes an `evaluate` function to evaluate the different hierarchies. To evaluate models we use `mase` metric and compare it to base predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mase\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['Total'] = tags['Country']\n",
    "eval_tags['State'] = tags['Country/State']\n",
    "eval_tags['Regions'] = tags['Country/State/Region']\n",
    "\n",
    "df = Y_rec_df.merge(Y_test_df, on=['unique_id', 'ds'])\n",
    "evaluation = evaluate(df = df,\n",
    "                      tags = eval_tags,\n",
    "                      train_df = Y_train_df,\n",
    "                      metrics = [partial(mase, seasonality=4)])\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp', 'MinTrace(mint_shrink)', 'TopDown(forecast_proportions)']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>metric</th>\n",
       "      <th>Base</th>\n",
       "      <th>BottomUp</th>\n",
       "      <th>MinTrace(mint_shrink)</th>\n",
       "      <th>TopDown(forecast_proportions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>mase</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regions</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overall</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level metric  Base  BottomUp  MinTrace(mint_shrink)  \\\n",
       "0    Total   mase  1.59      2.94                   0.55   \n",
       "1    State   mase  2.17      1.88                   1.86   \n",
       "2  Regions   mase  1.34      1.34                   1.50   \n",
       "3  Overall   mase  1.42      1.41                   1.53   \n",
       "\n",
       "   TopDown(forecast_proportions)  \n",
       "0                           1.59  \n",
       "1                           2.36  \n",
       "2                           1.49  \n",
       "3                           1.57  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.query('metric == \"mase\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recap\n",
    "\n",
    "In this example we fitted:\n",
    "\n",
    "- `StatsForecast` with `AutoETS` model for the **Country** level.\n",
    "- `MLForecast` with `HistGradientBoostingRegressor` model for the **Country/State** level.\n",
    "- `NeuralForecast` with `NBEATS` model for the **Country/State/Region** level. \n",
    "\n",
    "We then combined the results into a one single prediction.\n",
    "\n",
    "For the reconciliation of the forecasts, we used `HierarchicalReconciliation` with three different methods:\n",
    "\n",
    "- `BottomUp`\n",
    "- `MinTrace(method='mint_shrink')`\n",
    "- `TopDown(method='forecast_proportions')`\n",
    "\n",
    "Finally, we evaluated the performance of these reconciliation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
