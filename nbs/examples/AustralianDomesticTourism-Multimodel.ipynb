{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model Aggregation\n",
    "\n",
    "> Geographical Hierarchical Forecasting on Australian Tourism Data using multiple models for each level in the hierarchy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extends the classic Australian Domestic Tourism (`Tourism`) geographical aggregation example to showcase how `HierarchicalForecast` can be used to produce coherent forecasts when **different forecasting models are applied at each level of the hierarchy**. We will use the `Tourism` dataset, which contains monthly time series of the number of visitors to each state of Australia.\n",
    "\n",
    "Specifically, we will demonstrate fitting a diverse set of models across the hierarchical levels. This includes statistical models like `AutoETS` from `StatsForecast`, machine learning models such as `HistGradientBoostingRegressor` using `MLForecast`, and neural network models like `NBEATS` from `NeuralForecast`. After generating these base forecasts, we will reconcile them using `BottomUp` reconciliation from `HierarchicalForecast`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using CPU or GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/AustralianDomesticTourism-Multimodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hierarchicalforecast statsforecast mlforecast datasetsforecast lightgbm sklearn neuralforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the [Tourism](https://otexts.com/fpp3/tourism.html) dataset from the [Forecasting: Principles and Practice](https://otexts.com/fpp3/) book.\n",
    "\n",
    "The dataset only contains the time series at the lowest level, so we need to create the time series for all hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>State</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>658.553895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>449.853935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-07-01</td>\n",
       "      <td>592.904597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1998-10-01</td>\n",
       "      <td>524.242760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>548.394105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country    Region            State         ds           y\n",
       "0  Australia  Adelaide  South Australia 1998-01-01  658.553895\n",
       "1  Australia  Adelaide  South Australia 1998-04-01  449.853935\n",
       "2  Australia  Adelaide  South Australia 1998-07-01  592.904597\n",
       "3  Australia  Adelaide  South Australia 1998-10-01  524.242760\n",
       "4  Australia  Adelaide  South Australia 1999-01-01  548.394105"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "Y_df = Y_df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "Y_df.insert(0, 'Country', 'Australia')\n",
    "Y_df = Y_df[['Country', 'Region', 'State', 'ds', 'y']]\n",
    "Y_df['ds'] = Y_df['ds'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2', regex=True)\n",
    "Y_df['ds'] = pd.PeriodIndex(Y_df[\"ds\"], freq='Q').to_timestamp()\n",
    "Y_df_first = Y_df.groupby([\"Country\", \"Region\", \"State\", \"ds\"], as_index=False).agg({\"y\":\"sum\"})\n",
    "Y_df_first.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be grouped in the following hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'],\n",
    "    ['Country', 'State', 'Region']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `aggregate` function from `HierarchicalForecast` we can get the full set of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from hierarchicalforecast.utils import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, S_df, tags = aggregate(Y_df_first, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test sets\n",
    "\n",
    "We use the final two years (8 quarters) as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df = Y_df.groupby('unique_id', as_index=False).tail(8)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing different models for different hierarchies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we illustrate how to fit a different type of model for each level of the hierarchy. In particular, for each level, we will fit the following models:\n",
    "\n",
    "* **Country**: `AutoETS` model from `StatsForecast`.\n",
    "* **State**: `HistGradientBoostingRegressor` model from `scikit-learn` through the `MLForecast` API.\n",
    "* **Region**: `NBEATS` model from `NeuralForecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoETS\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS\n",
    "\n",
    "# The following helps suppress the Pytorch logging information\n",
    "import logging  \n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)  \n",
    "logging.getLogger(\"lightning_fabric\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `fit_predict_any_model` function provides a unified interface for training and forecasting with models from `StatsForecast`, `MLForecast`, and `NeuralForecast`. By abstracting away the specific fit and predict methods of each library, it simplifies the process of applying diverse model types across different levels of a hierarchy. This utility streamlines the experimentation and implementation of multi-model hierarchical forecasting strategies, enhancing code readability and reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_any_model(model: StatsForecast | MLForecast | NeuralForecast, df: pd.DataFrame, h:int):\n",
    "    if isinstance(model, StatsForecast):\n",
    "        yhat = model.forecast(df=df, h=h, fitted=True)\n",
    "        yfitted = model.forecast_fitted_values()\n",
    "\n",
    "    elif isinstance(model, MLForecast):\n",
    "        model.fit(df, fitted=True)\n",
    "        yhat = model.predict(new_df=df, h=h)\n",
    "        yfitted = model.forecast_fitted_values()\n",
    "\n",
    "    elif isinstance(model, NeuralForecast):\n",
    "        model.fit(df=df, val_size=h)\n",
    "        yhat = model.predict()\n",
    "        yfitted = model.predict_insample(step_size=h).drop(columns=[\"cutoff\"])[[\"unique_id\", \"ds\", \"y\", \"NBEATS\"]]\n",
    "\n",
    "    else:\n",
    "        print(\"Model is not a StatsForecast, MLForecast or NeuralForecast object.\")\n",
    "\n",
    "    yhat.columns = [\"unique_id\", \"ds\", \"multimodel_prediction\"]\n",
    "    yfitted.columns = [\"unique_id\", \"ds\", \"y\", \"multimodel_prediction\"]\n",
    "    return yhat, yfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "stat_model = StatsForecast(models=[AutoETS(season_length=4, model='ZZA')], freq='QS', n_jobs=-1)\n",
    "ml_model = MLForecast(models = {'gbm': HistGradientBoostingRegressor()}, freq='QS', lags=[1, 4])\n",
    "neural_model = NeuralForecast(models=[NBEATS(h=8, input_size=16, learning_rate=1e-3, enable_progress_bar=False, logger=False, enable_model_summary=False)],freq='QS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Country\": stat_model,\n",
    "    \"Country/State\": ml_model,\n",
    "    \"Country/State/Region\": neural_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Y_hat = []\n",
    "Y_fitted = []\n",
    "\n",
    "for key, value in tags.items():\n",
    "    df_level = Y_train_df.query(\"unique_id.isin(@value)\")\n",
    "    yhat_level, yfitted_level = fit_predict_any_model(models[key], df_level, h=8)\n",
    "    \n",
    "    Y_hat.append(yhat_level)\n",
    "    Y_fitted.append(yfitted_level)\n",
    "\n",
    "Y_hat_df = pd.concat(Y_hat, ignore_index=True)\n",
    "Y_fitted_df = pd.concat(Y_fitted, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconcile forecasts\n",
    "\n",
    "The following cell makes the previous forecasts coherent using the `HierarchicalReconciliation` class. In this example we use `BottomUp` reconciler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrec = HierarchicalReconciliation(reconcilers=[BottomUp()])\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S=S_df, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `Y_rec_df` contains the reconciled forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>multimodel_prediction</th>\n",
       "      <th>multimodel_prediction/BottomUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>24776.339488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>24458.490282</td>\n",
       "      <td>22953.216803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>23974.055984</td>\n",
       "      <td>22466.372158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>24563.454495</td>\n",
       "      <td>23772.236997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25990.068004</td>\n",
       "      <td>25599.068889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds  multimodel_prediction  multimodel_prediction/BottomUp\n",
       "0  Australia 2016-01-01           25990.068004                    24776.339488\n",
       "1  Australia 2016-04-01           24458.490282                    22953.216803\n",
       "2  Australia 2016-07-01           23974.055984                    22466.372158\n",
       "3  Australia 2016-10-01           24563.454495                    23772.236997\n",
       "4  Australia 2017-01-01           25990.068004                    25599.068889"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_rec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes an `evaluate` function to evaluate the different hierarchies. To evaluate models we use `mase` metric and compare it to base predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mase\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tags = {}\n",
    "eval_tags['Total'] = tags['Country']\n",
    "eval_tags['State'] = tags['Country/State']\n",
    "eval_tags['Regions'] = tags['Country/State/Region']\n",
    "\n",
    "df = Y_rec_df.merge(Y_test_df, on=['unique_id', 'ds'])\n",
    "evaluation = evaluate(df = df,\n",
    "                      tags = eval_tags,\n",
    "                      train_df = Y_train_df,\n",
    "                      metrics = [partial(mase, seasonality=4)])\n",
    "\n",
    "evaluation.columns = ['level', 'metric', 'Base', 'BottomUp']\n",
    "numeric_cols = evaluation.select_dtypes(include=\"number\").columns\n",
    "evaluation[numeric_cols] = evaluation[numeric_cols].map('{:.2f}'.format).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>metric</th>\n",
       "      <th>Base</th>\n",
       "      <th>BottomUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>mase</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regions</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overall</td>\n",
       "      <td>mase</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level metric  Base  BottomUp\n",
       "0    Total   mase  1.59      2.94\n",
       "1    State   mase  2.17      1.88\n",
       "2  Regions   mase  1.34      1.34\n",
       "3  Overall   mase  1.42      1.41"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.query('metric == \"mase\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
