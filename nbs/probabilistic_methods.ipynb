{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp probabilistic_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\"> Probabilistic Methods </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide a collection of methods designed to provide hierarchically coherent probabilistic distributions, \n",
    "which means that they generate samples of multivariate time series with hierarchical linear constraints.\n",
    "\n",
    "We designed these methods to extend the `core.HierarchicalForecast` capabilities class. Check their [usage example here](https://nixtla.github.io/hierarchicalforecast/examples/example.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from hierarchicalforecast.methods import is_strictly_hierarchical, cov2corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 1. Normality </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Normality:\n",
    "    \"\"\" Normality Probabilistic Reconciliation Class.\n",
    "\n",
    "    The Normality method leverages the Gaussian Distribution linearity, to\n",
    "    generate hierarchically coherent prediction distributions. This class is \n",
    "    meant to be used as the `sampler` input as other `HierarchicalForecast` [reconciliation classes](https://nixtla.github.io/hierarchicalforecast/methods.html).\n",
    "\n",
    "    Given base forecasts under a normal distribution:\n",
    "    $$\\hat{y}_{h} \\sim \\mathrm{N}(\\hat{\\\\boldsymbol{\\\\mu}}, \\hat{\\mathbf{W}}_{h})$$\n",
    "\n",
    "    The reconciled forecasts are also normally distributed:\n",
    "    $$\\\\tilde{y}_{h} \\sim \\mathrm{N}(\\mathbf{S}\\mathbf{P}\\hat{\\\\boldsymbol{\\\\mu}}, \n",
    "    \\mathbf{S}\\mathbf{P}\\hat{\\mathbf{W}}_{h} \\mathbf{P}^{\\intercal} \\mathbf{S}^{\\intercal})$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `S`: np.array, summing matrix of size (`base`, `bottom`).<br>\n",
    "    `P`: np.array, reconciliation matrix of size (`bottom`, `base`).<br>\n",
    "    `W`: np.array, hierarchical covariance matrix of size (`base`, `base`).<br>\n",
    "    `sigmah`: np.array, forecast standard dev. of size (`base`, `horizon`).<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Panagiotelis A., Gamakumara P. Athanasopoulos G., and Hyndman R. J. (2022).\n",
    "    \"Probabilistic forecast reconciliation: Properties, evaluation and score optimisation\". European Journal of Operational Research.](https://www.sciencedirect.com/science/article/pii/S0377221722006087)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 S: np.ndarray,\n",
    "                 sigmah: np.ndarray,\n",
    "                 P: np.ndarray=None,\n",
    "                 W: np.ndarray=None):\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.W = W\n",
    "        self.sigmah = sigmah\n",
    "\n",
    "    def get_prediction_levels(self, res, level):\n",
    "        \"\"\" Adds reconciled forecast levels to results dictionary \"\"\"\n",
    "\n",
    "        # Errors normality implies independence/diagonal covariance\n",
    "        R1 = cov2corr(self.W)\n",
    "        W_h = [np.diag(sigma) @ R1 @ np.diag(sigma).T for sigma in self.sigmah.T]\n",
    "\n",
    "        # Reconciled covariances across forecast horizon\n",
    "        SP = self.S @ self.P\n",
    "        sigmah_rec = np.hstack([np.sqrt(np.diag(SP @ W @ SP.T))[:, None] for W in W_h])\n",
    "\n",
    "        res['sigmah'] = sigmah_rec\n",
    "        level = np.asarray(level)\n",
    "        z = norm.ppf(0.5 + level / 200)\n",
    "        for zs, lv in zip(z, level):\n",
    "            res[f'lo-{lv}'] = res['mean'] - zs * sigmah_rec\n",
    "            res[f'hi-{lv}'] = res['mean'] + zs * sigmah_rec\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Normality, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 2. Bootstrap </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class Bootstrap:\n",
    "    \"\"\" Bootstrap Probabilistic Reconciliation Class.\n",
    "\n",
    "    This method goes beyond the normality assumption for the base forecasts,\n",
    "    the technique simulates future sample paths and uses them to generate\n",
    "    base sample paths that are latered reconciled. This clever idea and its\n",
    "    simplicity allows to generate coherent bootstraped prediction intervals\n",
    "    for any reconciliation strategy. This class is meant to be used as the `sampler` \n",
    "    input as other `HierarchicalForecast` [reconciliation classes](https://nixtla.github.io/hierarchicalforecast/methods.html).\n",
    "\n",
    "    Given a boostraped set of simulated sample paths:\n",
    "    $$(\\hat{\\mathbf{y}}^{[1]}_{\\\\tau}, \\dots ,\\hat{\\mathbf{y}}^{[B]}_{\\\\tau})$$\n",
    "\n",
    "    The reconciled sample paths allow for reconciled distributional forecasts:\n",
    "    $$(\\mathbf{S}\\mathbf{P}\\hat{\\mathbf{y}}^{[1]}_{\\\\tau}, \\dots ,\\mathbf{S}\\mathbf{P}\\hat{\\mathbf{y}}^{[B]}_{\\\\tau})$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `S`: np.array, summing matrix of size (`base`, `bottom`).<br>\n",
    "    `P`: np.array, reconciliation matrix of size (`bottom`, `base`).<br>\n",
    "    `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "    `y_hat_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "    `y_hat`: Point forecasts values of size (`base`, `horizon`).<br>\n",
    "    `num_samples`: int, number of bootstraped samples generated.<br>\n",
    "    `seed`: int, random seed for numpy generator's replicability.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Puwasala Gamakumara Ph. D. dissertation. Monash University, Econometrics and Business Statistics (2020).\n",
    "    \"Probabilistic Forecast Reconciliation\"](https://bridges.monash.edu/articles/thesis/Probabilistic_Forecast_Reconciliation_Theory_and_Applications/11869533)\n",
    "    - [Panagiotelis A., Gamakumara P. Athanasopoulos G., and Hyndman R. J. (2022).\n",
    "    \"Probabilistic forecast reconciliation: Properties, evaluation and score optimisation\". European Journal of Operational Research.](https://www.sciencedirect.com/science/article/pii/S0377221722006087)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 S: np.ndarray,\n",
    "                 y_insample: np.ndarray,\n",
    "                 y_hat_insample: np.ndarray,\n",
    "                 y_hat: np.ndarray,\n",
    "                 num_samples: int,\n",
    "                 seed: int = 0,\n",
    "                 P: np.ndarray = None,\n",
    "                 W: np.ndarray = None):\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.W = W\n",
    "        self.y_hat = y_hat\n",
    "        self.y_insample = y_insample\n",
    "        self.y_hat_insample = y_hat_insample\n",
    "        self.num_samples = num_samples\n",
    "        self.seed = seed\n",
    "\n",
    "    def get_samples(self):\n",
    "        residuals = self.y_insample - self.y_hat_insample\n",
    "        h = self.y_hat.shape[1]\n",
    "\n",
    "        #removing nas from residuals\n",
    "        residuals = residuals[:, np.isnan(residuals).sum(axis=0) == 0]\n",
    "        sample_idx = np.arange(residuals.shape[1] - h)\n",
    "        state = np.random.RandomState(self.seed)\n",
    "        samples_idx = state.choice(sample_idx, size=self.num_samples)\n",
    "        samples = [self.y_hat + residuals[:, idx:(idx + h)] for idx in samples_idx]\n",
    "        SP = self.S @ self.P\n",
    "        samples = np.apply_along_axis(lambda path: np.matmul(SP, path),\n",
    "                                      axis=1, arr=samples)\n",
    "        return np.stack(samples)\n",
    "\n",
    "    def get_prediction_levels(self, res, level):\n",
    "        \"\"\" Adds reconciled forecast levels to results dictionary \"\"\"\n",
    "        samples = self.get_samples()\n",
    "        for lv in level:\n",
    "            min_q = (100 - lv) / 200\n",
    "            max_q = min_q + lv / 100\n",
    "            res[f'lo-{lv}'] = np.quantile(samples, min_q, axis=0)\n",
    "            res[f'hi-{lv}'] = np.quantile(samples, max_q, axis=0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Bootstrap, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 3. PERMBU </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class PERMBU:\n",
    "    \"\"\" PERMBU Probabilistic Reconciliation Class.\n",
    "\n",
    "    The PERMBU method leverages empirical bottom-level marginal distributions \n",
    "    with empirical copula functions (describing bottom-level dependencies) to \n",
    "    generate the distribution of aggregate-level distributions using BottomUp \n",
    "    reconciliation. The sample reordering technique in the PERMBU method reinjects \n",
    "    multivariate dependencies into independent bottom-level samples.\n",
    "\n",
    "        Algorithm:\n",
    "        1.   For all series compute conditional marginals distributions.\n",
    "        2.   Compute residuals $\\hat{\\epsilon}_{i,t}$ and obtain rank permutations.\n",
    "        2.   Obtain K-sample from the bottom-level series predictions.\n",
    "        3.   Apply recursively through the hierarchical structure:<br>\n",
    "            3.1.   For a given aggregate series $i$ and its children series:<br>\n",
    "            3.2.   Obtain children's empirical joint using sample reordering copula.<br>\n",
    "            3.2.   From the children's joint obtain the aggregate series's samples.    \n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `S`: np.array, summing matrix of size (`base`, `bottom`).<br>\n",
    "    `tags`: Each key is a level and each value its `S` indices.<br>\n",
    "    `y_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "    `y_hat_insample`: Insample values of size (`base`, `insample_size`).<br>\n",
    "    `sigmah`: np.array, forecast standard dev. of size (`base`, `horizon`).<br>\n",
    "    `num_samples`: int, number of normal prediction samples generated.<br>\n",
    "    `seed`: int, random seed for numpy generator's replicability.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Taieb, Souhaib Ben and Taylor, James W and Hyndman, Rob J. (2017). \n",
    "    Coherent probabilistic forecasts for hierarchical time series. \n",
    "    International conference on machine learning ICML.](https://proceedings.mlr.press/v70/taieb17a.html)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 S: np.ndarray,\n",
    "                 tags: Dict[str, np.ndarray],\n",
    "                 y_hat: np.ndarray,\n",
    "                 y_insample: np.ndarray,\n",
    "                 y_hat_insample: np.ndarray,\n",
    "                 sigmah: np.ndarray,\n",
    "                 num_samples: int=None,\n",
    "                 seed: int=0,\n",
    "                 P: np.ndarray = None):\n",
    "        # PERMBU only works for strictly hierarchical structures\n",
    "        if not is_strictly_hierarchical(S, tags):\n",
    "            raise ValueError('PERMBU probabilistic reconciliation requires strictly hierarchical structures.')\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.y_hat = y_hat\n",
    "        self.y_insample = y_insample\n",
    "        self.y_hat_insample = y_hat_insample\n",
    "        self.sigmah = sigmah\n",
    "        self.num_samples = num_samples\n",
    "        self.seed = seed\n",
    "\n",
    "    def _obtain_ranks(self, array):\n",
    "        \"\"\" Vector ranks\n",
    "\n",
    "        Efficiently obtain vector ranks.\n",
    "        Example `array=[4,2,7,1]` -> `ranks=[2, 1, 3, 0]`.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `array`: np.array, matrix with floats or integers on which the \n",
    "                ranks will be computed on the second dimension.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `ranks`: np.array, matrix with ranks along the second dimension.<br>\n",
    "        \"\"\"\n",
    "        temp = array.argsort(axis=1)\n",
    "        ranks = np.empty_like(temp)\n",
    "        a_range = np.arange(temp.shape[1])\n",
    "        for i_row in range(temp.shape[0]):\n",
    "            ranks[i_row, temp[i_row,:]] = a_range\n",
    "        return ranks\n",
    "\n",
    "    def _permutate_samples(self, samples, permutations):\n",
    "        \"\"\" Permutate Samples\n",
    "\n",
    "        Applies efficient vectorized permutation on the samples.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `samples`: np.array [series,samples], independent base samples.<br>\n",
    "        `permutations`: np.array [series,samples], permutation ranks with wich\n",
    "                  which `samples` dependence will be restored see `_obtain_ranks`.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `permutated_samples`: np.array.<br>\n",
    "        \"\"\"\n",
    "        # Generate auxiliary and flat permutation indexes\n",
    "        n_rows, n_cols = permutations.shape\n",
    "        aux_row_idx = np.arange(n_rows)[:,None] * n_cols\n",
    "        aux_row_idx = np.repeat(aux_row_idx, repeats=n_cols, axis=1)\n",
    "        permutate_idxs = permutations.flatten() + aux_row_idx.flatten()\n",
    "\n",
    "        # Apply flat permutation indexes and recover original shape\n",
    "        permutated_samples = samples.flatten()\n",
    "        permutated_samples = permutated_samples[permutate_idxs]\n",
    "        permutated_samples = permutated_samples.reshape(n_rows, n_cols)\n",
    "        return permutated_samples\n",
    "    \n",
    "    def _permutate_predictions(self, predictionum_samples, permutations):\n",
    "        \"\"\" Permutate Prediction Samples\n",
    "\n",
    "        Applies permutations to predictionum_samples across the horizon.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `predictionum_samples`: np.array [series,horizon,samples], independent \n",
    "                  base prediction samples.<br>\n",
    "        `permutations`: np.array [series, samples], permutation ranks with which\n",
    "                  `samples` dependence will be restored see `_obtain_ranks`.\n",
    "                  it can also apply a random permutation.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `permutated_predictionum_samples`: np.array.<br>\n",
    "        \"\"\"\n",
    "        # Apply permutation throughout forecast horizon\n",
    "        permutated_predictionum_samples = predictionum_samples.copy()\n",
    "\n",
    "        _, n_horizon, _ = predictionum_samples.shape\n",
    "        for t in range(n_horizon):\n",
    "            permutated_predictionum_samples[:,t,:] = \\\n",
    "                              self._permutate_samples(predictionum_samples[:,t,:],\n",
    "                                                      permutations)\n",
    "        return permutated_predictionum_samples\n",
    "\n",
    "    def _nonzero_indexes_by_row(self, M):\n",
    "        return [np.nonzero(M[row,:])[0] for row in range(len(M))]\n",
    "\n",
    "    def get_samples(self):\n",
    "        \"\"\"PERMBU Sample Reconciliation Method.\n",
    "\n",
    "        Applies PERMBU reconciliation method as defined by Taieb et. al 2017.\n",
    "        Generating independent base prediction samples, restoring its multivariate\n",
    "        dependence using estimated copula with reordering and applying the BottomUp\n",
    "        aggregation to the new samples.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y_hat`: Mean forecast values of size (`base`, `horizon`).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `rec_samples`: Reconciliated samples using the PERMBU approach.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute residuals and rank permutations\n",
    "        residuals = self.y_insample - self.y_hat_insample\n",
    "        #removing nas from residuals\n",
    "        residuals = residuals[:, np.isnan(residuals).sum(axis=0) == 0]\n",
    "        rank_permutations = self._obtain_ranks(residuals)\n",
    "\n",
    "        # Sample h step-ahead base marginal distributions\n",
    "        if self.num_samples is None:\n",
    "            num_samples = residuals.shape[1]\n",
    "        else:\n",
    "            num_samples = self.num_samples\n",
    "        state = np.random.RandomState(self.seed)\n",
    "        n_series, n_horizon = self.y_hat.shape\n",
    "\n",
    "        base_samples = np.array([\n",
    "            state.normal(loc=m, scale=s, size=num_samples) for m, s in \\\n",
    "            zip(self.y_hat.flatten(), self.sigmah.flatten())\n",
    "        ])\n",
    "        base_samples = base_samples.reshape(n_series, n_horizon, num_samples)\n",
    "\n",
    "        # Initialize PERMBU utility\n",
    "        rec_samples = base_samples.copy()\n",
    "        encoder = OneHotEncoder(sparse=False, dtype=np.float32)\n",
    "        hier_links = np.vstack(self._nonzero_indexes_by_row(self.S.T))\n",
    "\n",
    "        # BottomUp hierarchy traversing\n",
    "        hier_levels = hier_links.shape[1]-1\n",
    "        for level_idx in reversed(range(hier_levels)):\n",
    "            # Obtain aggregation matrix from parent/children links\n",
    "            children_links = np.unique(hier_links[:,level_idx:level_idx+2], \n",
    "                                       axis=0)\n",
    "            children_idxs = np.unique(children_links[:,1])\n",
    "            parent_idxs = np.unique(children_links[:,0])\n",
    "            Agg = encoder.fit_transform(children_links).T\n",
    "            Agg = Agg[:len(parent_idxs),:]\n",
    "\n",
    "            # Permute childrenum_samples for each prediction step\n",
    "            children_permutations = rank_permutations[children_idxs, :]\n",
    "            childrenum_samples = rec_samples[children_idxs,:,:]\n",
    "            childrenum_samples = self._permutate_predictions(\n",
    "                predictionum_samples=childrenum_samples,\n",
    "                permutations=children_permutations\n",
    "            )\n",
    "\n",
    "            # Overwrite hier_samples with BottomUp aggregation\n",
    "            # and randomly shuffle parent predictions after aggregation\n",
    "            parent_samples = np.einsum('ab,bhs->ahs', Agg, childrenum_samples)\n",
    "            random_permutation = np.array([\n",
    "                np.random.permutation(np.arange(num_samples)) \\\n",
    "                for serie in range(len(parent_samples))\n",
    "            ])\n",
    "            parent_samples = self._permutate_predictions(\n",
    "                predictionum_samples=parent_samples,\n",
    "                permutations=random_permutation\n",
    "            )\n",
    "\n",
    "            rec_samples[parent_idxs,:,:] = parent_samples\n",
    "\n",
    "        return np.transpose(rec_samples, (2, 0, 1))\n",
    "\n",
    "    def get_prediction_levels(self, res, level):\n",
    "        \"\"\" Adds reconciled forecast levels to results dictionary \"\"\"\n",
    "        samples = self.get_samples()\n",
    "        for lv in level:\n",
    "            min_q = (100 - lv) / 200\n",
    "            max_q = min_q + lv / 100\n",
    "            res[f'lo-{lv}'] = np.quantile(samples, min_q, axis=0)\n",
    "            res[f'hi-{lv}'] = np.quantile(samples, max_q, axis=0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(PERMBU, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> References </span>\n",
    "\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \n",
    "\"Forecasting principles and practice, Reconciled distributional forecasts\".](https://otexts.com/fpp3/rec-prob.html)<br>\n",
    "- [Puwasala Gamakumara Ph. D. dissertation. Monash University, Econometrics and Business Statistics (2020).\n",
    "\"Probabilistic Forecast Reconciliation\"](https://bridges.monash.edu/articles/thesis/Probabilistic_Forecast_Reconciliation_Theory_and_Applications/11869533)<br>\n",
    "- [Panagiotelis A., Gamakumara P. Athanasopoulos G., and Hyndman R. J. (2022). \"Probabilistic forecast reconciliation: Properties, evaluation and score optimisation\". European Journal of Operational Research.](https://www.sciencedirect.com/science/article/pii/S0377221722006087)<br>\n",
    "- [Taieb, Souhaib Ben and Taylor, James W and Hyndman, Rob J. (2017). Coherent probabilistic forecasts for hierarchical time series. \n",
    "International conference on machine learning ICML.](https://proceedings.mlr.press/v70/taieb17a.html)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
