{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3226c32-707e-45a6-ab7f-9d8f33924670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955e6c8-f4cd-49a6-b6c8-b91c4392a6d3",
   "metadata": {},
   "source": [
    "# Aggregation/Visualization Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f437e79",
   "metadata": {},
   "source": [
    "The `HierarchicalForecast` package contains utility functions to wrangle and visualize \n",
    "hierarchical series datasets. The `aggregate` function of the module allows you to create\n",
    "a hierarchy from categorical variables representing the structure levels, returning also\n",
    "the aggregation contraints matrix $\\mathbf{S}_{[a][b]}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74967eef-4a18-433e-9dc8-d5e8e6d7dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "import timeit\n",
    "from itertools import chain\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mycolorpy import colorlist as mcp\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e08169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a501424-ebfd-403c-982e-280cb859bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff333fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class CodeTimer:\n",
    "    def __init__(self, name=None, verbose=True):\n",
    "        self.name = \" '\"  + name + \"'\" if name else ''\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timeit.default_timer()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.took = (timeit.default_timer() - self.start)\n",
    "        if self.verbose:\n",
    "            print('Code block' + self.name + \\\n",
    "                  ' took:\\t{0:.5f}'.format(self.took) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e585c763-cba5-48f5-a021-822622f3b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _to_summing_matrix(S_df: pd.DataFrame):\n",
    "    \"\"\"Transforms the DataFrame `df` of hierarchies to a summing matrix S.\"\"\"\n",
    "    categories = [S_df[col].unique() for col in S_df.columns]\n",
    "    cat_sizes = [len(cats) for cats in categories]\n",
    "    idx_bottom = np.argmax(cat_sizes)\n",
    "    cats_bottom = categories[idx_bottom]\n",
    "    encoder = OneHotEncoder(categories=categories, sparse=False, dtype=np.float32)\n",
    "    S = encoder.fit_transform(S_df).T\n",
    "    S = pd.DataFrame(S, index=chain(*categories), columns=cats_bottom)\n",
    "    tags = dict(zip(S_df.columns, categories))\n",
    "    return S, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d1aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _to_summing_dataframe(Y_bottom_df: pd.DataFrame,\n",
    "                          spec: List[List[str]]):\n",
    "    \"\"\" Create Summing dataframe\n",
    "\n",
    "    This function receives the `Y_bottom_df` and a list of\n",
    "    hierarchical levels `spec`, and computes the aggregation\n",
    "    constraints dataframe `S_df`, it enriches `Y_bottom_df`\n",
    "    with a bottom level 'unique_id'.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `Y_bottom_df`: pd.DataFrame with columns `[levels, 'ds', 'y']` and levels in spec.<br>\n",
    "    `spec`: `spec`: List of levels. Each element of the list contains a list of columns of `df` to aggregate.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `Y_bottom_df, S_df, tags`: tuple with hierarchically structured series \n",
    "    `Y_bottom_df` ($\\mathbf{y}_{[b]}$), summing dataframe `S_df`, and hierarchical \n",
    "    aggregation indexes `tags`.\n",
    "    \"\"\"\n",
    "    #------------------------- Efficient Wrangling -------------------------#\n",
    "    # Keep unique levels, preserving first aparison order\n",
    "    all_levels = list(chain.from_iterable(spec))\n",
    "    all_levels = [*dict.fromkeys(all_levels)]\n",
    "\n",
    "    # Efficiently create hierarchical labels\n",
    "    S_df = Y_bottom_df[all_levels].copy()\n",
    "    S_df = S_df.drop_duplicates()\n",
    "    \n",
    "    max_len_idx = np.argmax([len(hier) for hier in spec])\n",
    "    bottom_levels = spec[max_len_idx]\n",
    "    for level_idx, levels in enumerate(spec):\n",
    "        if levels == bottom_levels:\n",
    "            # Enrich Y_bottom with unique_id\n",
    "            S_df['unique_id'] = S_df[levels].agg('/'.join, axis=1)\n",
    "            Y_bottom_df['unique_id'] = Y_bottom_df[levels].agg('/'.join, axis=1)\n",
    "        else:\n",
    "            S_df[f'Level_{[level_idx]}'] = S_df[levels].agg('/'.join, axis=1)\n",
    "\n",
    "    S_df = S_df.drop(all_levels, axis=1)\n",
    "\n",
    "    #------------------------------- Encoding ------------------------------#\n",
    "    # One hot encode only aggregate levels\n",
    "    # TODO: option to only operate with sparse matrices\n",
    "    bottom_ids = list(S_df.unique_id)\n",
    "    del S_df['unique_id']\n",
    "    categories = [S_df[col].unique() for col in S_df.columns]\n",
    "    tags = dict(zip(S_df.columns, categories))\n",
    "    encoder = OneHotEncoder(categories=categories,\n",
    "                            sparse=False, dtype=np.float32)\n",
    "    S = encoder.fit_transform(S_df).T\n",
    "    S = np.concatenate([S, np.eye(len(bottom_ids))], axis=0)\n",
    "    S_df = pd.DataFrame(S, columns=bottom_ids,\n",
    "                        index=list(chain(*categories))+bottom_ids)\n",
    "\n",
    "    # Match index ordering of S_df and Y_bottom_df\n",
    "    Y_bottom_df.unique_id = Y_bottom_df.unique_id.astype('category')\n",
    "    Y_bottom_df.unique_id = Y_bottom_df.unique_id.cat.set_categories(S_df.columns)\n",
    "    return Y_bottom_df, S_df, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6601ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def numpy_balance(*arrs):\n",
    "    \"\"\"\n",
    "    Fast NumPy implementation of balance function.\n",
    "    The function creates all the interactions between\n",
    "    the NumPy arrays provided.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `arrs`: NumPy arrays.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `out`: NumPy array.<br>\n",
    "    \"\"\"\n",
    "    N = len(arrs)\n",
    "    out =  np.transpose(np.meshgrid(*arrs, indexing='ij'),\n",
    "                        np.roll(np.arange(N + 1), -1)).reshape(-1, N)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f4267",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> Aggregate Function </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40374c36-a0f0-4539-92af-1bcbdfe26714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def aggregate_old(df: pd.DataFrame,\n",
    "                  spec: List[List[str]],\n",
    "                  agg_fn: Callable = np.sum):\n",
    "    \"\"\" Utils Aggregation Function.\n",
    "\n",
    "    Aggregates bottom level series contained in the pd.DataFrame `df` according \n",
    "    to levels defined in the `spec` list applying the `agg_fn` (sum, mean).\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `df`: pd.DataFrame with columns `['ds', 'y']` and columns to aggregate.<br>\n",
    "    `spec`: List of levels. Each element of the list contains a list of columns of `df` to aggregate.<br>\n",
    "    `agg_fn`: Function used to aggregate `'y'`.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `Y_df, S, tags`: tuple with hierarchically structured series `Y_df` ($\\mathbf{y}_{[a,b]}$),\n",
    "    summing matrix `S`, and hierarchical aggregation indexes `tags`.<br>\n",
    "    \"\"\"\n",
    "    max_len_idx = np.argmax([len(hier) for hier in spec])\n",
    "    bottom_comb = spec[max_len_idx]\n",
    "    df_hiers = []\n",
    "    for hier in spec:\n",
    "        df_hier = df.groupby(hier + ['ds'])['y'].apply(agg_fn).reset_index()\n",
    "        df_hier['unique_id'] = df_hier[hier].agg('/'.join, axis=1)\n",
    "        if hier == bottom_comb:\n",
    "            bottom_hier = df_hier['unique_id'].unique()\n",
    "        df_hiers.append(df_hier)\n",
    "    df_hiers = pd.concat(df_hiers)\n",
    "    S_df = df_hiers[['unique_id'] + bottom_comb].drop_duplicates().reset_index(drop=True)\n",
    "    S_df = S_df.set_index('unique_id')\n",
    "    S_df = S_df.fillna('agg')\n",
    "    hiers_cols = []\n",
    "    for hier in spec:\n",
    "        hier_col = '/'.join(hier) \n",
    "        S_df[hier_col] = S_df[hier].agg('/'.join, axis=1)\n",
    "        hiers_cols.append(hier_col)\n",
    "    Y_df = df_hiers[['unique_id', 'ds', 'y']].set_index('unique_id')\n",
    "    \n",
    "    # Aggregations constraints S definition\n",
    "    S, tags = _to_summing_matrix(S_df.loc[bottom_hier, hiers_cols])\n",
    "    return Y_df, S, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664fe88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def aggregate(Y_bottom_df: pd.DataFrame,\n",
    "              spec: List[List[str]],\n",
    "              is_balanced: bool=False):\n",
    "    \"\"\" Utils Aggregation Function.\n",
    "\n",
    "    Aggregates bottom level series contained in the pd.DataFrame `df` according \n",
    "    to levels defined in the `spec` list applying the `agg_fn` (sum, mean).\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `Y_bottom_df`: pd.DataFrame with columns `['ds', 'y']` and columns to aggregate.<br>\n",
    "    `spec`: List of levels. Each element of the list contains a list of columns of `df` to aggregate.<br>\n",
    "    `is_balanced`: bool=False, wether `Y_bottom_df` is balanced, if not we balance.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `Y_df, S_df, tags`: tuple with hierarchically structured series `Y_df` ($\\mathbf{y}_{[a,b]}$),\n",
    "    summing dataframe `S_df`, and hierarchical aggregation indexes `tags`.\n",
    "    \"\"\"\n",
    "    #------------------------- Efficient Wrangling -------------------------#\n",
    "    # Y_bottom_df's unique_id enrichment, and constraints S_df\n",
    "    Y_bottom_df, S_df, tags = _to_summing_dataframe(Y_bottom_df=Y_bottom_df, \n",
    "                                                    spec=spec)\n",
    "\n",
    "    # Create balanced/sorted dataset for efficient aggregation (nan=0)\n",
    "    # balanced = for all unique_ids all date stamps are present\n",
    "    if not is_balanced:\n",
    "        dates         = Y_bottom_df['ds'].unique()\n",
    "        balanced_prod = numpy_balance(S_df.columns, dates)\n",
    "        balanced_df   = pd.DataFrame(balanced_prod, columns=['unique_id', 'ds'])\n",
    "        balanced_df['ds'] = balanced_df['ds'].astype(Y_bottom_df['ds'].dtype)\n",
    "\n",
    "        Y_bottom_df.set_index(['unique_id', 'ds'], inplace=True)\n",
    "        balanced_df.set_index(['unique_id', 'ds'], inplace=True)\n",
    "        balanced_df   = balanced_df.merge(Y_bottom_df[['y']],\n",
    "                                          how='left', left_on=['unique_id', 'ds'],\n",
    "                                          right_index=True).reset_index()\n",
    "        balanced_df['y'].fillna(0, inplace=True)\n",
    "        Y_bottom_df.reset_index(inplace=True)\n",
    "    else:\n",
    "        balanced_df = Y_bottom_df.copy()\n",
    "\n",
    "    #------------------------- Efficient Aggregation -------------------------#\n",
    "    n_agg = S_df.shape[0] - S_df.shape[1]\n",
    "    Agg = S_df.values[:n_agg, :]\n",
    "    y_bottom = balanced_df.y.values.reshape(len(S_df.columns), len(dates))\n",
    "    y_agg = Agg @ y_bottom\n",
    "\n",
    "    # Create long format hierarchical dataframe\n",
    "    y_agg = y_agg.flatten()\n",
    "    y_bottom = y_bottom.flatten()\n",
    "    Y_df = pd.DataFrame(dict(\n",
    "                unique_id = np.repeat(S_df.index, len(dates)),\n",
    "                ds = np.tile(dates, len(S_df.index)),\n",
    "                y = np.concatenate([y_agg, y_bottom], axis=0)))\n",
    "    return Y_df, S_df, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7090fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "ds = pd.date_range(start='2000-01-01', end='2000-08-01', freq='MS')\n",
    "y_base = np.arange(1,9)\n",
    "r1 = y_base * (10**1)\n",
    "r2 = y_base * (10**1)\n",
    "r3 = y_base * (10**2)\n",
    "r4 = y_base * (10**2)\n",
    "\n",
    "ys = np.concatenate([r1, r2, r3, r4])\n",
    "ds = np.tile(ds, 4)\n",
    "unique_ids = ['r1'] * 8 + ['r2'] * 8 + ['r3'] * 8 + ['r4'] * 8\n",
    "top_level = 'Australia'\n",
    "middle_level = ['State1'] * 16 + ['State2'] * 16\n",
    "bottom_level = unique_ids\n",
    "\n",
    "Y_bottom_df = dict(ds=ds,\n",
    "                 top_level=top_level, \n",
    "                 middle_level=middle_level, \n",
    "                 bottom_level=bottom_level,\n",
    "                 y=ys)\n",
    "Y_bottom_df = pd.DataFrame(Y_bottom_df)\n",
    "Y_bottom_df.groupby('bottom_level').head(2)\n",
    "\n",
    "hierarchy_levels = [['top_level'],\n",
    "                    ['top_level', 'middle_level'],\n",
    "                    ['top_level', 'middle_level', 'bottom_level']]\n",
    "\n",
    "# Test equality under sorted dataframes\n",
    "old_Y_df, old_S_df, old_tags = aggregate_old(Y_bottom_df, hierarchy_levels)\n",
    "Y_df, S_df, tags = aggregate(Y_bottom_df, hierarchy_levels)\n",
    "\n",
    "np.all(np.isclose(Y_df.y.values, old_Y_df.y.values, atol=1e-8))\n",
    "np.all(np.isclose(S_df.to_numpy(), old_S_df.to_numpy(), atol=1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95b3ec5f-2dcf-4232-8a89-f76c445e0441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/hierarchicalforecast/tree/main/blob/main/hierarchicalforecast/utils.py#L34){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### aggregate\n",
       "\n",
       ">      aggregate (Y_bottom_df:pandas.core.frame.DataFrame, spec:List[List[str]],\n",
       ">                 is_balanced:bool=False)\n",
       "\n",
       "Utils Aggregation Function.\n",
       "\n",
       "Aggregates bottom level series contained in the pd.DataFrame `df` according \n",
       "to levels defined in the `spec` list applying the `agg_fn` (sum, mean).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`Y_bottom_df`: pd.DataFrame with columns `['ds', 'y']` and columns to aggregate.<br>\n",
       "`spec`: List of levels. Each element of the list contains a list of columns of `df` to aggregate.<br>\n",
       "`is_balanced`: bool=False, wether `Y_bottom_df` is balanced, if not we balance.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`Y_df, S_df, tags`: tuple with hierarchically structured series `Y_df` ($\\mathbf{y}_{[a,b]}$),\n",
       "summing dataframe `S_df`, and hierarchical aggregation indexes `tags`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/hierarchicalforecast/tree/main/blob/main/hierarchicalforecast/utils.py#L34){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### aggregate\n",
       "\n",
       ">      aggregate (Y_bottom_df:pandas.core.frame.DataFrame, spec:List[List[str]],\n",
       ">                 is_balanced:bool=False)\n",
       "\n",
       "Utils Aggregation Function.\n",
       "\n",
       "Aggregates bottom level series contained in the pd.DataFrame `df` according \n",
       "to levels defined in the `spec` list applying the `agg_fn` (sum, mean).\n",
       "\n",
       "**Parameters:**<br>\n",
       "`Y_bottom_df`: pd.DataFrame with columns `['ds', 'y']` and columns to aggregate.<br>\n",
       "`spec`: List of levels. Each element of the list contains a list of columns of `df` to aggregate.<br>\n",
       "`is_balanced`: bool=False, wether `Y_bottom_df` is balanced, if not we balance.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`Y_df, S_df, tags`: tuple with hierarchically structured series `Y_df` ($\\mathbf{y}_{[a,b]}$),\n",
       "summing dataframe `S_df`, and hierarchical aggregation indexes `tags`."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(aggregate, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96fd8bd9-d7e8-4602-a1ad-021f404532f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "hiers_grouped = [['Country'],\n",
    "                 ['Country', 'State'], \n",
    "                 ['Country', 'Purpose'], \n",
    "                 ['Country', 'State', 'Region'], \n",
    "                 ['Country', 'State', 'Purpose'], \n",
    "                 ['Country', 'State', 'Region', 'Purpose']]\n",
    "\n",
    "hier_df, S_df, tags = aggregate_old(df=df, spec=hiers_grouped)\n",
    "test_eq(len(hier_df), 34_000)\n",
    "test_eq(hier_df.index.nunique(), 425)\n",
    "test_eq(S_df.shape, (425, 304))\n",
    "test_eq(hier_df.index.unique(), S_df.index)\n",
    "test_eq(len(tags), len(hiers_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8571e560",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n34000\n425",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m hier_df, S_df, tags \u001b[39m=\u001b[39m aggregate(Y_bottom_df\u001b[39m=\u001b[39mdf, spec\u001b[39m=\u001b[39mhiers_grouped)\n\u001b[1;32m     13\u001b[0m test_eq(\u001b[39mlen\u001b[39m(hier_df), \u001b[39m34_000\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m test_eq(hier_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mnunique(), \u001b[39m425\u001b[39m)\n\u001b[1;32m     15\u001b[0m test_eq(S_df\u001b[39m.\u001b[39mshape, (\u001b[39m425\u001b[39m, \u001b[39m304\u001b[39m))\n\u001b[1;32m     16\u001b[0m test_eq(hier_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39munique(), S_df\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hierarchicalforecast/lib/python3.10/site-packages/fastcore/test.py:37\u001b[0m, in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_eq\u001b[39m(a,b):\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`test` that `a==b`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m     test(a,b,equals, \u001b[39m'\u001b[39;49m\u001b[39m==\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hierarchicalforecast/lib/python3.10/site-packages/fastcore/test.py:27\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m\"\u001b[39m\u001b[39m`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m cname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: cname\u001b[39m=\u001b[39mcmp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[39massert\u001b[39;00m cmp(a,b),\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcname\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00ma\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mb\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\n34000\n425"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "hiers_grouped = [['Country'],\n",
    "                 ['Country', 'State'], \n",
    "                 ['Country', 'Purpose'], \n",
    "                 ['Country', 'State', 'Region'], \n",
    "                 ['Country', 'State', 'Purpose'], \n",
    "                 ['Country', 'State', 'Region', 'Purpose']]\n",
    "\n",
    "hier_df, S_df, tags = aggregate(Y_bottom_df=df, spec=hiers_grouped)\n",
    "test_eq(len(hier_df), 34_000)\n",
    "test_eq(hier_df.index.nunique(), 425)\n",
    "test_eq(S_df.shape, (425, 304))\n",
    "test_eq(hier_df.index.unique(), S_df.index)\n",
    "test_eq(len(tags), len(hiers_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22febc26-1901-4bef-a181-09ae2f52453b",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> Hierarchical Visualization </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125e256-c210-4776-ac55-9841acee583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HierarchicalPlot:\n",
    "    \"\"\" Hierarchical Plot\n",
    "\n",
    "    This class contains a collection of matplotlib visualization methods, suited for small\n",
    "    to medium sized hierarchical series.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `S`: pd.DataFrame with summing matrix of size `(base, bottom)`, see [aggregate function](https://nixtla.github.io/hierarchicalforecast/utils.html#aggregate).<br>\n",
    "    `tags`: np.ndarray, with hierarchical aggregation indexes, where \n",
    "        each key is a level and its value contains tags associated to that level.<br><br>\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 S: pd.DataFrame,\n",
    "                 tags: Dict[str, np.ndarray]):\n",
    "        self.S = S\n",
    "        self.tags = tags\n",
    "\n",
    "    def plot_summing_matrix(self):\n",
    "        \"\"\" Summation Constraints plot\n",
    "        \n",
    "        This method simply plots the hierarchical aggregation\n",
    "        constraints matrix $\\mathbf{S}$.\n",
    "        \"\"\"\n",
    "        plt.figure(num=1, figsize=(4, 6), dpi=80, facecolor='w')\n",
    "        plt.spy(self.S)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_series(self,\n",
    "                    series: str,\n",
    "                    Y_df: Optional[pd.DataFrame] = None,\n",
    "                    models: Optional[List[str]] = None,\n",
    "                    level: Optional[List[int]] = None):\n",
    "        \"\"\" Single Series plot\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `series`: str, string identifying the `'unique_id'` any-level series to plot.<br>\n",
    "        `Y_df`: pd.DataFrame, hierarchically structured series ($\\mathbf{y}_{[a,b]}$). \n",
    "                It contains columns `['unique_id', 'ds', 'y']`, it may have `'models'`.<br>\n",
    "        `models`: List[str], string identifying filtering model columns.\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals available in `Y_df`.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        Single series plot with filtered models and prediction interval level.<br><br>\n",
    "        \"\"\"\n",
    "        if series not in self.S.index:\n",
    "            raise Exception(f'time series {series} not found')\n",
    "        fig, ax = plt.subplots(1, 1, figsize = (20, 7))\n",
    "        df_plot = Y_df.loc[series].set_index('ds')\n",
    "        cols = models if models is not None else df_plot.columns\n",
    "        cols_wo_levels = [col for col in cols if ('lo' not in col and 'hi' not in col)]\n",
    "        cmap = mcp.gen_color('tab10', 10)[:len(cols_wo_levels)]\n",
    "        cmap_dict = dict(zip(cols_wo_levels, cmap))\n",
    "        df_plot[cols_wo_levels].plot(ax=ax, linewidth=2, color=cmap)\n",
    "        if level is not None:\n",
    "            for lv in level:\n",
    "                for col in cols_wo_levels:\n",
    "                    if col == 'y':\n",
    "                        # we dont need intervals\n",
    "                        # for the actual value\n",
    "                        continue\n",
    "                    if f'{col}-lo-{lv}' not in df_plot.columns:\n",
    "                        # if model\n",
    "                        # doesnt have levels\n",
    "                        continue\n",
    "                    ax.fill_between(\n",
    "                        df_plot.index, \n",
    "                        df_plot[f'{col}-lo-{lv}'], \n",
    "                        df_plot[f'{col}-hi-{lv}'],\n",
    "                        alpha=-lv/50 + 2,\n",
    "                        color=cmap_dict[col],\n",
    "                        label=f'{col}_level_{lv}'\n",
    "                    )\n",
    "        ax.set_title(f'{series} Forecast', fontsize=22)\n",
    "        ax.set_xlabel('Timestamp [t]', fontsize=20)\n",
    "        ax.legend(prop={'size': 15})\n",
    "        ax.grid()\n",
    "        for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            label.set_fontsize(20)\n",
    "                    \n",
    "    def plot_hierarchically_linked_series(self,\n",
    "                                          bottom_series: str,\n",
    "                                          Y_df: Optional[pd.DataFrame] = None,\n",
    "                                          models: Optional[List[str]] = None,\n",
    "                                          level: Optional[List[int]] = None):\n",
    "        \"\"\" Hierarchically Linked Series plot\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `bottom_series`: str, string identifying the `'unique_id'` bottom-level series to plot.<br>\n",
    "        `Y_df`: pd.DataFrame, hierarchically structured series ($\\mathbf{y}_{[a,b]}$). \n",
    "                It contains columns ['unique_id', 'ds', 'y'] and models. <br>\n",
    "        `models`: List[str], string identifying filtering model columns.\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals available in `Y_df`.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        Collection of hierarchilly linked series plots associated with the `bottom_series`\n",
    "        and filtered models and prediction interval level.<br><br>\n",
    "        \"\"\"\n",
    "        if bottom_series not in self.S.columns:\n",
    "            raise Exception(f'bottom time series {bottom_series} not found')\n",
    "        linked_series = self.S[bottom_series].loc[lambda x: x == 1.].index\n",
    "        fig, axs = plt.subplots(len(linked_series), 1, figsize=(20, 2 * len(linked_series)))\n",
    "        cols = models if models is not None else Y_df.drop(['ds'], axis=1)\n",
    "        cols_wo_levels = [col for col in cols if ('lo' not in col and 'hi' not in col)]\n",
    "        cmap = mcp.gen_color('tab10', 10)[:len(cols_wo_levels)]\n",
    "        cmap_dict = dict(zip(cols_wo_levels, cmap))\n",
    "        for idx, series in enumerate(linked_series):\n",
    "            df_plot = Y_df.loc[[series]].set_index('ds')\n",
    "            df_plot[cols_wo_levels].plot(ax=axs[idx], linewidth=2, color=cmap)\n",
    "            if level is not None:\n",
    "                for lv in level:\n",
    "                    for col in cols_wo_levels:\n",
    "                        if col == 'y':\n",
    "                            # we dont need intervals\n",
    "                            # for the actual value\n",
    "                            continue\n",
    "                        if f'{col}-lo-{lv}' not in df_plot.columns:\n",
    "                            # if model\n",
    "                            # doesnt have levels\n",
    "                            continue\n",
    "                        axs[idx].fill_between(\n",
    "                            df_plot.index, \n",
    "                            df_plot[f'{col}-lo-{lv}'], \n",
    "                            df_plot[f'{col}-hi-{lv}'],\n",
    "                            alpha=-lv/50 + 2,\n",
    "                            color=cmap_dict[col],\n",
    "                            label=f'{col}_level_{lv}'\n",
    "                        )\n",
    "            axs[idx].set_title(f'{series}', fontsize=10)\n",
    "            axs[idx].grid()\n",
    "            axs[idx].get_xaxis().label.set_visible(False)\n",
    "            axs[idx].legend().set_visible(False)\n",
    "            for label in (axs[idx].get_xticklabels() + axs[idx].get_yticklabels()):\n",
    "                label.set_fontsize(10)\n",
    "        plt.subplots_adjust(hspace=0.4)\n",
    "        handles, labels = axs[0].get_legend_handles_labels()\n",
    "        kwargs = dict(loc='lower center', \n",
    "                      prop={'size': 10}, \n",
    "                      bbox_to_anchor=(0, 0.05, 1, 1))\n",
    "        if sys.version_info.minor > 7:\n",
    "            kwargs['ncols'] = np.max([2, np.ceil(len(labels) / 2)])\n",
    "        fig.legend(handles, labels, **kwargs)\n",
    "\n",
    "    def plot_hierarchical_predictions_gap(self,\n",
    "                                          Y_df: pd.DataFrame,\n",
    "                                          models: Optional[List[str]] = None,\n",
    "                                          xlabel: Optional=None,\n",
    "                                          ylabel: Optional=None,\n",
    "                                          ):\n",
    "        \"\"\" Hierarchically Predictions Gap plot\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `Y_df`: pd.DataFrame, hierarchically structured series ($\\mathbf{y}_{[a,b]}$). \n",
    "                It contains columns ['unique_id', 'ds', 'y'] and models. <br>\n",
    "        `models`: List[str], string identifying filtering model columns.\n",
    "        `xlabel`: str, string for the plot's x axis label.\n",
    "        `ylable`: str, string for the plot's y axis label.\n",
    "\n",
    "        **Returns:**<br>\n",
    "        Plots of aggregated predictions at different levels of the hierarchical structure.\n",
    "        The aggregation is performed according to the tag levels see \n",
    "        [aggregate function](https://nixtla.github.io/hierarchicalforecast/utils.html).<br><br>\n",
    "        \"\"\"\n",
    "        # Parse predictions dataframe\n",
    "        horizon_dates = Y_df['ds'].unique()\n",
    "        cols = models if models is not None else Y_df.drop(['ds', 'y'], axis=1).columns\n",
    "        \n",
    "        # Plot predictions across tag levels\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        \n",
    "        if 'y' in Y_df.columns:\n",
    "            y_plot = Y_df[Y_df.index ==\"['Total']\"].y.values\n",
    "            plt.plot(horizon_dates, y_plot, label='True')\n",
    "\n",
    "        ys = []\n",
    "        for tag in self.tags:\n",
    "            y_plot = sum([Y_df[cols].loc[Y_df.index == idx].values \\\n",
    "                          for idx in self.tags[tag]])\n",
    "            plt.plot(horizon_dates, y_plot, label=f'Level: {tag}')\n",
    "            \n",
    "            ys.append(y_plot[:,None])\n",
    "\n",
    "        plt.title('Predictions Accumulated Difference')\n",
    "        if ylabel is not None:\n",
    "            plt.ylabel(ylabel)\n",
    "        if xlabel is not None:\n",
    "            plt.xlabel(xlabel)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c4cff-ebbe-41f9-920b-7bbc997d0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalPlot, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1872c-7979-44f7-972b-2031729b04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalPlot.plot_summing_matrix, \n",
    "         name='plot_summing_matrix', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920de36f-e7fe-4ea4-81bb-d0f897e1f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalPlot.plot_series, \n",
    "         name='plot_series', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa265cd-0c05-4617-a40a-f2c62513f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalPlot.plot_hierarchically_linked_series, \n",
    "         name='plot_hierarchically_linked_series', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8621cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HierarchicalPlot.plot_hierarchical_predictions_gap,\n",
    "         name='plot_hierarchical_predictions_gap', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bdbce-cb13-4ba2-a794-1cd1bc3b96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hplots = HierarchicalPlot(S=S, tags=tags)\n",
    "hplots.plot_summing_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa2909-6344-4b6c-a4d9-6d4f903ce408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hier_df['Model'] = hier_df['y'] * 1.1\n",
    "hier_df['Model-lo-80'] = hier_df['Model'] - 0.1 * hier_df['Model']\n",
    "hier_df['Model-hi-80'] = hier_df['Model'] + 0.1 * hier_df['Model']\n",
    "hplots.plot_series(\n",
    "    series='Australia', \n",
    "    Y_df=hier_df,\n",
    "    level=[80, 90]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88068d1a-b670-410a-975e-a92e22ea9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hplots.plot_series(series='Australia', \n",
    "                   Y_df=hier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b90ed3-e1c3-47da-850b-ccda3319f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hplots.plot_hierarchically_linked_series(\n",
    "    bottom_series='Australia/Western Australia/Experience Perth/Visiting', \n",
    "    Y_df=hier_df,\n",
    "    level=[80, 90]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45855eb-e800-40db-a00b-5ddb956ae348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "hplots.plot_hierarchically_linked_series(\n",
    "    bottom_series='Australia/Western Australia/Experience Perth/Visiting', \n",
    "    Y_df=hier_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9263e-6d07-4527-88ea-40153435f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test series with just one value\n",
    "hplots.plot_hierarchically_linked_series(\n",
    "    bottom_series='Australia/Western Australia/Experience Perth/Visiting', \n",
    "    Y_df=hier_df.groupby('unique_id').tail(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, ETS, Naive\n",
    "from datasetsforecast.hierarchical import HierarchicalData\n",
    "\n",
    "Y_df, S, tags = HierarchicalData.load('./data', 'Labour')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "\n",
    "Y_test_df  = Y_df.groupby('unique_id').tail(24)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)\n",
    "Y_test_df  = Y_test_df.set_index('unique_id')\n",
    "Y_train_df = Y_train_df.set_index('unique_id')\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    df=Y_train_df, \n",
    "    #models=[AutoARIMA(season_length=12), Naive()], \n",
    "    models=[ETS(season_length=12, model='AAZ')],\n",
    "    freq='MS', \n",
    "    n_jobs=-1\n",
    ")\n",
    "Y_hat_df = fcst.forecast(h=24)\n",
    "\n",
    "# Plot prediction difference of different aggregation\n",
    "# Levels Country, Country/Region, Country/Gender/Region ...\n",
    "hplots = HierarchicalPlot(S=S, tags=tags)\n",
    "\n",
    "hplots.plot_hierarchical_predictions_gap(\n",
    "    Y_df=Y_hat_df, models='ETS',\n",
    "    xlabel='Month', ylabel='Predictions',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d4d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d443e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchicalforecast",
   "language": "python",
   "name": "hierarchicalforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
