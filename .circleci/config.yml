version: 2.1
jobs:
  nbdev-tests:
    resource_class: xlarge
    docker:
      - image: python:3.10-slim
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            pip install uv
            uv venv --python 3.10
      - run:
          name: Run nbdev tests
          command: |
            source .venv/bin/activate           
            uv pip install ".[dev]"
            nbdev_test --do_print --timing
  test-model-performance:
    parameters:
      hierarchy: 
        type: string
        default: "strict"
      type: 
        type: string
        default: "point"
      engine: 
        type: string
        default: "pandas"
    resource_class: large
    docker:
      - image: python:3.10-slim
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            pip install uv
            uv venv --python 3.10
      - run:
          name: Run model performance tests
          command: |
            source .venv/bin/activate           
            uv pip install ".[dev]"
            cd ./action_files/test_models/
            uv pip install -r requirements.txt
            python -m src.models << parameters.hierarchy >> << parameters.type >> << parameters.engine >>
            python -m src.evaluation << parameters.type >>
            cd ../../
      - store_artifacts:
          path: ./action_files/test_models/data/evaluation.csv
          destination: evaluation.csv
  test-model-performance-temporal:
    resource_class: large
    docker:
      - image: python:3.10-slim
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            pip install uv
            uv venv --python 3.10
      - run:
          name: Run model performance tests
          command: |
            source .venv/bin/activate           
            uv pip install ".[dev]"
            cd ./action_files/test_models/
            uv pip install -r requirements.txt
            python -m src.models_temporal 
            python -m src.evaluation_temporal
            cd ../../
      - store_artifacts:
          path: ./action_files/test_models/data/evaluation.csv
          destination: evaluation.csv
workflows:
  sample:
    jobs:
      - nbdev-tests
      - test-model-performance:
          matrix:
            parameters:
              hierarchy: ["strict", "non-strict"]
              type: ["point", "probabilistic"]
              engine: ["pandas", "polars"]
      - test-model-performance-temporal